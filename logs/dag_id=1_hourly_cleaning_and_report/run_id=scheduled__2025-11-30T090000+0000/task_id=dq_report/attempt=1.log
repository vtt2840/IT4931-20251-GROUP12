[2025-11-30T10:00:27.947+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T09:00:00+00:00 [queued]>
[2025-11-30T10:00:27.956+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T09:00:00+00:00 [queued]>
[2025-11-30T10:00:27.957+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-11-30T10:00:27.969+0000] {taskinstance.py:2191} INFO - Executing <Task(SparkSubmitOperator): dq_report> on 2025-11-30 09:00:00+00:00
[2025-11-30T10:00:27.975+0000] {standard_task_runner.py:60} INFO - Started process 3649 to run task
[2025-11-30T10:00:27.978+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', '1_hourly_cleaning_and_report', 'dq_report', 'scheduled__2025-11-30T09:00:00+00:00', '--job-id', '15', '--raw', '--subdir', 'DAGS_FOLDER/hourly_etl.py', '--cfg-path', '/tmp/tmpd5yrya39']
[2025-11-30T10:00:27.982+0000] {standard_task_runner.py:88} INFO - Job 15: Subtask dq_report
[2025-11-30T10:00:28.051+0000] {task_command.py:423} INFO - Running <TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T09:00:00+00:00 [running]> on host fa0622e2494f
[2025-11-30T10:00:28.152+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='group12' AIRFLOW_CTX_DAG_ID='1_hourly_cleaning_and_report' AIRFLOW_CTX_TASK_ID='dq_report' AIRFLOW_CTX_EXECUTION_DATE='2025-11-30T09:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-30T09:00:00+00:00'
[2025-11-30T10:00:28.155+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-11-30T10:00:28.156+0000] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2025-11-30T10:00:28.157+0000] {spark_submit.py:473} INFO - Spark-Submit cmd: spark-submit --master local --conf spark.master=local[*] --name arrow-spark /opt/***/scripts/dq_report.py
[2025-11-30T10:00:30.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkContext: Running Spark version 3.5.0
[2025-11-30T10:00:30.205+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-30T10:00:30.206+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkContext: Java version 17.0.17
[2025-11-30T10:00:30.250+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-11-30T10:00:30.309+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceUtils: ==============================================================
[2025-11-30T10:00:30.310+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-11-30T10:00:30.311+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceUtils: ==============================================================
[2025-11-30T10:00:30.312+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkContext: Submitted application: dq-report
[2025-11-30T10:00:30.325+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-11-30T10:00:30.331+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceProfile: Limiting resource is cpu
[2025-11-30T10:00:30.332+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-11-30T10:00:30.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SecurityManager: Changing view acls to: ***
[2025-11-30T10:00:30.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SecurityManager: Changing modify acls to: ***
[2025-11-30T10:00:30.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SecurityManager: Changing view acls groups to:
[2025-11-30T10:00:30.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SecurityManager: Changing modify acls groups to:
[2025-11-30T10:00:30.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-11-30T10:00:30.537+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Utils: Successfully started service 'sparkDriver' on port 34385.
[2025-11-30T10:00:30.559+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkEnv: Registering MapOutputTracker
[2025-11-30T10:00:30.587+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkEnv: Registering BlockManagerMaster
[2025-11-30T10:00:30.599+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-11-30T10:00:30.603+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-11-30T10:00:30.604+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-11-30T10:00:30.620+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-130d4263-ef78-4999-9eb5-be5c4532e3ea
[2025-11-30T10:00:30.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-11-30T10:00:30.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-11-30T10:00:30.742+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-11-30T10:00:30.806+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-11-30T10:00:30.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Executor: Starting executor ID driver on host fa0622e2494f
[2025-11-30T10:00:30.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Executor: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-30T10:00:30.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Executor: Java version 17.0.17
[2025-11-30T10:00:30.892+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-11-30T10:00:30.893+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@aa898df for default.
[2025-11-30T10:00:30.908+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33599.
[2025-11-30T10:00:30.908+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO NettyBlockTransferService: Server created on fa0622e2494f:33599
[2025-11-30T10:00:30.909+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-11-30T10:00:30.914+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fa0622e2494f, 33599, None)
[2025-11-30T10:00:30.916+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManagerMasterEndpoint: Registering block manager fa0622e2494f:33599 with 434.4 MiB RAM, BlockManagerId(driver, fa0622e2494f, 33599, None)
[2025-11-30T10:00:30.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fa0622e2494f, 33599, None)
[2025-11-30T10:00:30.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:30 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fa0622e2494f, 33599, None)
[2025-11-30T10:00:31.195+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:31,195 - INFO - ================================================================================
[2025-11-30T10:00:31.196+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:31,195 - INFO - Starting Data Quality Report Job
[2025-11-30T10:00:31.196+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:31,195 - INFO - ================================================================================
[2025-11-30T10:00:31.197+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:31,195 - INFO - Reading cleaned data from: hdfs://hadoop-namenode:9000/clean-data/air-quality
[2025-11-30T10:00:31.248+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:31 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-11-30T10:00:31.254+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:31 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2025-11-30T10:00:32.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO InMemoryFileIndex: It took 60 ms to list leaf files for 1 paths.
[2025-11-30T10:00:32.497+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:32.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:32.510+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:32.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:32.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:32.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:32.559+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.2 KiB, free 434.3 MiB)
[2025-11-30T10:00:32.582+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
[2025-11-30T10:00:32.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on fa0622e2494f:33599 (size: 37.2 KiB, free: 434.4 MiB)
[2025-11-30T10:00:32.587+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:32.601+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:32.602+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-11-30T10:00:32.647+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (fa0622e2494f, executor driver, partition 0, PROCESS_LOCAL, 7854 bytes)
[2025-11-30T10:00:32.657+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-11-30T10:00:32.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2100 bytes result sent to driver
[2025-11-30T10:00:32.951+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 318 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:32.952+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-11-30T10:00:32.956+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.434 s
[2025-11-30T10:00:32.958+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:32.959+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-11-30T10:00:32.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:32 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.461960 s
[2025-11-30T10:00:33.241+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:33 INFO BlockManagerInfo: Removed broadcast_0_piece0 on fa0622e2494f:33599 in memory (size: 37.2 KiB, free: 434.4 MiB)
[2025-11-30T10:00:33.711+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:33 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:33.715+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:33 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:33.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:33 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:34.013+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 145.052899 ms
[2025-11-30T10:00:34.031+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.1 KiB, free 434.2 MiB)
[2025-11-30T10:00:34.043+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 434.2 MiB)
[2025-11-30T10:00:34.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fa0622e2494f:33599 (size: 34.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.045+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:34.054+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:34.089+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-11-30T10:00:34.093+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:34.094+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:34.094+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:34.095+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:34.096+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:34.129+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.131+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.132+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on fa0622e2494f:33599 (size: 8.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.133+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:34.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:34.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-11-30T10:00:34.140+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:34.142+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-11-30T10:00:34.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 26.270612 ms
[2025-11-30T10:00:34.210+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:34.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:34.317+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2179 bytes result sent to driver
[2025-11-30T10:00:34.319+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 182 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:34.320+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-11-30T10:00:34.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.220 s
[2025-11-30T10:00:34.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:34.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:34.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:34.324+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:34.360+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 12.968582 ms
[2025-11-30T10:00:34.376+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:34.379+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:34.380+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:34.380+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-11-30T10:00:34.381+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:34.381+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:34.386+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.388+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.388+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.389+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:34.390+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:34.390+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-11-30T10:00:34.393+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:34.394+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
[2025-11-30T10:00:34.410+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Removed broadcast_2_piece0 on fa0622e2494f:33599 in memory (size: 8.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.431+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:34.433+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
[2025-11-30T10:00:34.449+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 13.855551 ms
[2025-11-30T10:00:34.459+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 4081 bytes result sent to driver
[2025-11-30T10:00:34.462+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 71 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:34.465+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-11-30T10:00:34.465+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.080 s
[2025-11-30T10:00:34.466+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:34.467+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-11-30T10:00:34.467+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.087825 s
[2025-11-30T10:00:34.469+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:34,469 - INFO - Total records: 39
[2025-11-30T10:00:34.688+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:34,688 - INFO - Computing global data quality metrics...
[2025-11-30T10:00:34.749+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:34.752+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileSourceStrategy: Pushed Filters: IsNull(city)
[2025-11-30T10:00:34.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileSourceStrategy: Post-Scan Filters: isnull(city#0)
[2025-11-30T10:00:34.800+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 19.153627 ms
[2025-11-30T10:00:34.805+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:34.813+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:34.814+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:34.815+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:34.817+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:34.824+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Registering RDD 12 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-11-30T10:00:34.825+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:34.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:34.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:34.827+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:34.828+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:34.828+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:34.830+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T10:00:34.832+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:34.832+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:34.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:34.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-11-30T10:00:34.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:34.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
[2025-11-30T10:00:34.856+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO CodeGenerator: Code generated in 15.718919 ms
[2025-11-30T10:00:34.858+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:34.878+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FilterCompat: Filtering using predicate: eq(city, null)
[2025-11-30T10:00:34.893+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:34.906+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO FilterCompat: Filtering using predicate: eq(city, null)
[2025-11-30T10:00:34.916+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2235 bytes result sent to driver
[2025-11-30T10:00:34.917+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Removed broadcast_3_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:34.918+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 85 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:34.919+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-11-30T10:00:34.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.094 s
[2025-11-30T10:00:34.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:34.921+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:34.921+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:34.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:34.926+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Removed broadcast_1_piece0 on fa0622e2494f:33599 in memory (size: 34.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:34.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:34.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:34.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
[2025-11-30T10:00:34.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:34.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:34.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:34.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on fa0622e2494f:33599 (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:34.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:34.948+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:34.948+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-11-30T10:00:34.949+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:34.950+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
[2025-11-30T10:00:34.953+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:34.954+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:34.957+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 3988 bytes result sent to driver
[2025-11-30T10:00:34.958+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:34.959+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-11-30T10:00:34.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
[2025-11-30T10:00:34.961+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:34.961+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-11-30T10:00:34.962+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:34 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.020542 s
[2025-11-30T10:00:35.010+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.012+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(aqi)
[2025-11-30T10:00:35.013+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(aqi#1)
[2025-11-30T10:00:35.049+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO CodeGenerator: Code generated in 14.63699 ms
[2025-11-30T10:00:35.053+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_6_piece0 on fa0622e2494f:33599 in memory (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.064+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.065+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.065+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_4_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.071+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 19 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-11-30T10:00:35.072+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.073+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.073+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.074+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_5_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.074+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.075+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.075+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.079+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.080+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.080+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.081+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.082+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:35.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
[2025-11-30T10:00:35.099+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO CodeGenerator: Code generated in 11.434505 ms
[2025-11-30T10:00:35.101+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.114+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(aqi, null)
[2025-11-30T10:00:35.116+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.128+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(aqi, null)
[2025-11-30T10:00:35.133+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 2149 bytes result sent to driver
[2025-11-30T10:00:35.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 51 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.062 s
[2025-11-30T10:00:35.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.153+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.154+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.155+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.156+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-11-30T10:00:35.157+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.158+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.158+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.163+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.164+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.164+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_8_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
[2025-11-30T10:00:35.169+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.170+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.174+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 3988 bytes result sent to driver
[2025-11-30T10:00:35.175+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.175+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.176+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.018 s
[2025-11-30T10:00:35.176+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.177+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-11-30T10:00:35.177+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.021243 s
[2025-11-30T10:00:35.212+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.213+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(co)
[2025-11-30T10:00:35.214+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(co#2)
[2025-11-30T10:00:35.240+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO CodeGenerator: Code generated in 11.086168 ms
[2025-11-30T10:00:35.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.256+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_7_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.261+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.262+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_9_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.263+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.264+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.265+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.271+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 26 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-11-30T10:00:35.272+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.273+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.273+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.274+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.274+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.275+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.275+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.276+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.277+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.277+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.277+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.279+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:35.279+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 10.0 (TID 7)
[2025-11-30T10:00:35.294+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO CodeGenerator: Code generated in 12.110374 ms
[2025-11-30T10:00:35.295+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.310+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(co, null)
[2025-11-30T10:00:35.312+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(co, null)
[2025-11-30T10:00:35.328+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 10.0 (TID 7). 2149 bytes result sent to driver
[2025-11-30T10:00:35.328+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 50 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.329+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.330+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.057 s
[2025-11-30T10:00:35.330+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.331+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.331+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.332+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.350+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.352+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.353+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
[2025-11-30T10:00:35.354+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.354+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.355+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.355+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:35.356+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.356+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.357+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.358+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.358+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.359+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)
[2025-11-30T10:00:35.363+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 3988 bytes result sent to driver
[2025-11-30T10:00:35.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 10 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.375+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.375+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s
[2025-11-30T10:00:35.376+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.376+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2025-11-30T10:00:35.377+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.019937 s
[2025-11-30T10:00:35.403+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.407+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(no2)
[2025-11-30T10:00:35.407+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(no2#3)
[2025-11-30T10:00:35.428+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.436+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.437+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.438+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.439+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.445+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 33 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-11-30T10:00:35.446+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.447+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.447+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.448+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.448+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.449+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.450+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.450+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.451+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.451+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.452+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.453+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 9) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:35.453+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 13.0 (TID 9)
[2025-11-30T10:00:35.458+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.471+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(no2, null)
[2025-11-30T10:00:35.472+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.484+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(no2, null)
[2025-11-30T10:00:35.489+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 13.0 (TID 9). 2149 bytes result sent to driver
[2025-11-30T10:00:35.490+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 9) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.490+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.491+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.043 s
[2025-11-30T10:00:35.491+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.492+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.492+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.493+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2025-11-30T10:00:35.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)
[2025-11-30T10:00:35.519+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)
[2025-11-30T10:00:35.519+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.522+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 10) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.522+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 15.0 (TID 10)
[2025-11-30T10:00:35.524+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.525+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.531+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 15.0 (TID 10). 4074 bytes result sent to driver
[2025-11-30T10:00:35.532+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_14_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.532+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 10) in 13 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.533+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.534+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-11-30T10:00:35.534+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.535+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-11-30T10:00:35.536+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.021490 s
[2025-11-30T10:00:35.537+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_11_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.543+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_12_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.546+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_10_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.565+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.566+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(o3)
[2025-11-30T10:00:35.566+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(o3#4)
[2025-11-30T10:00:35.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.591+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.592+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.592+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 16 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.593+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.597+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-11-30T10:00:35.597+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.598+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.599+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.599+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.601+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.604+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.606+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.606+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.608+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.608+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 11) (fa0622e2494f, executor driver, partition 0, ANY, 8537 bytes)
[2025-11-30T10:00:35.609+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 16.0 (TID 11)
[2025-11-30T10:00:35.612+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.624+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(o3, null)
[2025-11-30T10:00:35.625+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.639+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(o3, null)
[2025-11-30T10:00:35.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 16.0 (TID 11). 2149 bytes result sent to driver
[2025-11-30T10:00:35.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 11) in 36 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.042 s
[2025-11-30T10:00:35.645+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.646+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.646+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.647+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.659+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.660+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.661+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 18 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.661+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-11-30T10:00:35.662+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.662+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.663+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.663+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.664+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on fa0622e2494f:33599 (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.664+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.665+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.665+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.666+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 12) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.667+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 18.0 (TID 12)
[2025-11-30T10:00:35.670+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.671+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.673+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 18.0 (TID 12). 3988 bytes result sent to driver
[2025-11-30T10:00:35.674+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 12) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.675+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.675+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
[2025-11-30T10:00:35.676+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.677+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-11-30T10:00:35.677+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.016807 s
[2025-11-30T10:00:35.707+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.708+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(pm10)
[2025-11-30T10:00:35.708+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(pm10#5)
[2025-11-30T10:00:35.728+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 207.2 KiB, free 433.7 MiB)
[2025-11-30T10:00:35.735+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T10:00:35.736+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.737+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 19 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.738+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.742+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-11-30T10:00:35.743+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.744+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.745+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.745+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.746+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.746+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 18.9 KiB, free 433.6 MiB)
[2025-11-30T10:00:35.747+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.6 MiB)
[2025-11-30T10:00:35.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 13) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:35.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 19.0 (TID 13)
[2025-11-30T10:00:35.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.767+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(pm10, null)
[2025-11-30T10:00:35.769+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.783+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(pm10, null)
[2025-11-30T10:00:35.789+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 19.0 (TID 13). 2149 bytes result sent to driver
[2025-11-30T10:00:35.790+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 13) in 40 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.790+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.046 s
[2025-11-30T10:00:35.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.813+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.814+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.815+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 21 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.816+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
[2025-11-30T10:00:35.816+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.817+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.818+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)
[2025-11-30T10:00:35.818+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)
[2025-11-30T10:00:35.819+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.820+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.820+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.821+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.822+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 14) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.822+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 21.0 (TID 14)
[2025-11-30T10:00:35.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.830+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 21.0 (TID 14). 4031 bytes result sent to driver
[2025-11-30T10:00:35.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_15_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 14) in 13 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.836+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 21 (count at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-11-30T10:00:35.836+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
[2025-11-30T10:00:35.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0.022829 s
[2025-11-30T10:00:35.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_18_piece0 on fa0622e2494f:33599 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_17_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.851+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_20_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.857+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_13_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.862+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Removed broadcast_16_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:35.878+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:35.879+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Pushed Filters: IsNull(pm25)
[2025-11-30T10:00:35.879+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceStrategy: Post-Scan Filters: isnull(pm25#6)
[2025-11-30T10:00:35.901+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.906+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.907+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.908+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 22 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.908+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:35.913+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Registering RDD 54 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-11-30T10:00:35.913+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.914+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.915+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:35.915+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.916+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.917+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.917+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.918+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.918+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.921+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 15) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:35.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 22.0 (TID 15)
[2025-11-30T10:00:35.925+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:35.940+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(pm25, null)
[2025-11-30T10:00:35.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:35.952+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO FilterCompat: Filtering using predicate: eq(pm25, null)
[2025-11-30T10:00:35.956+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 22.0 (TID 15). 2149 bytes result sent to driver
[2025-11-30T10:00:35.957+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 15) in 38 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.958+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.958+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.044 s
[2025-11-30T10:00:35.959+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:35.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:35.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:35.961+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:35.976+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:35.978+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:35.979+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Final stage: ResultStage 24 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:35.982+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-11-30T10:00:35.984+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:35.985+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:35.986+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.986+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:35.987+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:35.987+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:35.988+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:35.988+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-11-30T10:00:35.989+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 16) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:35.989+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Running task 0.0 in stage 24.0 (TID 16)
[2025-11-30T10:00:35.990+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:35.990+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:35.991+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO Executor: Finished task 0.0 in stage 24.0 (TID 16). 3988 bytes result sent to driver
[2025-11-30T10:00:35.992+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 16) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:35.994+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-11-30T10:00:35.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: ResultStage 24 (count at NativeMethodAccessorImpl.java:0) finished in 0.013 s
[2025-11-30T10:00:35.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:35.996+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
[2025-11-30T10:00:35.996+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:35 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.017912 s
[2025-11-30T10:00:36.021+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:36.022+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Pushed Filters: IsNull(so2)
[2025-11-30T10:00:36.022+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Post-Scan Filters: isnull(so2#7)
[2025-11-30T10:00:36.037+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 207.2 KiB, free 433.7 MiB)
[2025-11-30T10:00:36.043+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.043+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 25 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:36.049+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Registering RDD 61 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-11-30T10:00:36.052+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.054+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:36.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 18.9 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 17) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:36.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 25.0 (TID 17)
[2025-11-30T10:00:36.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:36.071+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FilterCompat: Filtering using predicate: eq(so2, null)
[2025-11-30T10:00:36.072+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:36.081+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FilterCompat: Filtering using predicate: eq(so2, null)
[2025-11-30T10:00:36.085+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 25.0 (TID 17). 2149 bytes result sent to driver
[2025-11-30T10:00:36.086+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 17) in 29 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.087+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.088+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.036 s
[2025-11-30T10:00:36.088+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:36.089+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:36.089+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:36.090+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:36.101+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.103+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.105+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.107+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-11-30T10:00:36.107+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.108+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.109+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.5 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.110+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.111+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.112+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_24_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.112+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.113+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.113+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.114+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 18) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:36.115+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 27.0 (TID 18)
[2025-11-30T10:00:36.115+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_26_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.116+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:36.116+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:36.118+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 27.0 (TID 18). 3988 bytes result sent to driver
[2025-11-30T10:00:36.118+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_19_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.120+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 18) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.120+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.121+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
[2025-11-30T10:00:36.121+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:36.122+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-11-30T10:00:36.122+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 18 finished: count at NativeMethodAccessorImpl.java:0, took 0.018097 s
[2025-11-30T10:00:36.123+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_23_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.127+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_21_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.131+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_22_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.144+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:36.145+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Pushed Filters: IsNull(timestamp_utc)
[2025-11-30T10:00:36.145+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Post-Scan Filters: isnull(timestamp_utc#8)
[2025-11-30T10:00:36.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 9.387163 ms
[2025-11-30T10:00:36.168+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.173+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.174+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.175+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 28 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.176+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:36.181+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Registering RDD 68 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-11-30T10:00:36.183+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got map stage job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.184+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.185+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:36.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on fa0622e2494f:33599 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 19) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:36.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 28.0 (TID 19)
[2025-11-30T10:00:36.197+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 9.346032 ms
[2025-11-30T10:00:36.198+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:36.223+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-11-30T10:00:36.333+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:36.348+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 28.0 (TID 19). 2192 bytes result sent to driver
[2025-11-30T10:00:36.349+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 19) in 164 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.350+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.350+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0.168 s
[2025-11-30T10:00:36.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:36.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:36.352+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:36.354+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:36.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.363+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-11-30T10:00:36.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.366+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.366+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 20) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:36.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 30.0 (TID 20)
[2025-11-30T10:00:36.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:36.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:36.372+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 30.0 (TID 20). 3988 bytes result sent to driver
[2025-11-30T10:00:36.373+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 20) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.373+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.009 s
[2025-11-30T10:00:36.376+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:36.377+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-11-30T10:00:36.377+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 20 finished: count at NativeMethodAccessorImpl.java:0, took 0.011420 s
[2025-11-30T10:00:36.377+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO - Null counts:
[2025-11-30T10:00:36.378+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   city: 0 nulls (0.0%)
[2025-11-30T10:00:36.378+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   aqi: 0 nulls (0.0%)
[2025-11-30T10:00:36.379+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   co: 0 nulls (0.0%)
[2025-11-30T10:00:36.379+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   no2: 0 nulls (0.0%)
[2025-11-30T10:00:36.380+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   o3: 0 nulls (0.0%)
[2025-11-30T10:00:36.380+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   pm10: 0 nulls (0.0%)
[2025-11-30T10:00:36.381+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   pm25: 0 nulls (0.0%)
[2025-11-30T10:00:36.382+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   so2: 0 nulls (0.0%)
[2025-11-30T10:00:36.382+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO -   timestamp_utc: 0 nulls (0.0%)
[2025-11-30T10:00:36.386+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,375 - INFO - Analyzing duplicates...
[2025-11-30T10:00:36.399+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:36.400+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:36.401+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:36.473+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 46.611994 ms
[2025-11-30T10:00:36.476+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 207.4 KiB, free 433.7 MiB)
[2025-11-30T10:00:36.484+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.484+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.485+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 31 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.485+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:36.502+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Registering RDD 75 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-11-30T10:00:36.506+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.507+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:36.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.510+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 32.0 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 433.6 MiB)
[2025-11-30T10:00:36.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on fa0622e2494f:33599 (size: 13.4 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 21) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:36.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 31.0 (TID 21)
[2025-11-30T10:00:36.542+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 28.999946 ms
[2025-11-30T10:00:36.556+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 8.536472 ms
[2025-11-30T10:00:36.564+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 5.056851 ms
[2025-11-30T10:00:36.575+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_28_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.578+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_27_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.580+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_29_piece0 on fa0622e2494f:33599 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.583+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 4.701129 ms
[2025-11-30T10:00:36.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_30_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.587+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_25_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.587+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:36.602+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:36.641+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 31.0 (TID 21). 3148 bytes result sent to driver
[2025-11-30T10:00:36.642+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 21) in 133 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.139 s
[2025-11-30T10:00:36.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:36.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:36.646+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:36.647+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:36.653+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T10:00:36.687+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 19.785111 ms
[2025-11-30T10:00:36.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Registering RDD 78 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-11-30T10:00:36.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.706+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.707+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
[2025-11-30T10:00:36.709+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.712+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[78] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.713+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 45.3 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.714+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.716+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on fa0622e2494f:33599 (size: 20.5 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.719+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[78] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.719+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.720+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 22) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7604 bytes)
[2025-11-30T10:00:36.720+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 33.0 (TID 22)
[2025-11-30T10:00:36.721+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 (2.7 KiB) non-empty blocks including 1 (2.7 KiB) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:36.722+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:36.739+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 17.023128 ms
[2025-11-30T10:00:36.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 33.0 (TID 22). 5978 bytes result sent to driver
[2025-11-30T10:00:36.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 22) in 39 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0) finished in 0.044 s
[2025-11-30T10:00:36.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:36.756+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:36.756+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:36.757+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:36.765+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 4.958032 ms
[2025-11-30T10:00:36.772+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.773+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.774+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ResultStage 36 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.774+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-11-30T10:00:36.775+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.775+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.776+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.5 KiB, free 434.0 MiB)
[2025-11-30T10:00:36.776+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.0 MiB)
[2025-11-30T10:00:36.776+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on fa0622e2494f:33599 (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.777+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.778+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.778+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.779+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 23) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:36.779+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 36.0 (TID 23)
[2025-11-30T10:00:36.781+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:36.782+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:36.787+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 5.568265 ms
[2025-11-30T10:00:36.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 36.0 (TID 23). 3995 bytes result sent to driver
[2025-11-30T10:00:36.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 23) in 15 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ResultStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0.018 s
[2025-11-30T10:00:36.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:36.794+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-11-30T10:00:36.794+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.021005 s
[2025-11-30T10:00:36.794+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,793 - INFO - Total duplicates: 5 (12.82%)
[2025-11-30T10:00:36.795+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:36,794 - INFO - Validating value ranges...
[2025-11-30T10:00:36.825+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:36.828+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(aqi,0),GreaterThan(aqi,500))
[2025-11-30T10:00:36.829+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Post-Scan Filters: ((aqi#1 < 0) OR (aqi#1 > 500))
[2025-11-30T10:00:36.849+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 8.019425 ms
[2025-11-30T10:00:36.851+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 207.2 KiB, free 433.8 MiB)
[2025-11-30T10:00:36.858+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_31_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.860+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_33_piece0 on fa0622e2494f:33599 in memory (size: 20.5 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.861+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.862+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:36.863+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 35 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.863+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:36.864+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_34_piece0 on fa0622e2494f:33599 in memory (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.866+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_32_piece0 on fa0622e2494f:33599 in memory (size: 13.4 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.867+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Registering RDD 85 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-11-30T10:00:36.868+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got map stage job 24 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.868+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.869+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:36.869+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.870+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.870+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 19.8 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.871+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.872+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.872+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.872+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.873+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.873+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 24) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:36.874+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 37.0 (TID 24)
[2025-11-30T10:00:36.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 9.221323 ms
[2025-11-30T10:00:36.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:36.903+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FilterCompat: Filtering using predicate: or(lt(aqi, 0), gt(aqi, 500))
[2025-11-30T10:00:36.904+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:36.913+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FilterCompat: Filtering using predicate: or(lt(aqi, 0), gt(aqi, 500))
[2025-11-30T10:00:36.916+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 37.0 (TID 24). 2149 bytes result sent to driver
[2025-11-30T10:00:36.917+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 24) in 44 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.917+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.918+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ShuffleMapStage 37 (count at NativeMethodAccessorImpl.java:0) finished in 0.049 s
[2025-11-30T10:00:36.919+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:36.919+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:36.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:36.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:36.930+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:36.931+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Got job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:36.931+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Final stage: ResultStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:36.932+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
[2025-11-30T10:00:36.932+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:36.933+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[88] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:36.933+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.934+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:36.934+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.935+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:36.935+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[88] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:36.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-11-30T10:00:36.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 25) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:36.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Running task 0.0 in stage 39.0 (TID 25)
[2025-11-30T10:00:36.939+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:36.940+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:36.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO Executor: Finished task 0.0 in stage 39.0 (TID 25). 3988 bytes result sent to driver
[2025-11-30T10:00:36.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 25) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:36.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-11-30T10:00:36.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: ResultStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0.011 s
[2025-11-30T10:00:36.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:36.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
[2025-11-30T10:00:36.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DAGScheduler: Job 25 finished: count at NativeMethodAccessorImpl.java:0, took 0.014519 s
[2025-11-30T10:00:36.969+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:36.970+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(pm25,0.0),GreaterThan(pm25,500.0))
[2025-11-30T10:00:36.971+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO FileSourceStrategy: Post-Scan Filters: ((pm25#6 < 0.0) OR (pm25#6 > 500.0))
[2025-11-30T10:00:36.987+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO CodeGenerator: Code generated in 7.386127 ms
[2025-11-30T10:00:36.989+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.996+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_37_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:36.998+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T10:00:36.999+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Removed broadcast_36_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.000+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:36 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:37.000+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 38 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.001+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.002+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_35_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.004+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 92 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2025-11-30T10:00:37.004+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.005+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.005+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.006+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.006+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.007+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.007+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.008+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.008+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.009+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.009+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.010+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 26) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.010+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 40.0 (TID 26)
[2025-11-30T10:00:37.020+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 6.869083 ms
[2025-11-30T10:00:37.020+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.031+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(pm25, 0.0), gt(pm25, 500.0))
[2025-11-30T10:00:37.032+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.041+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(pm25, 0.0), gt(pm25, 500.0))
[2025-11-30T10:00:37.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 40.0 (TID 26). 2149 bytes result sent to driver
[2025-11-30T10:00:37.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 26) in 36 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.045+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.045+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0) finished in 0.041 s
[2025-11-30T10:00:37.046+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.047+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.047+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.048+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 27 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 42 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
[2025-11-30T10:00:37.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.062+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.063+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.063+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.064+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.064+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.065+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 27) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.065+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 42.0 (TID 27)
[2025-11-30T10:00:37.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.067+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 42.0 (TID 27). 3988 bytes result sent to driver
[2025-11-30T10:00:37.067+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 27) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.068+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.068+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:37.069+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.069+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
[2025-11-30T10:00:37.070+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 27 finished: count at NativeMethodAccessorImpl.java:0, took 0.009992 s
[2025-11-30T10:00:37.091+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.092+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(pm10,0.0),GreaterThan(pm10,600.0))
[2025-11-30T10:00:37.093+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters: ((pm10#5 < 0.0) OR (pm10#5 > 600.0))
[2025-11-30T10:00:37.114+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 10.032179 ms
[2025-11-30T10:00:37.116+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.123+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_40_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.125+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_38_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.126+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_39_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.127+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.2 MiB)
[2025-11-30T10:00:37.127+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.128+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 41 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.128+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.131+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 99 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 14
[2025-11-30T10:00:37.132+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 28 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[99] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.137+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.138+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.139+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.139+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[99] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.140+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.141+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 28) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.141+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 43.0 (TID 28)
[2025-11-30T10:00:37.146+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 8.178805 ms
[2025-11-30T10:00:37.147+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.156+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(pm10, 0.0), gt(pm10, 600.0))
[2025-11-30T10:00:37.157+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(pm10, 0.0), gt(pm10, 600.0))
[2025-11-30T10:00:37.169+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 43.0 (TID 28). 2149 bytes result sent to driver
[2025-11-30T10:00:37.171+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 28) in 35 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.171+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.172+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.038 s
[2025-11-30T10:00:37.172+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.173+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.173+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.174+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.182+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.183+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 29 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.184+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 45 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.185+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
[2025-11-30T10:00:37.185+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[102] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[102] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 29) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.191+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 45.0 (TID 29)
[2025-11-30T10:00:37.191+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.192+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.192+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 45.0 (TID 29). 3988 bytes result sent to driver
[2025-11-30T10:00:37.193+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 29) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.193+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.194+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0.009 s
[2025-11-30T10:00:37.195+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.196+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
[2025-11-30T10:00:37.196+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 29 finished: count at NativeMethodAccessorImpl.java:0, took 0.011270 s
[2025-11-30T10:00:37.218+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.219+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(co,0.0),GreaterThan(co,10000.0))
[2025-11-30T10:00:37.220+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters: ((co#2 < 0.0) OR (co#2 > 10000.0))
[2025-11-30T10:00:37.236+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 8.382303 ms
[2025-11-30T10:00:37.238+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_41_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.246+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_43_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.248+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_42_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.248+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.2 MiB)
[2025-11-30T10:00:37.249+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.249+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 44 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.249+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.252+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 106 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 15
[2025-11-30T10:00:37.253+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.254+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.254+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.255+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.255+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.256+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.256+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.257+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.257+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.258+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.258+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.259+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 30) (fa0622e2494f, executor driver, partition 0, ANY, 8537 bytes)
[2025-11-30T10:00:37.259+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 46.0 (TID 30)
[2025-11-30T10:00:37.268+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 7.93706 ms
[2025-11-30T10:00:37.269+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.282+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(co, 0.0), gt(co, 10000.0))
[2025-11-30T10:00:37.283+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.294+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(co, 0.0), gt(co, 10000.0))
[2025-11-30T10:00:37.297+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 46.0 (TID 30). 2149 bytes result sent to driver
[2025-11-30T10:00:37.298+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 30) in 42 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.298+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.299+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-11-30T10:00:37.300+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.300+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.301+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.301+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.310+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.311+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 31 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.312+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.312+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-11-30T10:00:37.313+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.314+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[109] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.314+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.315+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.315+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.316+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.316+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[109] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.316+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.317+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 31) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.317+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 48.0 (TID 31)
[2025-11-30T10:00:37.318+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.318+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.320+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 48.0 (TID 31). 3988 bytes result sent to driver
[2025-11-30T10:00:37.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 31) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.009 s
[2025-11-30T10:00:37.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-11-30T10:00:37.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 31 finished: count at NativeMethodAccessorImpl.java:0, took 0.011452 s
[2025-11-30T10:00:37.343+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.344+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(no2,0.0),GreaterThan(no2,500.0))
[2025-11-30T10:00:37.344+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters: ((no2#3 < 0.0) OR (no2#3 > 500.0))
[2025-11-30T10:00:37.354+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_46_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_45_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.363+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_44_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.0 MiB)
[2025-11-30T10:00:37.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 47 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.366+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 113 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 16
[2025-11-30T10:00:37.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.372+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.372+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.373+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.373+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 32) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.375+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 49.0 (TID 32)
[2025-11-30T10:00:37.376+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.387+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(no2, 0.0), gt(no2, 500.0))
[2025-11-30T10:00:37.389+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.398+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(no2, 0.0), gt(no2, 500.0))
[2025-11-30T10:00:37.401+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 49.0 (TID 32). 2149 bytes result sent to driver
[2025-11-30T10:00:37.402+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 32) in 29 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.402+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.403+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 49 (count at NativeMethodAccessorImpl.java:0) finished in 0.033 s
[2025-11-30T10:00:37.403+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.404+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.404+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.405+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.416+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:37.417+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 33 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:37.417+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 51 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:37.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-11-30T10:00:37.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:37.419+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.419+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.420+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.420+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.421+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.421+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.422+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 33) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.422+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 51.0 (TID 33)
[2025-11-30T10:00:37.423+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.424+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.425+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 51.0 (TID 33). 3988 bytes result sent to driver
[2025-11-30T10:00:37.426+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 33) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.427+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.428+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 51 (count at NativeMethodAccessorImpl.java:0) finished in 0.010 s
[2025-11-30T10:00:37.428+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.429+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-11-30T10:00:37.429+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 33 finished: count at NativeMethodAccessorImpl.java:0, took 0.011986 s
[2025-11-30T10:00:37.447+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.447+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(o3,0.0),GreaterThan(o3,500.0))
[2025-11-30T10:00:37.448+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters: ((o3#4 < 0.0) OR (o3#4 > 500.0))
[2025-11-30T10:00:37.458+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.465+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_47_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.466+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_49_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.467+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.468+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.469+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_48_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.470+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 50 from count at <unknown>:0
[2025-11-30T10:00:37.470+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.473+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 120 (count at <unknown>:0) as input to shuffle 17
[2025-11-30T10:00:37.474+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 34 (count at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:37.475+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (count at <unknown>:0)
[2025-11-30T10:00:37.478+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.479+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.480+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[120] at count at <unknown>:0), which has no missing parents
[2025-11-30T10:00:37.480+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.480+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.481+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.481+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.482+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[120] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.482+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.483+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 34) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.483+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 52.0 (TID 34)
[2025-11-30T10:00:37.484+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.489+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(o3, 0.0), gt(o3, 500.0))
[2025-11-30T10:00:37.490+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.500+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(o3, 0.0), gt(o3, 500.0))
[2025-11-30T10:00:37.503+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 52.0 (TID 34). 2149 bytes result sent to driver
[2025-11-30T10:00:37.503+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 34) in 26 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.504+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.504+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 52 (count at <unknown>:0) finished in 0.030 s
[2025-11-30T10:00:37.505+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.505+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.506+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.506+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-30T10:00:37.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 35 (count at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:37.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 54 (count at <unknown>:0)
[2025-11-30T10:00:37.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
[2025-11-30T10:00:37.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[123] at count at <unknown>:0), which has no missing parents
[2025-11-30T10:00:37.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.519+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.519+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[123] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 35) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 54.0 (TID 35)
[2025-11-30T10:00:37.523+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.523+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.525+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 54.0 (TID 35). 3988 bytes result sent to driver
[2025-11-30T10:00:37.526+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 35) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.526+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.527+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 54 (count at <unknown>:0) finished in 0.009 s
[2025-11-30T10:00:37.527+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.528+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
[2025-11-30T10:00:37.528+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 35 finished: count at <unknown>:0, took 0.012012 s
[2025-11-30T10:00:37.549+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.550+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(so2,0.0),GreaterThan(so2,500.0))
[2025-11-30T10:00:37.550+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters: ((so2#7 < 0.0) OR (so2#7 > 500.0))
[2025-11-30T10:00:37.560+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.567+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_51_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.568+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_50_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.569+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_52_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.569+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 434.2 MiB)
[2025-11-30T10:00:37.570+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.571+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 53 from count at <unknown>:0
[2025-11-30T10:00:37.571+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.574+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 127 (count at <unknown>:0) as input to shuffle 18
[2025-11-30T10:00:37.575+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 36 (count at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:37.576+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (count at <unknown>:0)
[2025-11-30T10:00:37.576+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.577+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.577+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[127] at count at <unknown>:0), which has no missing parents
[2025-11-30T10:00:37.578+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.578+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.579+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on fa0622e2494f:33599 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.579+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.580+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[127] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.580+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.581+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 36) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.581+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 55.0 (TID 36)
[2025-11-30T10:00:37.582+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.591+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(so2, 0.0), gt(so2, 500.0))
[2025-11-30T10:00:37.592+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.600+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FilterCompat: Filtering using predicate: or(lt(so2, 0.0), gt(so2, 500.0))
[2025-11-30T10:00:37.603+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 55.0 (TID 36). 2149 bytes result sent to driver
[2025-11-30T10:00:37.604+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 36) in 25 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 55 (count at <unknown>:0) finished in 0.029 s
[2025-11-30T10:00:37.606+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.607+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.607+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.608+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.615+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-30T10:00:37.616+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got job 37 (count at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:37.616+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ResultStage 57 (count at <unknown>:0)
[2025-11-30T10:00:37.617+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-11-30T10:00:37.618+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.619+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[130] at count at <unknown>:0), which has no missing parents
[2025-11-30T10:00:37.619+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.623+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.624+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on fa0622e2494f:33599 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.625+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.626+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[130] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.626+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 37) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:37.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 57.0 (TID 37)
[2025-11-30T10:00:37.628+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 57.0 (TID 37). 3988 bytes result sent to driver
[2025-11-30T10:00:37.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 37) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.630+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ResultStage 57 (count at <unknown>:0) finished in 0.008 s
[2025-11-30T10:00:37.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:37.632+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-11-30T10:00:37.632+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Job 37 finished: count at <unknown>:0, took 0.009871 s
[2025-11-30T10:00:37.633+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:37,626 - INFO - Detecting spikes by city/date...
[2025-11-30T10:00:37.763+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:37.764+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:37.766+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:37.797+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 7.40821 ms
[2025-11-30T10:00:37.799+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 207.5 KiB, free 433.9 MiB)
[2025-11-30T10:00:37.807+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_53_piece0 on fa0622e2494f:33599 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.808+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_54_piece0 on fa0622e2494f:33599 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.809+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.810+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on fa0622e2494f:33599 (size: 35.0 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.810+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Removed broadcast_55_piece0 on fa0622e2494f:33599 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.811+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 56 from collect at /opt/***/scripts/dq_report.py:148
[2025-11-30T10:00:37.812+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:37.817+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 135 (collect at /opt/***/scripts/dq_report.py:148) as input to shuffle 19
[2025-11-30T10:00:37.818+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 38 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T10:00:37.819+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 58 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T10:00:37.821+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:37.821+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.822+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[135] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T10:00:37.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 35.5 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.827+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.827+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on fa0622e2494f:33599 (size: 15.9 KiB, free: 434.4 MiB)
[2025-11-30T10:00:37.828+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.829+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[135] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.830+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.831+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 38) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:37.831+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 58.0 (TID 38)
[2025-11-30T10:00:37.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 6.326741 ms
[2025-11-30T10:00:37.844+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:37.870+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 2.783885 ms
[2025-11-30T10:00:37.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 5.608664 ms
[2025-11-30T10:00:37.892+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 3.660376 ms
[2025-11-30T10:00:37.899+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 4.61329 ms
[2025-11-30T10:00:37.907+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 3.998644 ms
[2025-11-30T10:00:37.914+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:37.935+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 5.007615 ms
[2025-11-30T10:00:37.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Finished task 0.0 in stage 58.0 (TID 38). 2903 bytes result sent to driver
[2025-11-30T10:00:37.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 38) in 117 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:37.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-11-30T10:00:37.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: ShuffleMapStage 58 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.127 s
[2025-11-30T10:00:37.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:37.948+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:37.949+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:37.949+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:37.952+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T10:00:37.959+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Registering RDD 138 (collect at /opt/***/scripts/dq_report.py:148) as input to shuffle 20
[2025-11-30T10:00:37.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Got map stage job 39 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T10:00:37.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T10:00:37.961+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-11-30T10:00:37.962+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:37.962+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[138] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T10:00:37.963+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 36.0 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.963+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 434.1 MiB)
[2025-11-30T10:00:37.965+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on fa0622e2494f:33599 (size: 16.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:37.965+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:37.966+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[138] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:37.966+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-11-30T10:00:37.967+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 39) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7604 bytes)
[2025-11-30T10:00:37.968+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO Executor: Running task 0.0 in stage 60.0 (TID 39)
[2025-11-30T10:00:37.970+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:37.971+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:37.977+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 3.695263 ms
[2025-11-30T10:00:37.982+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 3.403765 ms
[2025-11-30T10:00:37.989+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 4.109628 ms
[2025-11-30T10:00:37.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:37 INFO CodeGenerator: Code generated in 3.843628 ms
[2025-11-30T10:00:38.005+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.158251 ms
[2025-11-30T10:00:38.014+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 60.0 (TID 39). 5474 bytes result sent to driver
[2025-11-30T10:00:38.015+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 39) in 50 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.016+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.017+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ShuffleMapStage 60 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.056 s
[2025-11-30T10:00:38.018+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:38.018+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:38.019+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:38.019+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:38.020+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T10:00:38.038+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 7.280774 ms
[2025-11-30T10:00:38.049+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 6.121005 ms
[2025-11-30T10:00:38.073+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:148
[2025-11-30T10:00:38.075+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got job 40 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T10:00:38.076+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ResultStage 63 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T10:00:38.077+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
[2025-11-30T10:00:38.078+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.078+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[143] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T10:00:38.079+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 50.9 KiB, free 434.0 MiB)
[2025-11-30T10:00:38.085+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 434.0 MiB)
[2025-11-30T10:00:38.087+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on fa0622e2494f:33599 (size: 23.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.087+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_58_piece0 on fa0622e2494f:33599 in memory (size: 16.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.088+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.089+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[143] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.090+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.090+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 40) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:38.091+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_57_piece0 on fa0622e2494f:33599 in memory (size: 15.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.092+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 63.0 (TID 40)
[2025-11-30T10:00:38.103+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:38.104+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:38.110+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.903981 ms
[2025-11-30T10:00:38.124+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 8.840838 ms
[2025-11-30T10:00:38.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.110939 ms
[2025-11-30T10:00:38.153+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.147884 ms
[2025-11-30T10:00:38.158+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 3.216585 ms
[2025-11-30T10:00:38.170+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 2.862415 ms
[2025-11-30T10:00:38.177+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 4.338335 ms
[2025-11-30T10:00:38.184+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.565607 ms
[2025-11-30T10:00:38.194+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 8.413194 ms
[2025-11-30T10:00:38.199+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 63.0 (TID 40). 6806 bytes result sent to driver
[2025-11-30T10:00:38.200+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 40) in 113 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.201+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.202+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ResultStage 63 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.124 s
[2025-11-30T10:00:38.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:38.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
[2025-11-30T10:00:38.204+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 40 finished: collect at /opt/***/scripts/dq_report.py:148, took 0.127834 s
[2025-11-30T10:00:38.219+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:38,218 - INFO - Spike detections (>50% increase): 0
[2025-11-30T10:00:38.220+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:38,218 - INFO - Generating daily city-level data quality report...
[2025-11-30T10:00:38.308+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:38.309+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:38.310+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:38.333+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 8.240163 ms
[2025-11-30T10:00:38.334+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 207.7 KiB, free 433.9 MiB)
[2025-11-30T10:00:38.340+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 433.9 MiB)
[2025-11-30T10:00:38.341+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on fa0622e2494f:33599 (size: 35.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.342+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 60 from collect at /opt/***/scripts/dq_report.py:182
[2025-11-30T10:00:38.342+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:38.346+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Registering RDD 148 (collect at /opt/***/scripts/dq_report.py:182) as input to shuffle 21
[2025-11-30T10:00:38.346+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got map stage job 41 (collect at /opt/***/scripts/dq_report.py:182) with 1 output partitions
[2025-11-30T10:00:38.347+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at /opt/***/scripts/dq_report.py:182)
[2025-11-30T10:00:38.350+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:38.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[148] at collect at /opt/***/scripts/dq_report.py:182), which has no missing parents
[2025-11-30T10:00:38.359+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 46.4 KiB, free 433.8 MiB)
[2025-11-30T10:00:38.360+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.8 MiB)
[2025-11-30T10:00:38.360+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on fa0622e2494f:33599 (size: 19.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[148] at collect at /opt/***/scripts/dq_report.py:182) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 41) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:38.363+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 64.0 (TID 41)
[2025-11-30T10:00:38.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 6.721019 ms
[2025-11-30T10:00:38.374+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:38.396+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 4.739537 ms
[2025-11-30T10:00:38.429+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 13.552482 ms
[2025-11-30T10:00:38.434+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 3.234092 ms
[2025-11-30T10:00:38.442+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.039071 ms
[2025-11-30T10:00:38.463+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 9.794289 ms
[2025-11-30T10:00:38.466+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:38.489+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 64.0 (TID 41). 2903 bytes result sent to driver
[2025-11-30T10:00:38.489+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 41) in 127 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.490+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.490+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ShuffleMapStage 64 (collect at /opt/***/scripts/dq_report.py:182) finished in 0.143 s
[2025-11-30T10:00:38.491+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:38.491+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:38.492+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:38.493+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:38.493+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T10:00:38.503+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:182
[2025-11-30T10:00:38.506+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got job 42 (collect at /opt/***/scripts/dq_report.py:182) with 1 output partitions
[2025-11-30T10:00:38.507+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ResultStage 66 (collect at /opt/***/scripts/dq_report.py:182)
[2025-11-30T10:00:38.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
[2025-11-30T10:00:38.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[151] at collect at /opt/***/scripts/dq_report.py:182), which has no missing parents
[2025-11-30T10:00:38.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 50.0 KiB, free 433.7 MiB)
[2025-11-30T10:00:38.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 433.7 MiB)
[2025-11-30T10:00:38.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_59_piece0 on fa0622e2494f:33599 in memory (size: 23.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on fa0622e2494f:33599 (size: 21.1 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_61_piece0 on fa0622e2494f:33599 in memory (size: 19.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[151] at collect at /opt/***/scripts/dq_report.py:182) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 42) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:38.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 66.0 (TID 42)
[2025-11-30T10:00:38.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:38.522+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:38.541+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 8.633044 ms
[2025-11-30T10:00:38.553+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 5.774577 ms
[2025-11-30T10:00:38.563+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 6.880627 ms
[2025-11-30T10:00:38.574+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 66.0 (TID 42). 5159 bytes result sent to driver
[2025-11-30T10:00:38.575+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 42) in 59 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.576+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.576+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ResultStage 66 (collect at /opt/***/scripts/dq_report.py:182) finished in 0.070 s
[2025-11-30T10:00:38.577+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:38.577+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
[2025-11-30T10:00:38.578+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 42 finished: collect at /opt/***/scripts/dq_report.py:182, took 0.072848 s
[2025-11-30T10:00:38.582+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:38,582 - INFO - Daily city-level DQ records: 1
[2025-11-30T10:00:38.583+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:38,582 - INFO - Generating report JSON...
[2025-11-30T10:00:38.601+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:38.601+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:38.602+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:38.622+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 12.041932 ms
[2025-11-30T10:00:38.624+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 207.2 KiB, free 433.7 MiB)
[2025-11-30T10:00:38.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T10:00:38.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on fa0622e2494f:33599 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.632+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 63 from collect at /opt/***/scripts/dq_report.py:189
[2025-11-30T10:00:38.632+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:38.635+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Registering RDD 155 (collect at /opt/***/scripts/dq_report.py:189) as input to shuffle 22
[2025-11-30T10:00:38.636+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got map stage job 43 (collect at /opt/***/scripts/dq_report.py:189) with 1 output partitions
[2025-11-30T10:00:38.637+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ShuffleMapStage 67 (collect at /opt/***/scripts/dq_report.py:189)
[2025-11-30T10:00:38.638+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:38.638+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.639+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[155] at collect at /opt/***/scripts/dq_report.py:189), which has no missing parents
[2025-11-30T10:00:38.639+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 39.3 KiB, free 433.6 MiB)
[2025-11-30T10:00:38.640+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 433.6 MiB)
[2025-11-30T10:00:38.641+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on fa0622e2494f:33599 (size: 17.5 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.641+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.641+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[155] at collect at /opt/***/scripts/dq_report.py:189) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.642+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.642+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 43) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:38.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 67.0 (TID 43)
[2025-11-30T10:00:38.655+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 10.868001 ms
[2025-11-30T10:00:38.661+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 4.168983 ms
[2025-11-30T10:00:38.668+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 2.850721 ms
[2025-11-30T10:00:38.670+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:38.684+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:38.701+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 67.0 (TID 43). 3105 bytes result sent to driver
[2025-11-30T10:00:38.702+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 43) in 61 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.703+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.703+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ShuffleMapStage 67 (collect at /opt/***/scripts/dq_report.py:189) finished in 0.066 s
[2025-11-30T10:00:38.704+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:38.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:38.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:38.706+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:38.706+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T10:00:38.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 10.598019 ms
[2025-11-30T10:00:38.726+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:189
[2025-11-30T10:00:38.727+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got job 44 (collect at /opt/***/scripts/dq_report.py:189) with 1 output partitions
[2025-11-30T10:00:38.727+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ResultStage 69 (collect at /opt/***/scripts/dq_report.py:189)
[2025-11-30T10:00:38.728+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-11-30T10:00:38.728+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.729+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[158] at collect at /opt/***/scripts/dq_report.py:189), which has no missing parents
[2025-11-30T10:00:38.730+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 42.1 KiB, free 433.5 MiB)
[2025-11-30T10:00:38.735+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 433.5 MiB)
[2025-11-30T10:00:38.736+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on fa0622e2494f:33599 (size: 19.1 KiB, free: 434.2 MiB)
[2025-11-30T10:00:38.737+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_62_piece0 on fa0622e2494f:33599 in memory (size: 21.1 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.737+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.738+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[158] at collect at /opt/***/scripts/dq_report.py:189) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.739+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.739+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 44) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:38.740+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_64_piece0 on fa0622e2494f:33599 in memory (size: 17.5 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.740+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 69.0 (TID 44)
[2025-11-30T10:00:38.741+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:38.742+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:38.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 9.649094 ms
[2025-11-30T10:00:38.756+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 69.0 (TID 44). 5498 bytes result sent to driver
[2025-11-30T10:00:38.757+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 44) in 20 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.758+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.758+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ResultStage 69 (collect at /opt/***/scripts/dq_report.py:189) finished in 0.029 s
[2025-11-30T10:00:38.759+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:38.759+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-11-30T10:00:38.760+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 44 finished: collect at /opt/***/scripts/dq_report.py:189, took 0.032164 s
[2025-11-30T10:00:38.762+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:38,761 - INFO - Computing pairwise Pearson correlations between pollutants...
[2025-11-30T10:00:38.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:38.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:38.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:38.832+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 9.964502 ms
[2025-11-30T10:00:38.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 207.3 KiB, free 433.4 MiB)
[2025-11-30T10:00:38.839+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.4 MiB)
[2025-11-30T10:00:38.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:38.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 66 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:38.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:38.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Registering RDD 162 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 23
[2025-11-30T10:00:38.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got map stage job 45 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:38.846+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:38.847+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:38.847+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.848+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[162] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:38.848+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 33.9 KiB, free 433.4 MiB)
[2025-11-30T10:00:38.849+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.3 MiB)
[2025-11-30T10:00:38.850+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:38.851+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.851+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[162] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.852+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.853+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 45) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:38.854+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 70.0 (TID 45)
[2025-11-30T10:00:38.863+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 9.781322 ms
[2025-11-30T10:00:38.865+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:38.882+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:38.895+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 70.0 (TID 45). 2136 bytes result sent to driver
[2025-11-30T10:00:38.897+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 45) in 47 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.897+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.898+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ShuffleMapStage 70 (corr at NativeMethodAccessorImpl.java:0) finished in 0.052 s
[2025-11-30T10:00:38.899+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:38.899+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:38.900+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:38.901+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:38.916+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 7.456213 ms
[2025-11-30T10:00:38.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:38.924+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Got job 46 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:38.925+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Final stage: ResultStage 72 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:38.925+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-11-30T10:00:38.926+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:38.929+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[165] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:38.929+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 22.2 KiB, free 433.3 MiB)
[2025-11-30T10:00:38.931+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.3 MiB)
[2025-11-30T10:00:38.932+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:38.933+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_67_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:38.933+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:38.934+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[165] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:38.934+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-11-30T10:00:38.935+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 46) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:38.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO BlockManagerInfo: Removed broadcast_65_piece0 on fa0622e2494f:33599 in memory (size: 19.1 KiB, free: 434.3 MiB)
[2025-11-30T10:00:38.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Running task 0.0 in stage 72.0 (TID 46)
[2025-11-30T10:00:38.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:38.938+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:38.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 6.347629 ms
[2025-11-30T10:00:38.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO Executor: Finished task 0.0 in stage 72.0 (TID 46). 3989 bytes result sent to driver
[2025-11-30T10:00:38.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 46) in 12 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:38.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-11-30T10:00:38.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: ResultStage 72 (corr at NativeMethodAccessorImpl.java:0) finished in 0.020 s
[2025-11-30T10:00:38.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:38.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-11-30T10:00:38.948+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DAGScheduler: Job 46 finished: corr at NativeMethodAccessorImpl.java:0, took 0.023292 s
[2025-11-30T10:00:38.957+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO CodeGenerator: Code generated in 3.309683 ms
[2025-11-30T10:00:38.980+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:38.981+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:38.981+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:38 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.002+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.007+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.008+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.008+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 69 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.009+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.012+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 169 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 24
[2025-11-30T10:00:39.013+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 47 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.013+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 73 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.014+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.015+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.016+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[169] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.017+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 33.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.017+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.018+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.019+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.019+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[169] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.020+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.020+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 47) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.021+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 73.0 (TID 47)
[2025-11-30T10:00:39.022+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.033+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.053+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 73.0 (TID 47). 2222 bytes result sent to driver
[2025-11-30T10:00:39.054+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 47) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.055+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 73 (corr at NativeMethodAccessorImpl.java:0) finished in 0.041 s
[2025-11-30T10:00:39.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_66_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_68_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.070+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.071+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 48 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.072+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 75 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.073+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
[2025-11-30T10:00:39.074+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.074+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[172] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.075+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.076+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.077+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.078+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.079+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[172] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.079+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.080+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 48) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.081+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 75.0 (TID 48)
[2025-11-30T10:00:39.082+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.082+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 75.0 (TID 48). 3989 bytes result sent to driver
[2025-11-30T10:00:39.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 48) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.084+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.085+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 75 (corr at NativeMethodAccessorImpl.java:0) finished in 0.009 s
[2025-11-30T10:00:39.085+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.086+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
[2025-11-30T10:00:39.087+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 48 finished: corr at NativeMethodAccessorImpl.java:0, took 0.010692 s
[2025-11-30T10:00:39.102+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.103+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.103+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.122+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.128+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.129+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.130+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 72 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.130+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.132+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 176 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 25
[2025-11-30T10:00:39.133+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 49 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 76 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[176] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.137+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 33.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.139+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.139+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.140+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_69_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.141+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.141+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[176] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.142+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.143+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_71_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.144+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 49) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.144+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 76.0 (TID 49)
[2025-11-30T10:00:39.145+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_70_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.145+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.154+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.164+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 76.0 (TID 49). 2136 bytes result sent to driver
[2025-11-30T10:00:39.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 49) in 25 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 76 (corr at NativeMethodAccessorImpl.java:0) finished in 0.032 s
[2025-11-30T10:00:39.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.167+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.167+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.167+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.181+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.181+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 50 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.183+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 78 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.183+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
[2025-11-30T10:00:39.184+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.184+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[179] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.185+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.185+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.186+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[179] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 50) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.187+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 78.0 (TID 50)
[2025-11-30T10:00:39.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 78.0 (TID 50). 3989 bytes result sent to driver
[2025-11-30T10:00:39.188+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 50) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 78 (corr at NativeMethodAccessorImpl.java:0) finished in 0.006 s
[2025-11-30T10:00:39.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
[2025-11-30T10:00:39.190+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 50 finished: corr at NativeMethodAccessorImpl.java:0, took 0.007995 s
[2025-11-30T10:00:39.210+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.211+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.211+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.228+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.234+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_74_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.235+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_73_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.236+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_72_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.237+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 433.5 MiB)
[2025-11-30T10:00:39.238+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on fa0622e2494f:33599 (size: 35.0 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.238+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 75 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.241+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.241+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 183 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 26
[2025-11-30T10:00:39.242+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 51 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.243+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.243+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.244+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.244+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[183] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 33.9 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.246+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.246+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.247+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[183] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.247+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.248+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 51) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.248+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 79.0 (TID 51)
[2025-11-30T10:00:39.249+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.258+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.268+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 79.0 (TID 51). 2136 bytes result sent to driver
[2025-11-30T10:00:39.269+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 51) in 24 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.270+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.270+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 79 (corr at NativeMethodAccessorImpl.java:0) finished in 0.028 s
[2025-11-30T10:00:39.271+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.271+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.272+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.272+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.284+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.285+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 52 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.285+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 81 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
[2025-11-30T10:00:39.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[186] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.287+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.288+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.288+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.289+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.290+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[186] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.290+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.291+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 52) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.293+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 81.0 (TID 52)
[2025-11-30T10:00:39.294+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.295+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.296+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 81.0 (TID 52). 4032 bytes result sent to driver
[2025-11-30T10:00:39.297+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_76_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.297+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 52) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.298+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.298+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 81 (corr at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T10:00:39.298+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.299+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-11-30T10:00:39.300+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 52 finished: corr at NativeMethodAccessorImpl.java:0, took 0.013394 s
[2025-11-30T10:00:39.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.344+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.351+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.352+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.353+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 78 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.353+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.356+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 190 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 27
[2025-11-30T10:00:39.357+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 53 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.357+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.358+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.358+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.359+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[190] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.360+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 33.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.360+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[190] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.363+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 53) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 82.0 (TID 53)
[2025-11-30T10:00:39.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.375+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.387+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 82.0 (TID 53). 2136 bytes result sent to driver
[2025-11-30T10:00:39.387+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 53) in 27 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.388+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.389+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 82 (corr at NativeMethodAccessorImpl.java:0) finished in 0.031 s
[2025-11-30T10:00:39.389+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.390+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.390+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.391+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.408+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.409+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 54 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.409+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 84 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.410+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
[2025-11-30T10:00:39.411+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.412+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[193] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.412+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.413+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.413+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.414+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.414+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[193] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.415+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.415+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 54) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.416+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 84.0 (TID 54)
[2025-11-30T10:00:39.416+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.417+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.417+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 84.0 (TID 54). 3989 bytes result sent to driver
[2025-11-30T10:00:39.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 54) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.419+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 84 (corr at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:39.419+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.420+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
[2025-11-30T10:00:39.420+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 54 finished: corr at NativeMethodAccessorImpl.java:0, took 0.009543 s
[2025-11-30T10:00:39.437+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.438+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.438+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.461+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:39.467+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 432.9 MiB)
[2025-11-30T10:00:39.468+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on fa0622e2494f:33599 (size: 35.0 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.469+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 81 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.469+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.471+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 197 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 28
[2025-11-30T10:00:39.472+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 55 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.473+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.473+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.474+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.474+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[197] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.475+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 33.9 KiB, free 432.8 MiB)
[2025-11-30T10:00:39.475+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 432.8 MiB)
[2025-11-30T10:00:39.476+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on fa0622e2494f:33599 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.476+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.476+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[197] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.477+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.477+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 55) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.478+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 85.0 (TID 55)
[2025-11-30T10:00:39.478+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.493+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.507+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 85.0 (TID 55). 2222 bytes result sent to driver
[2025-11-30T10:00:39.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_80_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.510+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 55) in 32 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 85 (corr at NativeMethodAccessorImpl.java:0) finished in 0.036 s
[2025-11-30T10:00:39.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.515+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.516+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.517+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_75_piece0 on fa0622e2494f:33599 in memory (size: 35.0 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.518+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_78_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.519+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_77_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_79_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.523+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.530+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 56 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.532+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 87 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.533+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
[2025-11-30T10:00:39.534+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.535+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[200] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.536+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.536+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.537+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.538+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.538+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[200] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.539+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.540+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 56) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.540+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 87.0 (TID 56)
[2025-11-30T10:00:39.541+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.541+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.542+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 87.0 (TID 56). 3989 bytes result sent to driver
[2025-11-30T10:00:39.543+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 56) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.543+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.544+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 87 (corr at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:39.544+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.545+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
[2025-11-30T10:00:39.546+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 56 finished: corr at NativeMethodAccessorImpl.java:0, took 0.009840 s
[2025-11-30T10:00:39.550+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.551+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.552+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.575+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO CodeGenerator: Code generated in 10.807389 ms
[2025-11-30T10:00:39.577+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.583+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.583+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 84 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.585+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.587+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 204 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 29
[2025-11-30T10:00:39.588+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 57 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.589+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 88 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.589+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.590+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.591+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[204] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.592+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.592+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.593+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.593+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.594+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[204] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.594+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.595+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 57) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.596+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 88.0 (TID 57)
[2025-11-30T10:00:39.603+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO CodeGenerator: Code generated in 7.162983 ms
[2025-11-30T10:00:39.604+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.615+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.626+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 88.0 (TID 57). 2136 bytes result sent to driver
[2025-11-30T10:00:39.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 57) in 34 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.628+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 88 (corr at NativeMethodAccessorImpl.java:0) finished in 0.039 s
[2025-11-30T10:00:39.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.630+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.630+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.640+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.641+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 58 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.642+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 90 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.642+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
[2025-11-30T10:00:39.643+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[207] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.645+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.646+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.646+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.647+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[207] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.647+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.648+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 58) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.650+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 90.0 (TID 58)
[2025-11-30T10:00:39.650+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.651+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.652+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 90.0 (TID 58). 3989 bytes result sent to driver
[2025-11-30T10:00:39.653+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 58) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.654+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.655+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 90 (corr at NativeMethodAccessorImpl.java:0) finished in 0.007 s
[2025-11-30T10:00:39.655+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.656+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
[2025-11-30T10:00:39.656+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 58 finished: corr at NativeMethodAccessorImpl.java:0, took 0.008673 s
[2025-11-30T10:00:39.671+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.672+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.673+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.689+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:39.696+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_81_piece0 on fa0622e2494f:33599 in memory (size: 35.0 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.697+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_83_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.698+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_86_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.699+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_82_piece0 on fa0622e2494f:33599 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.700+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.700+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.701+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_85_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.702+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 87 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.702+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.703+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_84_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.704+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 211 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 30
[2025-11-30T10:00:39.704+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 59 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.706+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.707+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[211] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.707+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.708+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.708+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.709+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.709+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[211] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.710+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.710+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 59) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.711+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 91.0 (TID 59)
[2025-11-30T10:00:39.712+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.730+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 91.0 (TID 59). 2136 bytes result sent to driver
[2025-11-30T10:00:39.730+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 59) in 24 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.731+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.731+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 91 (corr at NativeMethodAccessorImpl.java:0) finished in 0.026 s
[2025-11-30T10:00:39.732+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.732+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.732+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.733+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.743+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.744+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 60 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.744+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 93 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.745+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
[2025-11-30T10:00:39.746+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.746+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[214] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.747+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.749+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[214] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 60) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 93.0 (TID 60)
[2025-11-30T10:00:39.752+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 93.0 (TID 60). 3989 bytes result sent to driver
[2025-11-30T10:00:39.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 60) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 93 (corr at NativeMethodAccessorImpl.java:0) finished in 0.007 s
[2025-11-30T10:00:39.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
[2025-11-30T10:00:39.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 60 finished: corr at NativeMethodAccessorImpl.java:0, took 0.008522 s
[2025-11-30T10:00:39.767+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.768+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.769+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.781+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.787+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.787+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.788+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 90 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.789+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.790+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 218 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 31
[2025-11-30T10:00:39.791+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 61 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.792+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.793+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[218] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.794+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.795+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.796+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.797+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.797+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[218] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.798+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.798+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 61) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.799+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 94.0 (TID 61)
[2025-11-30T10:00:39.799+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.807+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.817+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 94.0 (TID 61). 2136 bytes result sent to driver
[2025-11-30T10:00:39.818+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 61) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.818+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.819+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 94 (corr at NativeMethodAccessorImpl.java:0) finished in 0.027 s
[2025-11-30T10:00:39.820+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.820+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.821+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.822+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.832+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 62 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 96 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
[2025-11-30T10:00:39.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[221] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.839+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.839+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_88_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[221] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_89_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 62) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.842+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 96.0 (TID 62)
[2025-11-30T10:00:39.842+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_87_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.842+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_91_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.844+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 96.0 (TID 62). 3989 bytes result sent to driver
[2025-11-30T10:00:39.844+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 62) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 96 (corr at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T10:00:39.846+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.846+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
[2025-11-30T10:00:39.846+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 62 finished: corr at NativeMethodAccessorImpl.java:0, took 0.013321 s
[2025-11-30T10:00:39.859+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.860+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.861+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.873+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.878+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.879+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.880+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 93 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.881+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:39.883+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 225 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 32
[2025-11-30T10:00:39.883+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got map stage job 63 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.884+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ShuffleMapStage 97 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:39.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.886+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[225] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.886+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T10:00:39.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.888+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.888+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[225] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.889+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.890+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 63) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:39.890+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 97.0 (TID 63)
[2025-11-30T10:00:39.891+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:39.901+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:39.920+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 97.0 (TID 63). 2136 bytes result sent to driver
[2025-11-30T10:00:39.921+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 63) in 34 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ShuffleMapStage 97 (corr at NativeMethodAccessorImpl.java:0) finished in 0.037 s
[2025-11-30T10:00:39.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:39.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:39.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:39.924+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:39.924+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.935+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Got job 64 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:39.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Final stage: ResultStage 99 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:39.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
[2025-11-30T10:00:39.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:39.938+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[228] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:39.938+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.939+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:39.940+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.940+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:39.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[228] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:39.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-11-30T10:00:39.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 64) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:39.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Running task 0.0 in stage 99.0 (TID 64)
[2025-11-30T10:00:39.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:39.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:39.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO Executor: Finished task 0.0 in stage 99.0 (TID 64). 3989 bytes result sent to driver
[2025-11-30T10:00:39.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 64) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:39.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-11-30T10:00:39.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: ResultStage 99 (corr at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:39.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:39.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
[2025-11-30T10:00:39.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Job 64 finished: corr at NativeMethodAccessorImpl.java:0, took 0.010139 s
[2025-11-30T10:00:39.959+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:39.960+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:39.961+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:39.982+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO CodeGenerator: Code generated in 9.607275 ms
[2025-11-30T10:00:39.983+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:39.990+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_90_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.991+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_92_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:39.992+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_94_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.993+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_93_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.994+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.4 MiB)
[2025-11-30T10:00:39.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Removed broadcast_95_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:39.995+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO SparkContext: Created broadcast 96 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:39.997+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.000+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:39 INFO DAGScheduler: Registering RDD 232 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 33
[2025-11-30T10:00:40.001+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 65 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.001+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.002+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.003+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.003+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[232] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.004+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.005+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.005+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.006+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.006+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[232] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.007+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.007+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 65) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.008+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 100.0 (TID 65)
[2025-11-30T10:00:40.013+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO CodeGenerator: Code generated in 7.975152 ms
[2025-11-30T10:00:40.014+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.026+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.040+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 100.0 (TID 65). 2136 bytes result sent to driver
[2025-11-30T10:00:40.041+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 65) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.041+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.042+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 100 (corr at NativeMethodAccessorImpl.java:0) finished in 0.041 s
[2025-11-30T10:00:40.042+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.043+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.044+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.054+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.055+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 66 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 102 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.056+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
[2025-11-30T10:00:40.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.057+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[235] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.058+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.059+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[235] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.060+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 66) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.061+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 102.0 (TID 66)
[2025-11-30T10:00:40.062+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.062+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.063+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 102.0 (TID 66). 3989 bytes result sent to driver
[2025-11-30T10:00:40.064+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 66) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.065+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 102 (corr at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:40.066+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.067+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
[2025-11-30T10:00:40.068+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 66 finished: corr at NativeMethodAccessorImpl.java:0, took 0.010236 s
[2025-11-30T10:00:40.082+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.083+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.098+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.103+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.104+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.105+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 99 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.105+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.107+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 239 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 34
[2025-11-30T10:00:40.107+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 67 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.108+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 103 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.109+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.109+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.110+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[239] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.110+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.111+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.111+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.112+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.112+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[239] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.113+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.113+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 67) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.114+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 103.0 (TID 67)
[2025-11-30T10:00:40.115+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.123+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.134+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 103.0 (TID 67). 2136 bytes result sent to driver
[2025-11-30T10:00:40.135+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 67) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.136+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 103 (corr at NativeMethodAccessorImpl.java:0) finished in 0.028 s
[2025-11-30T10:00:40.137+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.137+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.138+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.138+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.149+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.150+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 68 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.151+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 105 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.151+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
[2025-11-30T10:00:40.152+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.153+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[242] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.154+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.156+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.156+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.157+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_96_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.158+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.158+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[242] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.159+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.159+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_97_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.160+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 68) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.160+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 105.0 (TID 68)
[2025-11-30T10:00:40.161+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_98_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.161+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.162+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.162+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_100_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.163+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 105.0 (TID 68). 3946 bytes result sent to driver
[2025-11-30T10:00:40.163+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 68) in 3 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.164+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 105 (corr at NativeMethodAccessorImpl.java:0) finished in 0.011 s
[2025-11-30T10:00:40.165+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-11-30T10:00:40.166+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 68 finished: corr at NativeMethodAccessorImpl.java:0, took 0.011811 s
[2025-11-30T10:00:40.176+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.177+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.177+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.189+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.195+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.196+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.196+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 102 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.196+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.199+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 246 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 35
[2025-11-30T10:00:40.200+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 69 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.200+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 106 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.201+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.201+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.202+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[246] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.202+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.203+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.204+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[246] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.205+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.205+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 69) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.206+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 106.0 (TID 69)
[2025-11-30T10:00:40.206+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.213+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.222+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 106.0 (TID 69). 2136 bytes result sent to driver
[2025-11-30T10:00:40.222+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 69) in 20 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.223+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.224+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 106 (corr at NativeMethodAccessorImpl.java:0) finished in 0.022 s
[2025-11-30T10:00:40.224+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.224+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.225+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.225+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.234+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.235+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 70 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.235+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 108 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.236+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
[2025-11-30T10:00:40.236+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.237+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[249] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.237+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.238+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.238+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.239+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.240+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[249] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.241+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.241+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 70) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.242+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 108.0 (TID 70)
[2025-11-30T10:00:40.242+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.243+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.243+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 108.0 (TID 70). 3989 bytes result sent to driver
[2025-11-30T10:00:40.244+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 70) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.244+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 108 (corr at NativeMethodAccessorImpl.java:0) finished in 0.006 s
[2025-11-30T10:00:40.245+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.246+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished
[2025-11-30T10:00:40.247+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 70 finished: corr at NativeMethodAccessorImpl.java:0, took 0.007769 s
[2025-11-30T10:00:40.255+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.256+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.257+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.270+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:40.277+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_103_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.278+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_104_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.279+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.0 MiB)
[2025-11-30T10:00:40.280+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.280+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_102_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.281+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 105 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.281+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.281+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_101_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.282+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_99_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.282+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 253 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 36
[2025-11-30T10:00:40.283+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 71 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.283+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 109 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.283+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.284+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.284+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[253] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.285+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.285+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.286+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.287+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[253] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.287+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.288+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 71) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.289+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 109.0 (TID 71)
[2025-11-30T10:00:40.289+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.296+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.305+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 109.0 (TID 71). 2136 bytes result sent to driver
[2025-11-30T10:00:40.306+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 71) in 20 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.306+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.307+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 109 (corr at NativeMethodAccessorImpl.java:0) finished in 0.022 s
[2025-11-30T10:00:40.307+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.308+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.308+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.309+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.318+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.319+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 72 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.319+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 111 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.320+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
[2025-11-30T10:00:40.320+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[256] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.321+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.322+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.323+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.324+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[256] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.324+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.324+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 72) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.325+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 111.0 (TID 72)
[2025-11-30T10:00:40.326+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.326+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.327+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 111.0 (TID 72). 3946 bytes result sent to driver
[2025-11-30T10:00:40.327+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 72) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.328+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.328+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 111 (corr at NativeMethodAccessorImpl.java:0) finished in 0.008 s
[2025-11-30T10:00:40.328+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.329+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
[2025-11-30T10:00:40.329+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 72 finished: corr at NativeMethodAccessorImpl.java:0, took 0.009864 s
[2025-11-30T10:00:40.341+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.342+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.343+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.355+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.361+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 108 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.362+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.364+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 260 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-11-30T10:00:40.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 73 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.365+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 112 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.366+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.366+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[260] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.367+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.368+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.369+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[260] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.370+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 73) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 112.0 (TID 73)
[2025-11-30T10:00:40.371+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.380+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.392+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 112.0 (TID 73). 2136 bytes result sent to driver
[2025-11-30T10:00:40.393+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 73) in 24 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.394+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.395+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 112 (corr at NativeMethodAccessorImpl.java:0) finished in 0.028 s
[2025-11-30T10:00:40.396+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.396+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.397+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.398+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.405+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.407+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 74 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.408+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 114 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.410+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
[2025-11-30T10:00:40.411+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.412+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[263] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.413+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.413+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.414+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.414+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_109_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.415+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.416+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[263] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.416+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.417+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 74) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_106_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.418+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 114.0 (TID 74)
[2025-11-30T10:00:40.419+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_107_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.420+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.421+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.422+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_105_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.422+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 114.0 (TID 74). 3989 bytes result sent to driver
[2025-11-30T10:00:40.423+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 74) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.424+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.425+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 114 (corr at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T10:00:40.426+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.426+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
[2025-11-30T10:00:40.427+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 74 finished: corr at NativeMethodAccessorImpl.java:0, took 0.013185 s
[2025-11-30T10:00:40.433+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.434+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.434+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.446+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.451+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.452+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.452+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 111 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.453+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.455+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 267 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-11-30T10:00:40.455+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 75 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.456+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 115 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.457+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.457+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.458+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[267] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.458+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.459+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.460+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.460+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.461+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[267] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.462+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.462+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 75) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.463+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 115.0 (TID 75)
[2025-11-30T10:00:40.464+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.472+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.485+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 115.0 (TID 75). 2136 bytes result sent to driver
[2025-11-30T10:00:40.486+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 75) in 28 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.487+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.487+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 115 (corr at NativeMethodAccessorImpl.java:0) finished in 0.031 s
[2025-11-30T10:00:40.487+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.488+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.488+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.488+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.499+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T10:00:40.499+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 76 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T10:00:40.500+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 117 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T10:00:40.501+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-11-30T10:00:40.502+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.502+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[270] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:40.503+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.504+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.505+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.506+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.507+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[270] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.508+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.509+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 76) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.509+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 117.0 (TID 76)
[2025-11-30T10:00:40.511+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 117.0 (TID 76). 3946 bytes result sent to driver
[2025-11-30T10:00:40.512+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 76) in 3 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 117 (corr at NativeMethodAccessorImpl.java:0) finished in 0.006 s
[2025-11-30T10:00:40.513+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-11-30T10:00:40.514+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 76 finished: corr at NativeMethodAccessorImpl.java:0, took 0.007180 s
[2025-11-30T10:00:40.520+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.521+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.532+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:40.539+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_108_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.541+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_113_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.542+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.543+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.543+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_111_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.544+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 114 from corr at <unknown>:0
[2025-11-30T10:00:40.545+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_110_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.545+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.546+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_112_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.546+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 274 (corr at <unknown>:0) as input to shuffle 39
[2025-11-30T10:00:40.547+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 77 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.547+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 118 (corr at <unknown>:0)
[2025-11-30T10:00:40.548+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.549+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.549+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[274] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.550+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.551+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.551+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.552+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.552+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[274] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.553+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.553+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 77) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.554+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 118.0 (TID 77)
[2025-11-30T10:00:40.554+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.561+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.570+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 118.0 (TID 77). 2136 bytes result sent to driver
[2025-11-30T10:00:40.570+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 77) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.571+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.572+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 118 (corr at <unknown>:0) finished in 0.025 s
[2025-11-30T10:00:40.572+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.573+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.573+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.574+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.582+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T10:00:40.582+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 78 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.583+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 120 (corr at <unknown>:0)
[2025-11-30T10:00:40.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
[2025-11-30T10:00:40.584+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.585+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[277] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.585+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.589+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.589+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.590+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.590+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[277] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.591+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.591+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 78) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.593+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 120.0 (TID 78)
[2025-11-30T10:00:40.594+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.594+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.595+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 120.0 (TID 78). 3946 bytes result sent to driver
[2025-11-30T10:00:40.595+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 78) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.596+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.596+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 120 (corr at <unknown>:0) finished in 0.007 s
[2025-11-30T10:00:40.597+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.597+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-11-30T10:00:40.598+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 78 finished: corr at <unknown>:0, took 0.008124 s
[2025-11-30T10:00:40.604+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.605+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.620+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.625+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.626+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 117 from corr at <unknown>:0
[2025-11-30T10:00:40.627+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 281 (corr at <unknown>:0) as input to shuffle 40
[2025-11-30T10:00:40.629+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 79 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.630+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 121 (corr at <unknown>:0)
[2025-11-30T10:00:40.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.631+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.632+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[281] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.633+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.634+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.634+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.635+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.636+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[281] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.636+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.637+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 79) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.637+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 121.0 (TID 79)
[2025-11-30T10:00:40.638+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.644+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.659+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 121.0 (TID 79). 2222 bytes result sent to driver
[2025-11-30T10:00:40.660+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_116_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.660+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 79) in 27 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.661+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.662+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 121 (corr at <unknown>:0) finished in 0.030 s
[2025-11-30T10:00:40.662+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.663+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.663+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.664+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.665+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_114_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.665+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_115_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.671+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T10:00:40.672+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 80 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.672+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 123 (corr at <unknown>:0)
[2025-11-30T10:00:40.673+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
[2025-11-30T10:00:40.674+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.674+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[284] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.675+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.676+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.676+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.677+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.677+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[284] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.678+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.679+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 80) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.679+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 123.0 (TID 80)
[2025-11-30T10:00:40.680+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.681+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.681+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 123.0 (TID 80). 3989 bytes result sent to driver
[2025-11-30T10:00:40.682+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 80) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.682+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.682+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 123 (corr at <unknown>:0) finished in 0.006 s
[2025-11-30T10:00:40.683+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.683+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished
[2025-11-30T10:00:40.684+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 80 finished: corr at <unknown>:0, took 0.007578 s
[2025-11-30T10:00:40.692+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.693+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.693+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.705+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.711+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.711+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.712+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 120 from corr at <unknown>:0
[2025-11-30T10:00:40.713+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.714+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 288 (corr at <unknown>:0) as input to shuffle 41
[2025-11-30T10:00:40.715+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 81 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.715+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (corr at <unknown>:0)
[2025-11-30T10:00:40.716+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.716+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.717+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[288] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.718+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.719+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.719+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.720+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[288] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.720+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.720+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 81) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.721+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 124.0 (TID 81)
[2025-11-30T10:00:40.721+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.730+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.738+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 124.0 (TID 81). 2136 bytes result sent to driver
[2025-11-30T10:00:40.739+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 81) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.739+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.740+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 124 (corr at <unknown>:0) finished in 0.024 s
[2025-11-30T10:00:40.740+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.740+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.741+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.741+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T10:00:40.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 82 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.751+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 126 (corr at <unknown>:0)
[2025-11-30T10:00:40.752+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
[2025-11-30T10:00:40.752+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.752+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[291] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.753+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.754+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[291] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.755+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 82) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.756+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 126.0 (TID 82)
[2025-11-30T10:00:40.756+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.757+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.761+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 126.0 (TID 82). 4075 bytes result sent to driver
[2025-11-30T10:00:40.761+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 82) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.762+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_119_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.762+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.763+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 126 (corr at <unknown>:0) finished in 0.011 s
[2025-11-30T10:00:40.763+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.764+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
[2025-11-30T10:00:40.764+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 82 finished: corr at <unknown>:0, took 0.012356 s
[2025-11-30T10:00:40.765+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_121_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.765+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_118_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.766+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_117_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.776+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.777+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.778+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.789+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.795+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.795+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.796+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 123 from corr at <unknown>:0
[2025-11-30T10:00:40.797+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.799+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 295 (corr at <unknown>:0) as input to shuffle 42
[2025-11-30T10:00:40.800+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 83 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.800+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 127 (corr at <unknown>:0)
[2025-11-30T10:00:40.800+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.801+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.801+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[295] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.802+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T10:00:40.802+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.802+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.803+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.803+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[295] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.803+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.804+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 83) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.804+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 127.0 (TID 83)
[2025-11-30T10:00:40.805+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.813+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.823+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 127.0 (TID 83). 2136 bytes result sent to driver
[2025-11-30T10:00:40.823+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 83) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.824+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.824+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 127 (corr at <unknown>:0) finished in 0.023 s
[2025-11-30T10:00:40.825+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.825+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.826+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T10:00:40.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 84 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.838+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 129 (corr at <unknown>:0)
[2025-11-30T10:00:40.838+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
[2025-11-30T10:00:40.839+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.839+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[298] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.840+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T10:00:40.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.841+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.842+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[298] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.842+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 84) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 129.0 (TID 84)
[2025-11-30T10:00:40.843+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.844+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.844+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 129.0 (TID 84). 3989 bytes result sent to driver
[2025-11-30T10:00:40.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 84) in 4 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.845+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.846+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 129 (corr at <unknown>:0) finished in 0.007 s
[2025-11-30T10:00:40.847+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.847+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-11-30T10:00:40.848+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 84 finished: corr at <unknown>:0, took 0.009173 s
[2025-11-30T10:00:40.860+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T10:00:40.861+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T10:00:40.862+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T10:00:40.873+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T10:00:40.879+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 432.9 MiB)
[2025-11-30T10:00:40.880+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on fa0622e2494f:33599 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.881+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 126 from corr at <unknown>:0
[2025-11-30T10:00:40.881+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 8394309 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T10:00:40.883+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Registering RDD 302 (corr at <unknown>:0) as input to shuffle 43
[2025-11-30T10:00:40.884+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got map stage job 85 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.884+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ShuffleMapStage 130 (corr at <unknown>:0)
[2025-11-30T10:00:40.885+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:40.886+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.887+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[302] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.889+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 33.0 KiB, free 432.8 MiB)
[2025-11-30T10:00:40.892+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 432.9 MiB)
[2025-11-30T10:00:40.893+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_125_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.894+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on fa0622e2494f:33599 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.896+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.896+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_122_piece0 on fa0622e2494f:33599 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.897+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[302] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.898+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.899+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_120_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.899+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 85) (fa0622e2494f, executor driver, partition 0, ANY, 8542 bytes)
[2025-11-30T10:00:40.900+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 130.0 (TID 85)
[2025-11-30T10:00:40.901+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_124_piece0 on fa0622e2494f:33599 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.903+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-08d72811-3369-46f0-8849-052f83573f35.c000.snappy.parquet, range: 0-2969, partition values: [2025,11,30]
[2025-11-30T10:00:40.904+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Removed broadcast_123_piece0 on fa0622e2494f:33599 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T10:00:40.908+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T10:00:40.921+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 130.0 (TID 85). 2136 bytes result sent to driver
[2025-11-30T10:00:40.922+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 85) in 28 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.923+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.924+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ShuffleMapStage 130 (corr at <unknown>:0) finished in 0.040 s
[2025-11-30T10:00:40.924+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T10:00:40.925+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: running: Set()
[2025-11-30T10:00:40.926+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: waiting: Set()
[2025-11-30T10:00:40.926+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: failed: Set()
[2025-11-30T10:00:40.936+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T10:00:40.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Got job 86 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T10:00:40.937+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Final stage: ResultStage 132 (corr at <unknown>:0)
[2025-11-30T10:00:40.938+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
[2025-11-30T10:00:40.939+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:40.939+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[305] at corr at <unknown>:0), which has no missing parents
[2025-11-30T10:00:40.940+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T10:00:40.941+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on fa0622e2494f:33599 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T10:00:40.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:40.942+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[305] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:40.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0
[2025-11-30T10:00:40.943+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 86) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T10:00:40.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Running task 0.0 in stage 132.0 (TID 86)
[2025-11-30T10:00:40.944+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T10:00:40.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T10:00:40.945+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO Executor: Finished task 0.0 in stage 132.0 (TID 86). 3989 bytes result sent to driver
[2025-11-30T10:00:40.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 86) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:40.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool
[2025-11-30T10:00:40.946+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: ResultStage 132 (corr at <unknown>:0) finished in 0.008 s
[2025-11-30T10:00:40.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:40.947+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished
[2025-11-30T10:00:40.948+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO DAGScheduler: Job 86 finished: corr at <unknown>:0, took 0.009227 s
[2025-11-30T10:00:40.948+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:40,946 - INFO - Writing report to: hdfs://hadoop-namenode:9000/reports/data-quality/2025/11/30/dq_report.json
[2025-11-30T10:00:40.954+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:40,953 - INFO - Existing report folder found  deleting before overwrite
[2025-11-30T10:00:40.998+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[2025-11-30T10:00:41.000+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:40 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-11-30T10:00:41.001+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-11-30T10:00:41.003+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-11-30T10:00:41.015+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-11-30T10:00:41.016+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Got job 87 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-11-30T10:00:41.017+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Final stage: ResultStage 133 (runJob at SparkHadoopWriter.scala:83)
[2025-11-30T10:00:41.017+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T10:00:41.018+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Missing parents: List()
[2025-11-30T10:00:41.018+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[309] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T10:00:41.026+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 104.4 KiB, free 433.3 MiB)
[2025-11-30T10:00:41.026+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 38.4 KiB, free 433.2 MiB)
[2025-11-30T10:00:41.027+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on fa0622e2494f:33599 (size: 38.4 KiB, free: 434.2 MiB)
[2025-11-30T10:00:41.028+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1580
[2025-11-30T10:00:41.028+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[309] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T10:00:41.029+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
[2025-11-30T10:00:41.029+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 87) (fa0622e2494f, executor driver, partition 0, PROCESS_LOCAL, 10422 bytes)
[2025-11-30T10:00:41.030+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO Executor: Running task 0.0 in stage 133.0 (TID 87)
[2025-11-30T10:00:41.614+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-11-30T10:00:41.616+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-11-30T10:00:41.617+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-11-30T10:00:41.695+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO PythonRunner: Times: total = 650, boot = 565, init = 85, finish = 0
[2025-11-30T10:00:41.744+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO FileOutputCommitter: Saved output of task 'attempt_202511301000403268945667380061257_0309_m_000000_0' to hdfs://hadoop-namenode:9000/reports/data-quality/2025/11/30/_temporary/0/task_202511301000403268945667380061257_0309_m_000000
[2025-11-30T10:00:41.745+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkHadoopMapRedUtil: attempt_202511301000403268945667380061257_0309_m_000000_0: Committed. Elapsed time: 6 ms.
[2025-11-30T10:00:41.746+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO Executor: Finished task 0.0 in stage 133.0 (TID 87). 1620 bytes result sent to driver
[2025-11-30T10:00:41.747+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 87) in 720 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T10:00:41.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-11-30T10:00:41.748+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 42041
[2025-11-30T10:00:41.749+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: ResultStage 133 (runJob at SparkHadoopWriter.scala:83) finished in 0.732 s
[2025-11-30T10:00:41.749+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T10:00:41.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
[2025-11-30T10:00:41.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO DAGScheduler: Job 87 finished: runJob at SparkHadoopWriter.scala:83, took 0.696248 s
[2025-11-30T10:00:41.750+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkHadoopWriter: Start to commit write Job job_202511301000403268945667380061257_0309.
[2025-11-30T10:00:41.764+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkHadoopWriter: Write Job job_202511301000403268945667380061257_0309 committed. Elapsed time: 13 ms.
[2025-11-30T10:00:41.764+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO -  Data quality report written successfully
[2025-11-30T10:00:41.765+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO - ================================================================================
[2025-11-30T10:00:41.765+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO - DATA QUALITY REPORT (JSON)
[2025-11-30T10:00:41.765+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO - ================================================================================
[2025-11-30T10:00:41.766+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO - {
[2025-11-30T10:00:41.766+0000] {spark_submit.py:649} INFO - "report_date": "2025-11-30",
[2025-11-30T10:00:41.767+0000] {spark_submit.py:649} INFO - "report_timestamp": "2025-11-30T10:00:38.761882",
[2025-11-30T10:00:41.767+0000] {spark_submit.py:649} INFO - "summary": {
[2025-11-30T10:00:41.767+0000] {spark_submit.py:649} INFO - "total_records": 39,
[2025-11-30T10:00:41.768+0000] {spark_submit.py:649} INFO - "unique_records": 34,
[2025-11-30T10:00:41.768+0000] {spark_submit.py:649} INFO - "duplicate_records": 5,
[2025-11-30T10:00:41.769+0000] {spark_submit.py:649} INFO - "duplicate_ratio_percent": 12.82,
[2025-11-30T10:00:41.769+0000] {spark_submit.py:649} INFO - "null_columns": {
[2025-11-30T10:00:41.769+0000] {spark_submit.py:649} INFO - "city": {
[2025-11-30T10:00:41.770+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.770+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.770+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.771+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T10:00:41.771+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.772+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.772+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.772+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T10:00:41.773+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.773+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.773+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.774+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T10:00:41.774+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.774+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.775+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.775+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T10:00:41.775+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.776+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.776+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.776+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T10:00:41.777+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.777+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.778+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.778+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T10:00:41.779+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.779+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.780+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.780+0000] {spark_submit.py:649} INFO - "so2": {
[2025-11-30T10:00:41.781+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.781+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.782+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.782+0000] {spark_submit.py:649} INFO - "timestamp_utc": {
[2025-11-30T10:00:41.782+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T10:00:41.783+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T10:00:41.783+0000] {spark_submit.py:649} INFO - }
[2025-11-30T10:00:41.783+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.784+0000] {spark_submit.py:649} INFO - "range_violations": {
[2025-11-30T10:00:41.784+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T10:00:41.784+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T10:00:41.785+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.785+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.785+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.786+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T10:00:41.786+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T10:00:41.787+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.787+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.787+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.788+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T10:00:41.788+0000] {spark_submit.py:649} INFO - "range": "[0, 600]",
[2025-11-30T10:00:41.788+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.789+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.789+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.789+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T10:00:41.790+0000] {spark_submit.py:649} INFO - "range": "[0, 10000]",
[2025-11-30T10:00:41.790+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.790+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.791+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.791+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T10:00:41.792+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T10:00:41.792+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.792+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.792+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.793+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T10:00:41.793+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T10:00:41.793+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.794+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.794+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.794+0000] {spark_submit.py:649} INFO - "so2": {
[2025-11-30T10:00:41.795+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T10:00:41.795+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T10:00:41.797+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T10:00:41.800+0000] {spark_submit.py:649} INFO - }
[2025-11-30T10:00:41.802+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.805+0000] {spark_submit.py:649} INFO - "spike_detections": 0
[2025-11-30T10:00:41.805+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.807+0000] {spark_submit.py:649} INFO - "daily_city_details": [
[2025-11-30T10:00:41.807+0000] {spark_submit.py:649} INFO - {
[2025-11-30T10:00:41.809+0000] {spark_submit.py:649} INFO - "city": "HANOI",
[2025-11-30T10:00:41.809+0000] {spark_submit.py:649} INFO - "date": "2025-11-30",
[2025-11-30T10:00:41.810+0000] {spark_submit.py:649} INFO - "n_records": 39,
[2025-11-30T10:00:41.810+0000] {spark_submit.py:649} INFO - "aqi_nulls": 0,
[2025-11-30T10:00:41.811+0000] {spark_submit.py:649} INFO - "pm25_nulls": 0,
[2025-11-30T10:00:41.812+0000] {spark_submit.py:649} INFO - "pm10_nulls": 0,
[2025-11-30T10:00:41.812+0000] {spark_submit.py:649} INFO - "aqi_out_of_range": 0,
[2025-11-30T10:00:41.813+0000] {spark_submit.py:649} INFO - "pm25_out_of_range": 0,
[2025-11-30T10:00:41.813+0000] {spark_submit.py:649} INFO - "pm10_out_of_range": 0,
[2025-11-30T10:00:41.814+0000] {spark_submit.py:649} INFO - "aqi_avg": 217.0,
[2025-11-30T10:00:41.814+0000] {spark_submit.py:649} INFO - "aqi_stddev": null,
[2025-11-30T10:00:41.814+0000] {spark_submit.py:649} INFO - "aqi_p50": 217,
[2025-11-30T10:00:41.815+0000] {spark_submit.py:649} INFO - "status": "OK"
[2025-11-30T10:00:41.816+0000] {spark_submit.py:649} INFO - }
[2025-11-30T10:00:41.816+0000] {spark_submit.py:649} INFO - ],
[2025-11-30T10:00:41.817+0000] {spark_submit.py:649} INFO - "spikes": [],
[2025-11-30T10:00:41.817+0000] {spark_submit.py:649} INFO - "correlations": {
[2025-11-30T10:00:41.818+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T10:00:41.818+0000] {spark_submit.py:649} INFO - "pm25": NaN,
[2025-11-30T10:00:41.819+0000] {spark_submit.py:649} INFO - "pm10": NaN,
[2025-11-30T10:00:41.820+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T10:00:41.820+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T10:00:41.820+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T10:00:41.821+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.821+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.822+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T10:00:41.822+0000] {spark_submit.py:649} INFO - "pm10": NaN,
[2025-11-30T10:00:41.822+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T10:00:41.823+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T10:00:41.823+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T10:00:41.824+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.824+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.825+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T10:00:41.825+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T10:00:41.826+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T10:00:41.826+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T10:00:41.827+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.827+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.828+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T10:00:41.828+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T10:00:41.828+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T10:00:41.829+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.829+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.829+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T10:00:41.830+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T10:00:41.830+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.830+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.831+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T10:00:41.831+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T10:00:41.831+0000] {spark_submit.py:649} INFO - },
[2025-11-30T10:00:41.832+0000] {spark_submit.py:649} INFO - "so2": {}
[2025-11-30T10:00:41.832+0000] {spark_submit.py:649} INFO - }
[2025-11-30T10:00:41.833+0000] {spark_submit.py:649} INFO - }
[2025-11-30T10:00:41.833+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:41,764 - INFO - ================================================================================
[2025-11-30T10:00:41.833+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-11-30T10:00:41.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkUI: Stopped Spark web UI at http://fa0622e2494f:4040
[2025-11-30T10:00:41.834+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-11-30T10:00:41.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO MemoryStore: MemoryStore cleared
[2025-11-30T10:00:41.835+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO BlockManager: BlockManager stopped
[2025-11-30T10:00:41.836+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-11-30T10:00:41.836+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-11-30T10:00:41.837+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:41 INFO SparkContext: Successfully stopped SparkContext
[2025-11-30T10:00:42.755+0000] {spark_submit.py:649} INFO - 2025-11-30 10:00:42,754 - INFO - Spark session stopped
[2025-11-30T10:00:42.785+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:42 INFO ShutdownHookManager: Shutdown hook called
[2025-11-30T10:00:42.788+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-5ec89e40-e43e-4414-8ec3-d533639a023d
[2025-11-30T10:00:42.790+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-1481e0db-8f02-4de9-b561-9e77f0fb6e8c
[2025-11-30T10:00:42.794+0000] {spark_submit.py:649} INFO - 25/11/30 10:00:42 INFO ShutdownHookManager: Deleting directory /tmp/spark-5ec89e40-e43e-4414-8ec3-d533639a023d/pyspark-3a1da459-fe2c-444e-955f-d0b86ab6cabe
[2025-11-30T10:00:42.852+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=1_hourly_cleaning_and_report, task_id=dq_report, execution_date=20251130T090000, start_date=20251130T100027, end_date=20251130T100042
[2025-11-30T10:00:42.910+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-30T10:00:42.937+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
