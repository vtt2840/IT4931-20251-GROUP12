[2025-11-30T09:30:40.957+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T08:00:00+00:00 [queued]>
[2025-11-30T09:30:40.967+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T08:00:00+00:00 [queued]>
[2025-11-30T09:30:40.968+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 2
[2025-11-30T09:30:40.983+0000] {taskinstance.py:2191} INFO - Executing <Task(SparkSubmitOperator): dq_report> on 2025-11-30 08:00:00+00:00
[2025-11-30T09:30:40.988+0000] {standard_task_runner.py:60} INFO - Started process 1268 to run task
[2025-11-30T09:30:40.991+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', '1_hourly_cleaning_and_report', 'dq_report', 'scheduled__2025-11-30T08:00:00+00:00', '--job-id', '12', '--raw', '--subdir', 'DAGS_FOLDER/hourly_etl.py', '--cfg-path', '/tmp/tmphlngkz68']
[2025-11-30T09:30:40.993+0000] {standard_task_runner.py:88} INFO - Job 12: Subtask dq_report
[2025-11-30T09:30:41.070+0000] {task_command.py:423} INFO - Running <TaskInstance: 1_hourly_cleaning_and_report.dq_report scheduled__2025-11-30T08:00:00+00:00 [running]> on host fa0622e2494f
[2025-11-30T09:30:41.169+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='group12' AIRFLOW_CTX_DAG_ID='1_hourly_cleaning_and_report' AIRFLOW_CTX_TASK_ID='dq_report' AIRFLOW_CTX_EXECUTION_DATE='2025-11-30T08:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-11-30T08:00:00+00:00'
[2025-11-30T09:30:41.171+0000] {crypto.py:82} WARNING - empty cryptography key - values will not be stored encrypted.
[2025-11-30T09:30:41.172+0000] {base.py:83} INFO - Using connection ID 'spark_default' for task execution.
[2025-11-30T09:30:41.174+0000] {spark_submit.py:473} INFO - Spark-Submit cmd: spark-submit --master local --conf spark.master=local[*] --name arrow-spark /opt/***/scripts/dq_report.py
[2025-11-30T09:30:43.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SparkContext: Running Spark version 3.5.0
[2025-11-30T09:30:43.606+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SparkContext: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-30T09:30:43.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SparkContext: Java version 17.0.17
[2025-11-30T09:30:43.659+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2025-11-30T09:30:43.737+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceUtils: ==============================================================
[2025-11-30T09:30:43.738+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceUtils: No custom resources configured for spark.driver.
[2025-11-30T09:30:43.739+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceUtils: ==============================================================
[2025-11-30T09:30:43.740+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SparkContext: Submitted application: dq-report
[2025-11-30T09:30:43.766+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2025-11-30T09:30:43.775+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceProfile: Limiting resource is cpu
[2025-11-30T09:30:43.777+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2025-11-30T09:30:43.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SecurityManager: Changing view acls to: ***
[2025-11-30T09:30:43.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SecurityManager: Changing modify acls to: ***
[2025-11-30T09:30:43.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SecurityManager: Changing view acls groups to:
[2025-11-30T09:30:43.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SecurityManager: Changing modify acls groups to:
[2025-11-30T09:30:43.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:43 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: ***; groups with view permissions: EMPTY; users with modify permissions: ***; groups with modify permissions: EMPTY
[2025-11-30T09:30:44.023+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Utils: Successfully started service 'sparkDriver' on port 41431.
[2025-11-30T09:30:44.048+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SparkEnv: Registering MapOutputTracker
[2025-11-30T09:30:44.080+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SparkEnv: Registering BlockManagerMaster
[2025-11-30T09:30:44.094+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2025-11-30T09:30:44.095+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2025-11-30T09:30:44.099+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2025-11-30T09:30:44.116+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-bd1c5f58-4ddb-4835-945f-5f0b9609b5d1
[2025-11-30T09:30:44.130+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2025-11-30T09:30:44.147+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SparkEnv: Registering OutputCommitCoordinator
[2025-11-30T09:30:44.278+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2025-11-30T09:30:44.349+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2025-11-30T09:30:44.440+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Executor: Starting executor ID driver on host fa0622e2494f
[2025-11-30T09:30:44.441+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Executor: OS info Linux, 6.6.87.2-microsoft-standard-WSL2, amd64
[2025-11-30T09:30:44.442+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Executor: Java version 17.0.17
[2025-11-30T09:30:44.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2025-11-30T09:30:44.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@aa898df for default.
[2025-11-30T09:30:44.464+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 33513.
[2025-11-30T09:30:44.465+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO NettyBlockTransferService: Server created on fa0622e2494f:33513
[2025-11-30T09:30:44.466+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2025-11-30T09:30:44.471+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, fa0622e2494f, 33513, None)
[2025-11-30T09:30:44.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManagerMasterEndpoint: Registering block manager fa0622e2494f:33513 with 434.4 MiB RAM, BlockManagerId(driver, fa0622e2494f, 33513, None)
[2025-11-30T09:30:44.476+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, fa0622e2494f, 33513, None)
[2025-11-30T09:30:44.477+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, fa0622e2494f, 33513, None)
[2025-11-30T09:30:44.782+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:44,781 - INFO - ================================================================================
[2025-11-30T09:30:44.783+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:44,782 - INFO - Starting Data Quality Report Job
[2025-11-30T09:30:44.784+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:44,782 - INFO - ================================================================================
[2025-11-30T09:30:44.785+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:44,782 - INFO - Reading cleaned data from: hdfs://hadoop-namenode:9000/clean-data/air-quality
[2025-11-30T09:30:44.846+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2025-11-30T09:30:44.852+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:44 INFO SharedState: Warehouse path is 'file:/opt/***/spark-warehouse'.
[2025-11-30T09:30:45.890+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:45 INFO InMemoryFileIndex: It took 74 ms to list leaf files for 1 paths.
[2025-11-30T09:30:46.312+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO SparkContext: Starting job: parquet at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:46.329+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Got job 0 (parquet at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:46.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Final stage: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:46.332+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:46.333+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:46.336+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:46.406+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 103.2 KiB, free 434.3 MiB)
[2025-11-30T09:30:46.434+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 37.2 KiB, free 434.3 MiB)
[2025-11-30T09:30:46.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on fa0622e2494f:33513 (size: 37.2 KiB, free: 434.4 MiB)
[2025-11-30T09:30:46.442+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:46.459+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at parquet at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:46.460+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks resource profile 0
[2025-11-30T09:30:46.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (fa0622e2494f, executor driver, partition 0, PROCESS_LOCAL, 7854 bytes)
[2025-11-30T09:30:46.528+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2025-11-30T09:30:46.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2143 bytes result sent to driver
[2025-11-30T09:30:46.866+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 371 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:46.867+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2025-11-30T09:30:46.871+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: ResultStage 0 (parquet at NativeMethodAccessorImpl.java:0) finished in 0.521 s
[2025-11-30T09:30:46.873+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:46.874+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2025-11-30T09:30:46.876+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:46 INFO DAGScheduler: Job 0 finished: parquet at NativeMethodAccessorImpl.java:0, took 0.563176 s
[2025-11-30T09:30:47.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:47 INFO BlockManagerInfo: Removed broadcast_0_piece0 on fa0622e2494f:33513 in memory (size: 37.2 KiB, free: 434.4 MiB)
[2025-11-30T09:30:47.725+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:47 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:47.727+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:47 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:47.728+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:47 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:48.088+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO CodeGenerator: Code generated in 165.5499 ms
[2025-11-30T09:30:48.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 207.1 KiB, free 434.2 MiB)
[2025-11-30T09:30:48.122+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 34.7 KiB, free 434.2 MiB)
[2025-11-30T09:30:48.123+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on fa0622e2494f:33513 (size: 34.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:48.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO SparkContext: Created broadcast 1 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:48.135+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:48.184+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Registering RDD 5 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 0
[2025-11-30T09:30:48.189+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Got map stage job 1 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:48.190+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Final stage: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:48.190+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:48.191+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:48.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:48.225+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 17.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:48.227+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 8.0 KiB, free 434.1 MiB)
[2025-11-30T09:30:48.228+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on fa0622e2494f:33513 (size: 8.0 KiB, free: 434.4 MiB)
[2025-11-30T09:30:48.229+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:48.233+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[5] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:48.233+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2025-11-30T09:30:48.240+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:48.241+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
[2025-11-30T09:30:48.309+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO CodeGenerator: Code generated in 27.811841 ms
[2025-11-30T09:30:48.318+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:48.427+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2179 bytes result sent to driver
[2025-11-30T09:30:48.430+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 194 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:48.432+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2025-11-30T09:30:48.434+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: ShuffleMapStage 1 (count at NativeMethodAccessorImpl.java:0) finished in 0.237 s
[2025-11-30T09:30:48.435+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:48.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:48.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:48.438+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:48.490+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO CodeGenerator: Code generated in 15.091916 ms
[2025-11-30T09:30:48.518+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:48.520+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO BlockManagerInfo: Removed broadcast_2_piece0 on fa0622e2494f:33513 in memory (size: 8.0 KiB, free: 434.4 MiB)
[2025-11-30T09:30:48.521+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Got job 2 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:48.522+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Final stage: ResultStage 3 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:48.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 2)
[2025-11-30T09:30:48.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:48.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:48.530+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 12.5 KiB, free 434.2 MiB)
[2025-11-30T09:30:48.532+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:48.533+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:48.534+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:48.535+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[8] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:48.536+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2025-11-30T09:30:48.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 2) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:48.540+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO Executor: Running task 0.0 in stage 3.0 (TID 2)
[2025-11-30T09:30:48.575+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:48.581+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
[2025-11-30T09:30:48.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO CodeGenerator: Code generated in 17.445538 ms
[2025-11-30T09:30:48.611+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO Executor: Finished task 0.0 in stage 3.0 (TID 2). 4038 bytes result sent to driver
[2025-11-30T09:30:48.614+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 2) in 76 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:48.615+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2025-11-30T09:30:48.617+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: ResultStage 3 (count at NativeMethodAccessorImpl.java:0) finished in 0.088 s
[2025-11-30T09:30:48.618+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:48.619+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2025-11-30T09:30:48.619+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DAGScheduler: Job 2 finished: count at NativeMethodAccessorImpl.java:0, took 0.099937 s
[2025-11-30T09:30:48.624+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:48,623 - INFO - Total records: 5
[2025-11-30T09:30:48.915+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:48,914 - INFO - Computing global data quality metrics...
[2025-11-30T09:30:48.992+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:48.996+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO FileSourceStrategy: Pushed Filters: IsNull(city)
[2025-11-30T09:30:48.998+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:48 INFO FileSourceStrategy: Post-Scan Filters: isnull(city#0)
[2025-11-30T09:30:49.058+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 22.367235 ms
[2025-11-30T09:30:49.065+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.081+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.083+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.084+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 4 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.086+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_3_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.087+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:49.093+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_1_piece0 on fa0622e2494f:33513 in memory (size: 34.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.095+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Registering RDD 12 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 1
[2025-11-30T09:30:49.097+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got map stage job 3 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.098+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.098+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:49.099+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.107+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.109+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.111+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.112+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[12] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.112+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.114+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 3) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:49.115+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 4.0 (TID 3)
[2025-11-30T09:30:49.145+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 22.073786 ms
[2025-11-30T09:30:49.147+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:49.174+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FilterCompat: Filtering using predicate: eq(city, null)
[2025-11-30T09:30:49.199+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 4.0 (TID 3). 2235 bytes result sent to driver
[2025-11-30T09:30:49.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 3) in 88 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ShuffleMapStage 4 (count at NativeMethodAccessorImpl.java:0) finished in 0.103 s
[2025-11-30T09:30:49.205+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:49.205+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:49.206+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:49.206+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:49.227+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.228+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got job 4 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.229+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ResultStage 6 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.233+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 5)
[2025-11-30T09:30:49.233+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.234+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.235+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.236+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.236+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on fa0622e2494f:33513 (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.237+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.238+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 6 (MapPartitionsRDD[15] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.238+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 6.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.239+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 4) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:49.239+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 6.0 (TID 4)
[2025-11-30T09:30:49.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:49.245+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-11-30T09:30:49.250+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_5_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.251+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 6.0 (TID 4). 4031 bytes result sent to driver
[2025-11-30T09:30:49.253+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 4) in 15 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.253+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.254+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ResultStage 6 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s
[2025-11-30T09:30:49.255+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:49.256+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 6: Stage finished
[2025-11-30T09:30:49.257+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 4 finished: count at NativeMethodAccessorImpl.java:0, took 0.027625 s
[2025-11-30T09:30:49.301+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:49.303+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Pushed Filters: IsNull(aqi)
[2025-11-30T09:30:49.304+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Post-Scan Filters: isnull(aqi#1)
[2025-11-30T09:30:49.344+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 16.05252 ms
[2025-11-30T09:30:49.348+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.357+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_6_piece0 on fa0622e2494f:33513 in memory (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.360+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.361+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.362+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 7 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.363+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:49.364+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_4_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.369+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Registering RDD 19 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 2
[2025-11-30T09:30:49.370+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got map stage job 5 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.371+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.371+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:49.372+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.373+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ShuffleMapStage 7 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.374+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.379+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.380+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.381+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 7 (MapPartitionsRDD[19] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 5) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:49.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 7.0 (TID 5)
[2025-11-30T09:30:49.406+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 14.814459 ms
[2025-11-30T09:30:49.408+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:49.424+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FilterCompat: Filtering using predicate: eq(aqi, null)
[2025-11-30T09:30:49.431+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 7.0 (TID 5). 2149 bytes result sent to driver
[2025-11-30T09:30:49.432+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 5) in 49 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.433+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.434+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ShuffleMapStage 7 (count at NativeMethodAccessorImpl.java:0) finished in 0.062 s
[2025-11-30T09:30:49.435+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:49.436+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:49.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:49.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:49.461+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.462+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got job 6 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.464+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ResultStage 9 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.465+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
[2025-11-30T09:30:49.466+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.467+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[22] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.468+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.468+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.471+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.472+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[22] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 6) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:49.475+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 9.0 (TID 6)
[2025-11-30T09:30:49.480+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:49.481+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-11-30T09:30:49.483+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 9.0 (TID 6). 3988 bytes result sent to driver
[2025-11-30T09:30:49.486+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 6) in 12 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.487+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.488+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ResultStage 9 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s
[2025-11-30T09:30:49.488+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 6 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:49.489+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 9: Stage finished
[2025-11-30T09:30:49.490+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 6 finished: count at NativeMethodAccessorImpl.java:0, took 0.027063 s
[2025-11-30T09:30:49.538+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:49.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Pushed Filters: IsNull(co)
[2025-11-30T09:30:49.540+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Post-Scan Filters: isnull(co#2)
[2025-11-30T09:30:49.579+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 17.066979 ms
[2025-11-30T09:30:49.583+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_9_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.595+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.596+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 10 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:49.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_7_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_8_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.606+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Registering RDD 26 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 3
[2025-11-30T09:30:49.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got map stage job 7 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:49.609+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ShuffleMapStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 18.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.612+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.613+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.614+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.615+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 10 (MapPartitionsRDD[26] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.616+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.617+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 7) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:49.618+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 10.0 (TID 7)
[2025-11-30T09:30:49.635+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO CodeGenerator: Code generated in 14.638652 ms
[2025-11-30T09:30:49.637+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:49.652+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FilterCompat: Filtering using predicate: eq(co, null)
[2025-11-30T09:30:49.656+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 10.0 (TID 7). 2149 bytes result sent to driver
[2025-11-30T09:30:49.658+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 7) in 41 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.659+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.659+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ShuffleMapStage 10 (count at NativeMethodAccessorImpl.java:0) finished in 0.050 s
[2025-11-30T09:30:49.660+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:49.661+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:49.661+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:49.662+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:49.678+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.679+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got job 8 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.680+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ResultStage 12 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.680+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
[2025-11-30T09:30:49.681+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.686+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.687+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.688+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:49.688+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.689+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.689+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[29] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.690+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.690+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 8) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:49.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 12.0 (TID 8)
[2025-11-30T09:30:49.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:49.693+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:49.698+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_11_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.699+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 12.0 (TID 8). 4074 bytes result sent to driver
[2025-11-30T09:30:49.702+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 8) in 15 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.702+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.704+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ResultStage 12 (count at NativeMethodAccessorImpl.java:0) finished in 0.024 s
[2025-11-30T09:30:49.705+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 8 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:49.705+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 12: Stage finished
[2025-11-30T09:30:49.706+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 8 finished: count at NativeMethodAccessorImpl.java:0, took 0.026567 s
[2025-11-30T09:30:49.733+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:49.734+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Pushed Filters: IsNull(no2)
[2025-11-30T09:30:49.734+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Post-Scan Filters: isnull(no2#3)
[2025-11-30T09:30:49.751+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.757+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.758+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.759+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 13 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.759+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:49.763+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Registering RDD 33 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 4
[2025-11-30T09:30:49.764+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got map stage job 9 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.765+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.766+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:49.766+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.767+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.768+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.768+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.769+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.769+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.770+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[33] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.770+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 13.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.770+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 9) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:49.771+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 13.0 (TID 9)
[2025-11-30T09:30:49.775+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:49.791+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FilterCompat: Filtering using predicate: eq(no2, null)
[2025-11-30T09:30:49.797+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 13.0 (TID 9). 2149 bytes result sent to driver
[2025-11-30T09:30:49.798+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 9) in 28 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.799+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.800+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ShuffleMapStage 13 (count at NativeMethodAccessorImpl.java:0) finished in 0.034 s
[2025-11-30T09:30:49.800+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:49.801+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:49.801+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:49.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:49.820+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.821+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got job 10 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.821+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ResultStage 15 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.822+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 14)
[2025-11-30T09:30:49.822+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.823+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.824+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[36] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.829+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 10) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:49.830+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 15.0 (TID 10)
[2025-11-30T09:30:49.834+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:49.835+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:49.841+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_12_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.842+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 15.0 (TID 10). 4031 bytes result sent to driver
[2025-11-30T09:30:49.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 10) in 15 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.845+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ResultStage 15 (count at NativeMethodAccessorImpl.java:0) finished in 0.022 s
[2025-11-30T09:30:49.847+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 10 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:49.847+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Killing all running tasks in stage 15: Stage finished
[2025-11-30T09:30:49.848+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Job 10 finished: count at NativeMethodAccessorImpl.java:0, took 0.026829 s
[2025-11-30T09:30:49.849+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_10_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.854+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Removed broadcast_14_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:49.883+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:49.884+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Pushed Filters: IsNull(o3)
[2025-11-30T09:30:49.885+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceStrategy: Post-Scan Filters: isnull(o3#4)
[2025-11-30T09:30:49.905+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.912+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.914+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.916+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 16 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.917+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:49.921+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Registering RDD 40 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 5
[2025-11-30T09:30:49.922+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got map stage job 11 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.923+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.924+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:49.925+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.926+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.927+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.928+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.928+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:49.929+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:49.930+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[40] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:49.931+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks resource profile 0
[2025-11-30T09:30:49.932+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 11) (fa0622e2494f, executor driver, partition 0, ANY, 8336 bytes)
[2025-11-30T09:30:49.933+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Running task 0.0 in stage 16.0 (TID 11)
[2025-11-30T09:30:49.938+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:49.959+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO FilterCompat: Filtering using predicate: eq(o3, null)
[2025-11-30T09:30:49.968+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO Executor: Finished task 0.0 in stage 16.0 (TID 11). 2149 bytes result sent to driver
[2025-11-30T09:30:49.969+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 11) in 38 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:49.970+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool
[2025-11-30T09:30:49.972+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: ShuffleMapStage 16 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-11-30T09:30:49.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:49.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:49.974+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:49.974+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:49.988+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:49.990+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Got job 12 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:49.991+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Final stage: ResultStage 18 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:49.992+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 17)
[2025-11-30T09:30:49.993+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:49.993+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:49.994+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T09:30:49.999+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:49 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.001+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on fa0622e2494f:33513 (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.002+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_13_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.003+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.003+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[43] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.004+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.005+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 12) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:50.006+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 18.0 (TID 12)
[2025-11-30T09:30:50.007+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_17_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:50.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:50.012+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 18.0 (TID 12). 3988 bytes result sent to driver
[2025-11-30T09:30:50.014+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 12) in 12 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.015+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.016+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_15_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.017+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ResultStage 18 (count at NativeMethodAccessorImpl.java:0) finished in 0.023 s
[2025-11-30T09:30:50.018+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 12 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:50.019+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 18: Stage finished
[2025-11-30T09:30:50.020+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 12 finished: count at NativeMethodAccessorImpl.java:0, took 0.027547 s
[2025-11-30T09:30:50.062+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:50.063+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Pushed Filters: IsNull(pm10)
[2025-11-30T09:30:50.064+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Post-Scan Filters: isnull(pm10#5)
[2025-11-30T09:30:50.091+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.098+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.098+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.099+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 19 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:50.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Registering RDD 47 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 6
[2025-11-30T09:30:50.108+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got map stage job 13 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.109+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.110+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:50.111+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.112+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ShuffleMapStage 19 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.112+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.112+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.113+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.113+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.113+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 19 (MapPartitionsRDD[47] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.114+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.115+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 13) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:50.116+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 19.0 (TID 13)
[2025-11-30T09:30:50.124+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:50.141+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FilterCompat: Filtering using predicate: eq(pm10, null)
[2025-11-30T09:30:50.153+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 19.0 (TID 13). 2235 bytes result sent to driver
[2025-11-30T09:30:50.154+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_16_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.155+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 13) in 40 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.157+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.158+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ShuffleMapStage 19 (count at NativeMethodAccessorImpl.java:0) finished in 0.048 s
[2025-11-30T09:30:50.159+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:50.160+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:50.160+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:50.161+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:50.161+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_18_piece0 on fa0622e2494f:33513 in memory (size: 6.0 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.174+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.175+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got job 14 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.176+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ResultStage 21 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.177+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 20)
[2025-11-30T09:30:50.178+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.179+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.180+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:50.181+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:50.182+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.182+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.184+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[50] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.185+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.185+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 14) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:50.186+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 21.0 (TID 14)
[2025-11-30T09:30:50.189+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:50.190+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:50.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 21.0 (TID 14). 3988 bytes result sent to driver
[2025-11-30T09:30:50.194+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 14) in 11 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ResultStage 21 (count at NativeMethodAccessorImpl.java:0) finished in 0.017 s
[2025-11-30T09:30:50.197+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 14 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:50.197+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 21: Stage finished
[2025-11-30T09:30:50.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 14 finished: count at NativeMethodAccessorImpl.java:0, took 0.020825 s
[2025-11-30T09:30:50.236+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:50.237+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Pushed Filters: IsNull(pm25)
[2025-11-30T09:30:50.238+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Post-Scan Filters: isnull(pm25#6)
[2025-11-30T09:30:50.258+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.264+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.265+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.266+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 22 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.267+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:50.272+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Registering RDD 54 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 7
[2025-11-30T09:30:50.273+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got map stage job 15 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.274+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.274+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:50.275+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.276+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ShuffleMapStage 22 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.277+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.281+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.283+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_20_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.284+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.285+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.286+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 22 (MapPartitionsRDD[54] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.287+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.287+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 15) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:50.288+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 22.0 (TID 15)
[2025-11-30T09:30:50.289+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_19_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.294+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:50.295+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_21_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.311+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FilterCompat: Filtering using predicate: eq(pm25, null)
[2025-11-30T09:30:50.315+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 22.0 (TID 15). 2149 bytes result sent to driver
[2025-11-30T09:30:50.317+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 15) in 30 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.319+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.320+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ShuffleMapStage 22 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-11-30T09:30:50.320+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:50.321+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:50.321+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:50.322+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:50.343+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.345+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got job 16 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.346+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ResultStage 24 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.347+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 23)
[2025-11-30T09:30:50.348+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.349+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.349+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:50.350+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:50.350+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.351+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.352+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 24 (MapPartitionsRDD[57] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.352+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 24.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.353+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 16) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:50.354+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 24.0 (TID 16)
[2025-11-30T09:30:50.358+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:50.359+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:50.361+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 24.0 (TID 16). 3988 bytes result sent to driver
[2025-11-30T09:30:50.362+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 16) in 10 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.363+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.364+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ResultStage 24 (count at NativeMethodAccessorImpl.java:0) finished in 0.016 s
[2025-11-30T09:30:50.364+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 16 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:50.365+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 24: Stage finished
[2025-11-30T09:30:50.366+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 16 finished: count at NativeMethodAccessorImpl.java:0, took 0.020506 s
[2025-11-30T09:30:50.403+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:50.404+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Pushed Filters: IsNull(so2)
[2025-11-30T09:30:50.405+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Post-Scan Filters: isnull(so2#7)
[2025-11-30T09:30:50.426+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.434+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.435+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.436+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 25 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.437+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:50.442+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Registering RDD 61 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 8
[2025-11-30T09:30:50.443+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got map stage job 17 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.443+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.444+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:50.445+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.445+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ShuffleMapStage 25 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 18.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 25 (MapPartitionsRDD[61] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 17) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:50.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 25.0 (TID 17)
[2025-11-30T09:30:50.453+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:50.465+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FilterCompat: Filtering using predicate: eq(so2, null)
[2025-11-30T09:30:50.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 25.0 (TID 17). 2149 bytes result sent to driver
[2025-11-30T09:30:50.472+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 17) in 25 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.473+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.473+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ShuffleMapStage 25 (count at NativeMethodAccessorImpl.java:0) finished in 0.030 s
[2025-11-30T09:30:50.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:50.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:50.475+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:50.475+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:50.496+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.498+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got job 18 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.499+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ResultStage 27 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.500+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 26)
[2025-11-30T09:30:50.501+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.501+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)
[2025-11-30T09:30:50.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)
[2025-11-30T09:30:50.503+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.504+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[64] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.506+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.506+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 18) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:50.507+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 27.0 (TID 18)
[2025-11-30T09:30:50.510+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:50.511+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:50.513+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 27.0 (TID 18). 3988 bytes result sent to driver
[2025-11-30T09:30:50.514+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 18) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.516+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ResultStage 27 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
[2025-11-30T09:30:50.516+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 18 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:50.517+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 27: Stage finished
[2025-11-30T09:30:50.517+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 18 finished: count at NativeMethodAccessorImpl.java:0, took 0.019534 s
[2025-11-30T09:30:50.549+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:50.550+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Pushed Filters: IsNull(timestamp_utc)
[2025-11-30T09:30:50.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Post-Scan Filters: isnull(timestamp_utc#8)
[2025-11-30T09:30:50.578+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO CodeGenerator: Code generated in 12.255338 ms
[2025-11-30T09:30:50.580+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 207.2 KiB, free 433.6 MiB)
[2025-11-30T09:30:50.588+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T09:30:50.589+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.590+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 28 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.590+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:50.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Registering RDD 68 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 9
[2025-11-30T09:30:50.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got map stage job 19 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:50.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ShuffleMapStage 28 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 18.9 KiB, free 433.6 MiB)
[2025-11-30T09:30:50.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.6 MiB)
[2025-11-30T09:30:50.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on fa0622e2494f:33513 (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 28 (MapPartitionsRDD[68] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 19) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:50.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 28.0 (TID 19)
[2025-11-30T09:30:50.622+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO CodeGenerator: Code generated in 15.80933 ms
[2025-11-30T09:30:50.624+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:50.660+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO CodecPool: Got brand-new decompressor [.snappy]
[2025-11-30T09:30:50.821+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 28.0 (TID 19). 2278 bytes result sent to driver
[2025-11-30T09:30:50.821+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 19) in 219 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.822+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_26_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ShuffleMapStage 28 (count at NativeMethodAccessorImpl.java:0) finished in 0.223 s
[2025-11-30T09:30:50.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:50.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:50.830+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:50.831+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:50.832+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_22_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.833+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_24_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.839+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_23_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.841+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_27_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.844+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Got job 20 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:50.845+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Final stage: ResultStage 30 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:50.846+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 29)
[2025-11-30T09:30:50.847+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:50.848+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:50.848+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 12.5 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.849+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.850+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.851+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Removed broadcast_25_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:50.851+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:50.852+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[71] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:50.853+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks resource profile 0
[2025-11-30T09:30:50.853+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 20) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:50.854+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Running task 0.0 in stage 30.0 (TID 20)
[2025-11-30T09:30:50.854+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:50.855+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:50.856+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO Executor: Finished task 0.0 in stage 30.0 (TID 20). 3988 bytes result sent to driver
[2025-11-30T09:30:50.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 20) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:50.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool
[2025-11-30T09:30:50.858+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: ResultStage 30 (count at NativeMethodAccessorImpl.java:0) finished in 0.014 s
[2025-11-30T09:30:50.859+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 20 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:50.859+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO TaskSchedulerImpl: Killing all running tasks in stage 30: Stage finished
[2025-11-30T09:30:50.860+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DAGScheduler: Job 20 finished: count at NativeMethodAccessorImpl.java:0, took 0.016193 s
[2025-11-30T09:30:50.861+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO - Null counts:
[2025-11-30T09:30:50.862+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   city: 0 nulls (0.0%)
[2025-11-30T09:30:50.862+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   aqi: 0 nulls (0.0%)
[2025-11-30T09:30:50.863+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   co: 0 nulls (0.0%)
[2025-11-30T09:30:50.864+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   no2: 0 nulls (0.0%)
[2025-11-30T09:30:50.864+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   o3: 0 nulls (0.0%)
[2025-11-30T09:30:50.865+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   pm10: 0 nulls (0.0%)
[2025-11-30T09:30:50.866+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   pm25: 0 nulls (0.0%)
[2025-11-30T09:30:50.867+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,859 - INFO -   so2: 0 nulls (0.0%)
[2025-11-30T09:30:50.868+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,860 - INFO -   timestamp_utc: 0 nulls (0.0%)
[2025-11-30T09:30:50.869+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:50,860 - INFO - Analyzing duplicates...
[2025-11-30T09:30:50.890+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:50.891+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:50.892+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:50.969+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO CodeGenerator: Code generated in 50.693366 ms
[2025-11-30T09:30:50.972+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 207.4 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:50.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:50.980+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO SparkContext: Created broadcast 31 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:50.981+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:50 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.000+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 75 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 10
[2025-11-30T09:30:51.001+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 21 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.002+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.002+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.003+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.003+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 31 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.004+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 32.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.006+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 13.4 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.007+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on fa0622e2494f:33513 (size: 13.4 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.008+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.008+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 31 (MapPartitionsRDD[75] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 21) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:51.010+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 31.0 (TID 21)
[2025-11-30T09:30:51.039+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 26.103102 ms
[2025-11-30T09:30:51.054+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 9.48052 ms
[2025-11-30T09:30:51.061+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 4.96655 ms
[2025-11-30T09:30:51.083+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 14.501085 ms
[2025-11-30T09:30:51.088+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.124+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 31.0 (TID 21). 3105 bytes result sent to driver
[2025-11-30T09:30:51.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 21) in 116 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.126+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 31 (count at NativeMethodAccessorImpl.java:0) finished in 0.124 s
[2025-11-30T09:30:51.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.139+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShufflePartitionsUtil: For shuffle(10), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T09:30:51.175+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 19.018277 ms
[2025-11-30T09:30:51.191+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 78 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 11
[2025-11-30T09:30:51.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 22 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.193+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 32)
[2025-11-30T09:30:51.193+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.194+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 33 (MapPartitionsRDD[78] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 45.3 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 20.5 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on fa0622e2494f:33513 (size: 20.5 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.199+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.199+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 33 (MapPartitionsRDD[78] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.199+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 22) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7604 bytes)
[2025-11-30T09:30:51.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 33.0 (TID 22)
[2025-11-30T09:30:51.208+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (400.0 B) non-empty blocks including 1 (400.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.209+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-11-30T09:30:51.237+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 28.624181 ms
[2025-11-30T09:30:51.257+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_30_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.258+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 33.0 (TID 22). 6064 bytes result sent to driver
[2025-11-30T09:30:51.258+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 22) in 59 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.259+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.260+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 33 (count at NativeMethodAccessorImpl.java:0) finished in 0.064 s
[2025-11-30T09:30:51.261+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.262+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.263+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.263+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.264+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_29_piece0 on fa0622e2494f:33513 in memory (size: 8.3 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.266+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_28_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.269+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_32_piece0 on fa0622e2494f:33513 in memory (size: 13.4 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.274+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 6.2432 ms
[2025-11-30T09:30:51.282+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.284+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got job 23 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.284+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ResultStage 36 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.285+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 35)
[2025-11-30T09:30:51.286+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.286+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ResultStage 36 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.287+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.287+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 6.0 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.288+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on fa0622e2494f:33513 (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.288+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.289+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 36 (MapPartitionsRDD[81] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.290+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 36.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.290+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 36.0 (TID 23) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:51.291+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 36.0 (TID 23)
[2025-11-30T09:30:51.292+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.293+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:51.299+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 6.277801 ms
[2025-11-30T09:30:51.302+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 36.0 (TID 23). 3995 bytes result sent to driver
[2025-11-30T09:30:51.304+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 36.0 (TID 23) in 15 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.304+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 36.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.305+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ResultStage 36 (count at NativeMethodAccessorImpl.java:0) finished in 0.020 s
[2025-11-30T09:30:51.306+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 23 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:51.306+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 36: Stage finished
[2025-11-30T09:30:51.307+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 23 finished: count at NativeMethodAccessorImpl.java:0, took 0.022989 s
[2025-11-30T09:30:51.307+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:51,306 - INFO - Total duplicates: 0 (0.00%)
[2025-11-30T09:30:51.308+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:51,306 - INFO - Validating value ranges...
[2025-11-30T09:30:51.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:51.343+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(aqi,0),GreaterThan(aqi,500))
[2025-11-30T09:30:51.344+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Post-Scan Filters: ((aqi#1 < 0) OR (aqi#1 > 500))
[2025-11-30T09:30:51.367+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 10.047799 ms
[2025-11-30T09:30:51.369+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.375+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.376+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.377+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 35 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.378+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.381+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 85 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 12
[2025-11-30T09:30:51.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 24 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 37 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.383+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 37 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.385+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 19.8 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.386+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.387+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.388+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.388+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 37 (MapPartitionsRDD[85] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.389+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 37.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.390+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 37.0 (TID 24) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:51.390+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 37.0 (TID 24)
[2025-11-30T09:30:51.402+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 9.904757 ms
[2025-11-30T09:30:51.403+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.420+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FilterCompat: Filtering using predicate: or(lt(aqi, 0), gt(aqi, 500))
[2025-11-30T09:30:51.424+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 37.0 (TID 24). 2149 bytes result sent to driver
[2025-11-30T09:30:51.425+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 37.0 (TID 24) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.426+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 37.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.427+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 37 (count at NativeMethodAccessorImpl.java:0) finished in 0.043 s
[2025-11-30T09:30:51.427+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.428+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.429+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.429+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.441+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.443+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got job 25 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.444+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ResultStage 39 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.444+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 38)
[2025-11-30T09:30:51.445+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.445+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ResultStage 39 (MapPartitionsRDD[88] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_37 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_37_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_37_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 37 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 39 (MapPartitionsRDD[88] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 39.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 39.0 (TID 25) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:51.450+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 39.0 (TID 25)
[2025-11-30T09:30:51.452+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.453+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:51.454+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 39.0 (TID 25). 3988 bytes result sent to driver
[2025-11-30T09:30:51.455+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 39.0 (TID 25) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.457+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 39.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.457+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ResultStage 39 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T09:30:51.458+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 25 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:51.459+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 39: Stage finished
[2025-11-30T09:30:51.460+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 25 finished: count at NativeMethodAccessorImpl.java:0, took 0.015606 s
[2025-11-30T09:30:51.488+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:51.489+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(pm25,0.0),GreaterThan(pm25,500.0))
[2025-11-30T09:30:51.490+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Post-Scan Filters: ((pm25#6 < 0.0) OR (pm25#6 > 500.0))
[2025-11-30T09:30:51.510+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 8.866548 ms
[2025-11-30T09:30:51.512+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_38 stored as values in memory (estimated size 207.2 KiB, free 433.6 MiB)
[2025-11-30T09:30:51.520+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_34_piece0 on fa0622e2494f:33513 in memory (size: 6.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.522+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_38_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.522+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_35_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_38_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 38 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.526+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_31_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.528+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 92 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 13
[2025-11-30T09:30:51.529+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 26 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.530+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.531+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.533+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.534+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_36_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.534+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 40 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.535+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_39 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.536+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_39_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.536+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_33_piece0 on fa0622e2494f:33513 in memory (size: 20.5 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.537+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_39_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.537+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 39 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.538+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 40 (MapPartitionsRDD[92] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 40.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 40.0 (TID 26) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:51.540+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 40.0 (TID 26)
[2025-11-30T09:30:51.541+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_37_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.548+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 7.477228 ms
[2025-11-30T09:30:51.549+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.561+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FilterCompat: Filtering using predicate: or(lt(pm25, 0.0), gt(pm25, 500.0))
[2025-11-30T09:30:51.565+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 40.0 (TID 26). 2149 bytes result sent to driver
[2025-11-30T09:30:51.566+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 40.0 (TID 26) in 31 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.567+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 40.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.568+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 40 (count at NativeMethodAccessorImpl.java:0) finished in 0.038 s
[2025-11-30T09:30:51.568+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.569+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.570+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.570+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.582+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.583+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got job 27 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.584+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ResultStage 42 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.584+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 41)
[2025-11-30T09:30:51.585+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.585+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ResultStage 42 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.586+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_40 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.586+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_40_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.587+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_40_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.587+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 40 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.588+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 42 (MapPartitionsRDD[95] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.588+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 42.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.589+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 42.0 (TID 27) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:51.589+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 42.0 (TID 27)
[2025-11-30T09:30:51.590+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.591+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:51.593+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 42.0 (TID 27). 3988 bytes result sent to driver
[2025-11-30T09:30:51.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 42.0 (TID 27) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 42.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.595+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ResultStage 42 (count at NativeMethodAccessorImpl.java:0) finished in 0.010 s
[2025-11-30T09:30:51.596+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 27 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:51.596+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 42: Stage finished
[2025-11-30T09:30:51.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 27 finished: count at NativeMethodAccessorImpl.java:0, took 0.012828 s
[2025-11-30T09:30:51.623+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:51.624+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(pm10,0.0),GreaterThan(pm10,600.0))
[2025-11-30T09:30:51.624+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Post-Scan Filters: ((pm10#5 < 0.0) OR (pm10#5 > 600.0))
[2025-11-30T09:30:51.645+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 9.31225 ms
[2025-11-30T09:30:51.646+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_41 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.652+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_41_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.653+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_41_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.653+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 41 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.654+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.657+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 99 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 14
[2025-11-30T09:30:51.658+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 28 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.659+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.660+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.660+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.661+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 43 (MapPartitionsRDD[99] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.661+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_42 stored as values in memory (estimated size 20.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.662+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_42_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.663+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_42_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.663+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 42 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.663+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 43 (MapPartitionsRDD[99] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.664+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 43.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.665+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 43.0 (TID 28) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:51.665+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 43.0 (TID 28)
[2025-11-30T09:30:51.679+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 11.823234 ms
[2025-11-30T09:30:51.680+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.693+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FilterCompat: Filtering using predicate: or(lt(pm10, 0.0), gt(pm10, 600.0))
[2025-11-30T09:30:51.702+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 43.0 (TID 28). 2235 bytes result sent to driver
[2025-11-30T09:30:51.702+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_39_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.703+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 43.0 (TID 28) in 39 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.705+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 43.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.706+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 43 (count at NativeMethodAccessorImpl.java:0) finished in 0.044 s
[2025-11-30T09:30:51.708+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.709+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.709+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.710+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.711+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_38_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.712+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_40_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.719+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.721+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got job 29 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.722+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ResultStage 45 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.722+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 44)
[2025-11-30T09:30:51.723+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.724+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ResultStage 45 (MapPartitionsRDD[102] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.724+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_43 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.725+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_43_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.726+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_43_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.727+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 43 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.728+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 45 (MapPartitionsRDD[102] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.729+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 45.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.730+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 45.0 (TID 29) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:51.730+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 45.0 (TID 29)
[2025-11-30T09:30:51.731+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.732+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:51.732+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 45.0 (TID 29). 3988 bytes result sent to driver
[2025-11-30T09:30:51.733+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 45.0 (TID 29) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.734+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 45.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.735+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ResultStage 45 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T09:30:51.736+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 29 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:51.736+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 45: Stage finished
[2025-11-30T09:30:51.737+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 29 finished: count at NativeMethodAccessorImpl.java:0, took 0.016015 s
[2025-11-30T09:30:51.766+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:51.767+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(co,0.0),GreaterThan(co,10000.0))
[2025-11-30T09:30:51.768+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Post-Scan Filters: ((co#2 < 0.0) OR (co#2 > 10000.0))
[2025-11-30T09:30:51.792+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 11.444997 ms
[2025-11-30T09:30:51.795+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_44 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.801+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_44_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_44_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.804+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 44 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.805+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.808+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 106 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 15
[2025-11-30T09:30:51.809+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 30 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.810+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.811+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.812+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.813+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 46 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.813+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_45 stored as values in memory (estimated size 20.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.814+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_45_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.9 MiB)
[2025-11-30T09:30:51.815+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_45_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.816+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 45 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.817+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 46 (MapPartitionsRDD[106] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.818+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 46.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.819+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 46.0 (TID 30) (fa0622e2494f, executor driver, partition 0, ANY, 8336 bytes)
[2025-11-30T09:30:51.819+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 46.0 (TID 30)
[2025-11-30T09:30:51.831+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO CodeGenerator: Code generated in 11.735515 ms
[2025-11-30T09:30:51.833+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.849+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FilterCompat: Filtering using predicate: or(lt(co, 0.0), gt(co, 10000.0))
[2025-11-30T09:30:51.853+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 46.0 (TID 30). 2149 bytes result sent to driver
[2025-11-30T09:30:51.854+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 46.0 (TID 30) in 40 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.855+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 46.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.855+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 46 (count at NativeMethodAccessorImpl.java:0) finished in 0.045 s
[2025-11-30T09:30:51.856+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.858+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.871+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.873+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got job 31 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.874+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ResultStage 48 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.875+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 47)
[2025-11-30T09:30:51.876+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.876+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ResultStage 48 (MapPartitionsRDD[109] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.877+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_46 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.878+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_46_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)
[2025-11-30T09:30:51.879+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_46_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.880+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 46 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.881+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 48 (MapPartitionsRDD[109] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.881+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 48.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.882+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 48.0 (TID 31) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:51.883+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 48.0 (TID 31)
[2025-11-30T09:30:51.883+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:51.884+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:51.887+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 48.0 (TID 31). 3988 bytes result sent to driver
[2025-11-30T09:30:51.889+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 48.0 (TID 31) in 11 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.890+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 48.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.890+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ResultStage 48 (count at NativeMethodAccessorImpl.java:0) finished in 0.015 s
[2025-11-30T09:30:51.891+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 31 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:51.892+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Killing all running tasks in stage 48: Stage finished
[2025-11-30T09:30:51.892+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Job 31 finished: count at NativeMethodAccessorImpl.java:0, took 0.019158 s
[2025-11-30T09:30:51.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:51.921+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(no2,0.0),GreaterThan(no2,500.0))
[2025-11-30T09:30:51.922+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceStrategy: Post-Scan Filters: ((no2#3 < 0.0) OR (no2#3 > 500.0))
[2025-11-30T09:30:51.936+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_47 stored as values in memory (estimated size 207.2 KiB, free 433.6 MiB)
[2025-11-30T09:30:51.946+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_46_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.949+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_47_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T09:30:51.950+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_41_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.951+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_47_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.951+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 47 from count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:51.952+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_45_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.953+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:51.954+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_42_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:51.955+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_44_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.955+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Registering RDD 113 (count at NativeMethodAccessorImpl.java:0) as input to shuffle 16
[2025-11-30T09:30:51.956+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Got map stage job 32 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:51.957+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Final stage: ShuffleMapStage 49 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:51.958+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:51.958+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:51.959+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting ShuffleMapStage 49 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:51.959+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Removed broadcast_43_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.960+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_48 stored as values in memory (estimated size 20.0 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.961+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO MemoryStore: Block broadcast_48_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T09:30:51.961+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO BlockManagerInfo: Added broadcast_48_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:51.962+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Created broadcast 48 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:51.963+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 49 (MapPartitionsRDD[113] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:51.963+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Adding task set 49.0 with 1 tasks resource profile 0
[2025-11-30T09:30:51.964+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Starting task 0.0 in stage 49.0 (TID 32) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:51.964+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Running task 0.0 in stage 49.0 (TID 32)
[2025-11-30T09:30:51.966+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:51.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO FilterCompat: Filtering using predicate: or(lt(no2, 0.0), gt(no2, 500.0))
[2025-11-30T09:30:51.983+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO Executor: Finished task 0.0 in stage 49.0 (TID 32). 2149 bytes result sent to driver
[2025-11-30T09:30:51.984+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSetManager: Finished task 0.0 in stage 49.0 (TID 32) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:51.985+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO TaskSchedulerImpl: Removed TaskSet 49.0, whose tasks have all completed, from pool
[2025-11-30T09:30:51.986+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: ShuffleMapStage 49 (count at NativeMethodAccessorImpl.java:0) finished in 0.028 s
[2025-11-30T09:30:51.986+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:51.987+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:51.988+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:51.988+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:51.999+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:51 INFO SparkContext: Starting job: count at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:52.000+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got job 33 (count at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:52.001+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ResultStage 51 (count at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:52.002+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 50)
[2025-11-30T09:30:52.002+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.003+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ResultStage 51 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:52.004+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_49 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:52.005+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_49_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:52.006+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_49_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.006+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 49 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.007+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 51 (MapPartitionsRDD[116] at count at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.008+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 51.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.008+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 51.0 (TID 33) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:52.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 51.0 (TID 33)
[2025-11-30T09:30:52.010+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:52.010+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:52.011+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 51.0 (TID 33). 3988 bytes result sent to driver
[2025-11-30T09:30:52.012+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 51.0 (TID 33) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.013+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 51.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.014+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ResultStage 51 (count at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T09:30:52.014+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 33 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:52.015+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 51: Stage finished
[2025-11-30T09:30:52.015+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 33 finished: count at NativeMethodAccessorImpl.java:0, took 0.014273 s
[2025-11-30T09:30:52.040+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:52.041+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(o3,0.0),GreaterThan(o3,500.0))
[2025-11-30T09:30:52.042+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Post-Scan Filters: ((o3#4 < 0.0) OR (o3#4 > 500.0))
[2025-11-30T09:30:52.057+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_50 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.063+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_50_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.064+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_50_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.065+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 50 from count at <unknown>:0
[2025-11-30T09:30:52.066+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:52.071+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Registering RDD 120 (count at <unknown>:0) as input to shuffle 17
[2025-11-30T09:30:52.072+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got map stage job 34 (count at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:52.073+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ShuffleMapStage 52 (count at <unknown>:0)
[2025-11-30T09:30:52.074+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:52.075+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.076+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ShuffleMapStage 52 (MapPartitionsRDD[120] at count at <unknown>:0), which has no missing parents
[2025-11-30T09:30:52.076+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_51 stored as values in memory (estimated size 20.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.079+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_47_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.080+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_51_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 434.1 MiB)
[2025-11-30T09:30:52.081+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_51_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.082+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 51 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.083+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 52 (MapPartitionsRDD[120] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.084+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 52.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.085+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_49_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.085+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 52.0 (TID 34) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:52.086+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 52.0 (TID 34)
[2025-11-30T09:30:52.088+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_48_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.089+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:52.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FilterCompat: Filtering using predicate: or(lt(o3, 0.0), gt(o3, 500.0))
[2025-11-30T09:30:52.104+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 52.0 (TID 34). 2149 bytes result sent to driver
[2025-11-30T09:30:52.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 52.0 (TID 34) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 52.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ShuffleMapStage 52 (count at <unknown>:0) finished in 0.033 s
[2025-11-30T09:30:52.107+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:52.108+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:52.109+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:52.110+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:52.118+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-30T09:30:52.119+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got job 35 (count at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:52.120+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ResultStage 54 (count at <unknown>:0)
[2025-11-30T09:30:52.121+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 53)
[2025-11-30T09:30:52.122+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.123+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ResultStage 54 (MapPartitionsRDD[123] at count at <unknown>:0), which has no missing parents
[2025-11-30T09:30:52.124+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_52 stored as values in memory (estimated size 12.5 KiB, free 434.1 MiB)
[2025-11-30T09:30:52.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_52_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 434.1 MiB)
[2025-11-30T09:30:52.126+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_52_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.126+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 52 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 54 (MapPartitionsRDD[123] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 54.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 54.0 (TID 35) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:52.130+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 54.0 (TID 35)
[2025-11-30T09:30:52.131+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:52.132+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:52.133+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 54.0 (TID 35). 3988 bytes result sent to driver
[2025-11-30T09:30:52.134+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 54.0 (TID 35) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.134+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 54.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.136+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ResultStage 54 (count at <unknown>:0) finished in 0.012 s
[2025-11-30T09:30:52.137+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 35 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:52.138+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 54: Stage finished
[2025-11-30T09:30:52.139+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 35 finished: count at <unknown>:0, took 0.015403 s
[2025-11-30T09:30:52.163+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:52.164+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Pushed Filters: Or(LessThan(so2,0.0),GreaterThan(so2,500.0))
[2025-11-30T09:30:52.165+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Post-Scan Filters: ((so2#7 < 0.0) OR (so2#7 > 500.0))
[2025-11-30T09:30:52.177+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_53 stored as values in memory (estimated size 207.2 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.183+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_53_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.184+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_53_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.185+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 53 from count at <unknown>:0
[2025-11-30T09:30:52.186+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:52.190+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Registering RDD 127 (count at <unknown>:0) as input to shuffle 18
[2025-11-30T09:30:52.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got map stage job 36 (count at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:52.193+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ShuffleMapStage 55 (count at <unknown>:0)
[2025-11-30T09:30:52.194+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:52.195+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ShuffleMapStage 55 (MapPartitionsRDD[127] at count at <unknown>:0), which has no missing parents
[2025-11-30T09:30:52.197+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_54 stored as values in memory (estimated size 20.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_54_piece0 stored as bytes in memory (estimated size 8.7 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_54_piece0 in memory on fa0622e2494f:33513 (size: 8.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 54 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.201+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 55 (MapPartitionsRDD[127] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 55.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 55.0 (TID 36) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:52.203+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 55.0 (TID 36)
[2025-11-30T09:30:52.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:52.214+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FilterCompat: Filtering using predicate: or(lt(so2, 0.0), gt(so2, 500.0))
[2025-11-30T09:30:52.219+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 55.0 (TID 36). 2149 bytes result sent to driver
[2025-11-30T09:30:52.220+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 55.0 (TID 36) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.221+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 55.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.222+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ShuffleMapStage 55 (count at <unknown>:0) finished in 0.028 s
[2025-11-30T09:30:52.222+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:52.223+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:52.223+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:52.224+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:52.233+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Starting job: count at <unknown>:0
[2025-11-30T09:30:52.234+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got job 37 (count at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:52.235+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ResultStage 57 (count at <unknown>:0)
[2025-11-30T09:30:52.236+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 56)
[2025-11-30T09:30:52.236+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.237+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ResultStage 57 (MapPartitionsRDD[130] at count at <unknown>:0), which has no missing parents
[2025-11-30T09:30:52.238+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_55 stored as values in memory (estimated size 12.5 KiB, free 433.8 MiB)
[2025-11-30T09:30:52.241+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_55_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 433.8 MiB)
[2025-11-30T09:30:52.242+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_55_piece0 in memory on fa0622e2494f:33513 (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.243+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_52_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 55 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 57 (MapPartitionsRDD[130] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.245+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 57.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.246+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 57.0 (TID 37) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:52.247+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_50_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.248+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 57.0 (TID 37)
[2025-11-30T09:30:52.249+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_51_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.250+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:52.250+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_54_piece0 on fa0622e2494f:33513 in memory (size: 8.7 KiB, free: 434.4 MiB)
[2025-11-30T09:30:52.251+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:52.251+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 57.0 (TID 37). 3988 bytes result sent to driver
[2025-11-30T09:30:52.252+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 57.0 (TID 37) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.253+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 57.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.253+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ResultStage 57 (count at <unknown>:0) finished in 0.017 s
[2025-11-30T09:30:52.254+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 37 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:52.255+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 57: Stage finished
[2025-11-30T09:30:52.256+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 37 finished: count at <unknown>:0, took 0.019732 s
[2025-11-30T09:30:52.257+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:52,254 - INFO - Detecting spikes by city/date...
[2025-11-30T09:30:52.440+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:52.441+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:52.442+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:52.484+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 9.64299 ms
[2025-11-30T09:30:52.486+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_56 stored as values in memory (estimated size 207.5 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.492+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_56_piece0 stored as bytes in memory (estimated size 35.0 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.493+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_56_piece0 in memory on fa0622e2494f:33513 (size: 35.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.494+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 56 from collect at /opt/***/scripts/dq_report.py:148
[2025-11-30T09:30:52.495+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:52.501+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Registering RDD 135 (collect at /opt/***/scripts/dq_report.py:148) as input to shuffle 19
[2025-11-30T09:30:52.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got map stage job 38 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T09:30:52.503+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ShuffleMapStage 58 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T09:30:52.504+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:52.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.506+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ShuffleMapStage 58 (MapPartitionsRDD[135] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T09:30:52.513+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_57 stored as values in memory (estimated size 35.5 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.514+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_57_piece0 stored as bytes in memory (estimated size 15.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:52.514+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_57_piece0 in memory on fa0622e2494f:33513 (size: 15.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 57 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 58 (MapPartitionsRDD[135] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.516+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 58.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.517+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 58.0 (TID 38) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:52.518+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 58.0 (TID 38)
[2025-11-30T09:30:52.532+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 8.711368 ms
[2025-11-30T09:30:52.533+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:52.569+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 4.397838 ms
[2025-11-30T09:30:52.589+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 6.840576 ms
[2025-11-30T09:30:52.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 5.553997 ms
[2025-11-30T09:30:52.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 6.761577 ms
[2025-11-30T09:30:52.620+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 4.839377 ms
[2025-11-30T09:30:52.639+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 6.524979 ms
[2025-11-30T09:30:52.648+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 58.0 (TID 38). 2903 bytes result sent to driver
[2025-11-30T09:30:52.649+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 58.0 (TID 38) in 134 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.650+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 58.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.651+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ShuffleMapStage 58 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.147 s
[2025-11-30T09:30:52.652+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:52.652+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:52.653+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:52.654+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:52.656+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShufflePartitionsUtil: For shuffle(19), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T09:30:52.665+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Registering RDD 138 (collect at /opt/***/scripts/dq_report.py:148) as input to shuffle 20
[2025-11-30T09:30:52.666+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got map stage job 39 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T09:30:52.667+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ShuffleMapStage 60 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T09:30:52.668+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 59)
[2025-11-30T09:30:52.669+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.670+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ShuffleMapStage 60 (MapPartitionsRDD[138] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T09:30:52.673+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_58 stored as values in memory (estimated size 36.0 KiB, free 433.8 MiB)
[2025-11-30T09:30:52.673+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_58_piece0 stored as bytes in memory (estimated size 16.8 KiB, free 433.8 MiB)
[2025-11-30T09:30:52.674+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_58_piece0 in memory on fa0622e2494f:33513 (size: 16.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.675+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 58 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.676+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 60 (MapPartitionsRDD[138] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.676+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 60.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.677+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 60.0 (TID 39) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7604 bytes)
[2025-11-30T09:30:52.678+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 60.0 (TID 39)
[2025-11-30T09:30:52.683+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (142.0 B) non-empty blocks including 1 (142.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:52.684+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:52.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 4.436184 ms
[2025-11-30T09:30:52.698+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 3.814184 ms
[2025-11-30T09:30:52.707+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 4.768854 ms
[2025-11-30T09:30:52.715+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 5.30601 ms
[2025-11-30T09:30:52.730+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 8.024787 ms
[2025-11-30T09:30:52.741+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 60.0 (TID 39). 5474 bytes result sent to driver
[2025-11-30T09:30:52.743+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 60.0 (TID 39) in 66 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.743+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 60.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.744+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ShuffleMapStage 60 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.074 s
[2025-11-30T09:30:52.745+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:52.745+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:52.746+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:52.747+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:52.749+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShufflePartitionsUtil: For shuffle(20), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T09:30:52.771+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 9.267834 ms
[2025-11-30T09:30:52.787+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 8.054498 ms
[2025-11-30T09:30:52.823+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:148
[2025-11-30T09:30:52.824+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Got job 40 (collect at /opt/***/scripts/dq_report.py:148) with 1 output partitions
[2025-11-30T09:30:52.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Final stage: ResultStage 63 (collect at /opt/***/scripts/dq_report.py:148)
[2025-11-30T09:30:52.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 62)
[2025-11-30T09:30:52.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:52.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting ResultStage 63 (MapPartitionsRDD[143] at collect at /opt/***/scripts/dq_report.py:148), which has no missing parents
[2025-11-30T09:30:52.829+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_59 stored as values in memory (estimated size 50.9 KiB, free 433.8 MiB)
[2025-11-30T09:30:52.836+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO MemoryStore: Block broadcast_59_piece0 stored as bytes in memory (estimated size 23.0 KiB, free 433.7 MiB)
[2025-11-30T09:30:52.838+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_55_piece0 on fa0622e2494f:33513 in memory (size: 5.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.839+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Added broadcast_59_piece0 in memory on fa0622e2494f:33513 (size: 23.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.840+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO SparkContext: Created broadcast 59 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:52.840+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 63 (MapPartitionsRDD[143] at collect at /opt/***/scripts/dq_report.py:148) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:52.841+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Adding task set 63.0 with 1 tasks resource profile 0
[2025-11-30T09:30:52.842+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_58_piece0 on fa0622e2494f:33513 in memory (size: 16.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Starting task 0.0 in stage 63.0 (TID 40) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:52.844+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Running task 0.0 in stage 63.0 (TID 40)
[2025-11-30T09:30:52.846+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_57_piece0 on fa0622e2494f:33513 in memory (size: 15.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.846+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO BlockManagerInfo: Removed broadcast_53_piece0 on fa0622e2494f:33513 in memory (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:52.859+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Getting 1 (88.0 B) non-empty blocks including 1 (88.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:52.860+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:52.866+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 6.349528 ms
[2025-11-30T09:30:52.882+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 10.08547 ms
[2025-11-30T09:30:52.895+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 5.922604 ms
[2025-11-30T09:30:52.914+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 5.058511 ms
[2025-11-30T09:30:52.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 3.681531 ms
[2025-11-30T09:30:52.937+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 3.643495 ms
[2025-11-30T09:30:52.946+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 5.807077 ms
[2025-11-30T09:30:52.957+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 8.577405 ms
[2025-11-30T09:30:52.968+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO CodeGenerator: Code generated in 9.309178 ms
[2025-11-30T09:30:52.974+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO Executor: Finished task 0.0 in stage 63.0 (TID 40). 6806 bytes result sent to driver
[2025-11-30T09:30:52.975+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSetManager: Finished task 0.0 in stage 63.0 (TID 40) in 136 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:52.977+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Removed TaskSet 63.0, whose tasks have all completed, from pool
[2025-11-30T09:30:52.978+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: ResultStage 63 (collect at /opt/***/scripts/dq_report.py:148) finished in 0.150 s
[2025-11-30T09:30:52.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 40 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:52.980+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO TaskSchedulerImpl: Killing all running tasks in stage 63: Stage finished
[2025-11-30T09:30:52.980+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:52 INFO DAGScheduler: Job 40 finished: collect at /opt/***/scripts/dq_report.py:148, took 0.154036 s
[2025-11-30T09:30:52.999+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:52,999 - INFO - Spike detections (>50% increase): 0
[2025-11-30T09:30:53.000+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:52,999 - INFO - Generating daily city-level data quality report...
[2025-11-30T09:30:53.138+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:53.139+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:53.139+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:53.167+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 8.238139 ms
[2025-11-30T09:30:53.169+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_60 stored as values in memory (estimated size 207.7 KiB, free 433.9 MiB)
[2025-11-30T09:30:53.174+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_60_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.9 MiB)
[2025-11-30T09:30:53.175+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_60_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.176+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 60 from collect at /opt/***/scripts/dq_report.py:182
[2025-11-30T09:30:53.177+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:53.180+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Registering RDD 148 (collect at /opt/***/scripts/dq_report.py:182) as input to shuffle 21
[2025-11-30T09:30:53.181+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got map stage job 41 (collect at /opt/***/scripts/dq_report.py:182) with 1 output partitions
[2025-11-30T09:30:53.182+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ShuffleMapStage 64 (collect at /opt/***/scripts/dq_report.py:182)
[2025-11-30T09:30:53.182+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:53.183+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.183+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ShuffleMapStage 64 (MapPartitionsRDD[148] at collect at /opt/***/scripts/dq_report.py:182), which has no missing parents
[2025-11-30T09:30:53.192+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_61 stored as values in memory (estimated size 46.4 KiB, free 433.8 MiB)
[2025-11-30T09:30:53.193+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_61_piece0 stored as bytes in memory (estimated size 19.6 KiB, free 433.8 MiB)
[2025-11-30T09:30:53.193+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_61_piece0 in memory on fa0622e2494f:33513 (size: 19.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.194+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 61 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.195+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 64 (MapPartitionsRDD[148] at collect at /opt/***/scripts/dq_report.py:182) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.195+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 64.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 64.0 (TID 41) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:53.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 64.0 (TID 41)
[2025-11-30T09:30:53.208+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 6.503066 ms
[2025-11-30T09:30:53.209+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:53.231+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 4.441685 ms
[2025-11-30T09:30:53.271+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 18.713203 ms
[2025-11-30T09:30:53.278+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 4.323194 ms
[2025-11-30T09:30:53.291+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 7.51034 ms
[2025-11-30T09:30:53.316+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 11.536534 ms
[2025-11-30T09:30:53.325+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 64.0 (TID 41). 2903 bytes result sent to driver
[2025-11-30T09:30:53.326+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 64.0 (TID 41) in 130 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.326+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 64.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.327+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ShuffleMapStage 64 (collect at /opt/***/scripts/dq_report.py:182) finished in 0.143 s
[2025-11-30T09:30:53.329+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:53.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:53.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:53.331+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:53.332+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShufflePartitionsUtil: For shuffle(21), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T09:30:53.340+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:182
[2025-11-30T09:30:53.341+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got job 42 (collect at /opt/***/scripts/dq_report.py:182) with 1 output partitions
[2025-11-30T09:30:53.342+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ResultStage 66 (collect at /opt/***/scripts/dq_report.py:182)
[2025-11-30T09:30:53.342+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 65)
[2025-11-30T09:30:53.343+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.344+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ResultStage 66 (MapPartitionsRDD[151] at collect at /opt/***/scripts/dq_report.py:182), which has no missing parents
[2025-11-30T09:30:53.345+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_62 stored as values in memory (estimated size 50.0 KiB, free 433.7 MiB)
[2025-11-30T09:30:53.346+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_62_piece0 stored as bytes in memory (estimated size 21.1 KiB, free 433.7 MiB)
[2025-11-30T09:30:53.346+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_62_piece0 in memory on fa0622e2494f:33513 (size: 21.1 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.347+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 62 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.347+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 66 (MapPartitionsRDD[151] at collect at /opt/***/scripts/dq_report.py:182) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.348+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 66.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.349+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 66.0 (TID 42) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:53.350+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 66.0 (TID 42)
[2025-11-30T09:30:53.353+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (156.0 B) non-empty blocks including 1 (156.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:53.354+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:53.376+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 9.873271 ms
[2025-11-30T09:30:53.391+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 6.951125 ms
[2025-11-30T09:30:53.400+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 6.158062 ms
[2025-11-30T09:30:53.417+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_59_piece0 on fa0622e2494f:33513 in memory (size: 23.0 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.419+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_61_piece0 on fa0622e2494f:33513 in memory (size: 19.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.422+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 66.0 (TID 42). 5244 bytes result sent to driver
[2025-11-30T09:30:53.423+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 66.0 (TID 42) in 75 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.423+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 66.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.424+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ResultStage 66 (collect at /opt/***/scripts/dq_report.py:182) finished in 0.080 s
[2025-11-30T09:30:53.425+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 42 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:53.426+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 66: Stage finished
[2025-11-30T09:30:53.426+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 42 finished: collect at /opt/***/scripts/dq_report.py:182, took 0.084400 s
[2025-11-30T09:30:53.432+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:53,432 - INFO - Daily city-level DQ records: 1
[2025-11-30T09:30:53.433+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:53,432 - INFO - Generating report JSON...
[2025-11-30T09:30:53.455+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:53.456+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:53.457+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:53.482+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 14.884965 ms
[2025-11-30T09:30:53.485+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_63 stored as values in memory (estimated size 207.2 KiB, free 433.7 MiB)
[2025-11-30T09:30:53.491+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_63_piece0 stored as bytes in memory (estimated size 34.8 KiB, free 433.6 MiB)
[2025-11-30T09:30:53.492+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_63_piece0 in memory on fa0622e2494f:33513 (size: 34.8 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.493+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 63 from collect at /opt/***/scripts/dq_report.py:189
[2025-11-30T09:30:53.494+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:53.497+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Registering RDD 155 (collect at /opt/***/scripts/dq_report.py:189) as input to shuffle 22
[2025-11-30T09:30:53.498+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got map stage job 43 (collect at /opt/***/scripts/dq_report.py:189) with 1 output partitions
[2025-11-30T09:30:53.499+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ShuffleMapStage 67 (collect at /opt/***/scripts/dq_report.py:189)
[2025-11-30T09:30:53.500+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:53.500+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.501+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ShuffleMapStage 67 (MapPartitionsRDD[155] at collect at /opt/***/scripts/dq_report.py:189), which has no missing parents
[2025-11-30T09:30:53.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_64 stored as values in memory (estimated size 39.3 KiB, free 433.6 MiB)
[2025-11-30T09:30:53.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_64_piece0 stored as bytes in memory (estimated size 17.5 KiB, free 433.6 MiB)
[2025-11-30T09:30:53.503+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_64_piece0 in memory on fa0622e2494f:33513 (size: 17.5 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.504+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 64 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.504+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 67 (MapPartitionsRDD[155] at collect at /opt/***/scripts/dq_report.py:189) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 67.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 67.0 (TID 43) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:53.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 67.0 (TID 43)
[2025-11-30T09:30:53.521+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 14.120766 ms
[2025-11-30T09:30:53.528+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 4.218908 ms
[2025-11-30T09:30:53.537+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 3.947766 ms
[2025-11-30T09:30:53.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:53.560+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 67.0 (TID 43). 3105 bytes result sent to driver
[2025-11-30T09:30:53.561+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 67.0 (TID 43) in 58 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.562+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 67.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.563+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ShuffleMapStage 67 (collect at /opt/***/scripts/dq_report.py:189) finished in 0.063 s
[2025-11-30T09:30:53.564+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:53.564+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:53.565+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:53.566+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:53.567+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShufflePartitionsUtil: For shuffle(22), advisory target size: 67108864, actual target size 1048576, minimum partition size: 1048576
[2025-11-30T09:30:53.582+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 13.005082 ms
[2025-11-30T09:30:53.592+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Starting job: collect at /opt/***/scripts/dq_report.py:189
[2025-11-30T09:30:53.593+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got job 44 (collect at /opt/***/scripts/dq_report.py:189) with 1 output partitions
[2025-11-30T09:30:53.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ResultStage 69 (collect at /opt/***/scripts/dq_report.py:189)
[2025-11-30T09:30:53.595+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 68)
[2025-11-30T09:30:53.596+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ResultStage 69 (MapPartitionsRDD[158] at collect at /opt/***/scripts/dq_report.py:189), which has no missing parents
[2025-11-30T09:30:53.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_65 stored as values in memory (estimated size 42.1 KiB, free 433.5 MiB)
[2025-11-30T09:30:53.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_65_piece0 stored as bytes in memory (estimated size 19.1 KiB, free 433.5 MiB)
[2025-11-30T09:30:53.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_65_piece0 in memory on fa0622e2494f:33513 (size: 19.1 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 65 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 69 (MapPartitionsRDD[158] at collect at /opt/***/scripts/dq_report.py:189) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 69.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 69.0 (TID 44) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:53.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 69.0 (TID 44)
[2025-11-30T09:30:53.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:53.606+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:53.618+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 12.211775 ms
[2025-11-30T09:30:53.624+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 69.0 (TID 44). 5498 bytes result sent to driver
[2025-11-30T09:30:53.626+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 69.0 (TID 44) in 25 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.627+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 69.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.628+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ResultStage 69 (collect at /opt/***/scripts/dq_report.py:189) finished in 0.031 s
[2025-11-30T09:30:53.629+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 44 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:53.630+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 69: Stage finished
[2025-11-30T09:30:53.631+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 44 finished: collect at /opt/***/scripts/dq_report.py:189, took 0.035227 s
[2025-11-30T09:30:53.633+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:53,632 - INFO - Computing pairwise Pearson correlations between pollutants...
[2025-11-30T09:30:53.670+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:53.672+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:53.673+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:53.718+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 9.914307 ms
[2025-11-30T09:30:53.720+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_66 stored as values in memory (estimated size 207.3 KiB, free 433.3 MiB)
[2025-11-30T09:30:53.728+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_65_piece0 on fa0622e2494f:33513 in memory (size: 19.1 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.731+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_62_piece0 on fa0622e2494f:33513 in memory (size: 21.1 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.733+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_64_piece0 on fa0622e2494f:33513 in memory (size: 17.5 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.734+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_66_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.5 MiB)
[2025-11-30T09:30:53.735+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_66_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.736+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 66 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:53.737+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:53.740+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Registering RDD 162 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 23
[2025-11-30T09:30:53.744+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got map stage job 45 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:53.746+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ShuffleMapStage 70 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:53.747+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:53.747+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ShuffleMapStage 70 (MapPartitionsRDD[162] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:53.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_67 stored as values in memory (estimated size 33.9 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.749+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_67_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.749+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_67_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.750+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 67 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.750+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 70 (MapPartitionsRDD[162] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.751+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 70.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 70.0 (TID 45) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:53.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 70.0 (TID 45)
[2025-11-30T09:30:53.759+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 9.692214 ms
[2025-11-30T09:30:53.761+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:53.782+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 70.0 (TID 45). 2136 bytes result sent to driver
[2025-11-30T09:30:53.784+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 70.0 (TID 45) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.785+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 70.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.785+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ShuffleMapStage 70 (corr at NativeMethodAccessorImpl.java:0) finished in 0.042 s
[2025-11-30T09:30:53.786+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:53.787+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:53.788+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:53.788+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:53.812+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 10.17881 ms
[2025-11-30T09:30:53.822+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:53.823+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got job 46 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:53.823+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ResultStage 72 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:53.824+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 71)
[2025-11-30T09:30:53.824+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ResultStage 72 (MapPartitionsRDD[165] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:53.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_68 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.825+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_68_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_68_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.826+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 68 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 72 (MapPartitionsRDD[165] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 72.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 72.0 (TID 46) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:53.829+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 72.0 (TID 46)
[2025-11-30T09:30:53.831+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:53.832+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:53.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 10.929848 ms
[2025-11-30T09:30:53.845+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 72.0 (TID 46). 3989 bytes result sent to driver
[2025-11-30T09:30:53.846+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 72.0 (TID 46) in 19 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.847+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 72.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.847+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ResultStage 72 (corr at NativeMethodAccessorImpl.java:0) finished in 0.023 s
[2025-11-30T09:30:53.848+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 46 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:53.848+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 72: Stage finished
[2025-11-30T09:30:53.849+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 46 finished: corr at NativeMethodAccessorImpl.java:0, took 0.025570 s
[2025-11-30T09:30:53.861+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO CodeGenerator: Code generated in 3.327515 ms
[2025-11-30T09:30:53.884+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:53.885+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:53.885+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:53.908+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_69 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:53.913+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_69_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:53.914+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_69_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.915+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 69 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:53.915+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:53.918+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Registering RDD 169 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 24
[2025-11-30T09:30:53.918+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got map stage job 47 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:53.919+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ShuffleMapStage 73 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:53.919+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:53.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ShuffleMapStage 73 (MapPartitionsRDD[169] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:53.923+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_70 stored as values in memory (estimated size 33.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:53.926+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_70_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T09:30:53.926+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_70_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.927+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_67_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.928+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 70 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.929+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 73 (MapPartitionsRDD[169] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.929+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 73.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.930+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_68_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.931+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 73.0 (TID 47) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:53.932+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 73.0 (TID 47)
[2025-11-30T09:30:53.932+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Removed broadcast_66_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:53.933+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:53.948+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 73.0 (TID 47). 2136 bytes result sent to driver
[2025-11-30T09:30:53.949+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 73.0 (TID 47) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.950+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 73.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.951+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ShuffleMapStage 73 (corr at NativeMethodAccessorImpl.java:0) finished in 0.030 s
[2025-11-30T09:30:53.951+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:53.952+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:53.953+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:53.953+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:53.971+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:53.972+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Got job 48 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:53.972+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Final stage: ResultStage 75 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:53.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 74)
[2025-11-30T09:30:53.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:53.974+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting ResultStage 75 (MapPartitionsRDD[172] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:53.974+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_71 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.975+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO MemoryStore: Block broadcast_71_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:53.976+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO BlockManagerInfo: Added broadcast_71_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:53.977+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO SparkContext: Created broadcast 71 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:53.977+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 75 (MapPartitionsRDD[172] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:53.978+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Adding task set 75.0 with 1 tasks resource profile 0
[2025-11-30T09:30:53.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Starting task 0.0 in stage 75.0 (TID 48) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:53.979+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Running task 0.0 in stage 75.0 (TID 48)
[2025-11-30T09:30:53.980+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:53.980+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:53.981+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO Executor: Finished task 0.0 in stage 75.0 (TID 48). 3989 bytes result sent to driver
[2025-11-30T09:30:53.982+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSetManager: Finished task 0.0 in stage 75.0 (TID 48) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:53.983+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Removed TaskSet 75.0, whose tasks have all completed, from pool
[2025-11-30T09:30:53.983+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: ResultStage 75 (corr at NativeMethodAccessorImpl.java:0) finished in 0.010 s
[2025-11-30T09:30:53.984+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 48 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:53.984+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO TaskSchedulerImpl: Killing all running tasks in stage 75: Stage finished
[2025-11-30T09:30:53.985+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:53 INFO DAGScheduler: Job 48 finished: corr at NativeMethodAccessorImpl.java:0, took 0.012266 s
[2025-11-30T09:30:54.008+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.009+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.010+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.030+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_72 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.036+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_72_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.037+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_72_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.037+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 72 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.038+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.041+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 176 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 25
[2025-11-30T09:30:54.041+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 49 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.042+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 76 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.043+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.044+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.044+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 76 (MapPartitionsRDD[176] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.045+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_73 stored as values in memory (estimated size 33.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.045+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_73_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.046+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_73_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.046+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 73 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.047+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 76 (MapPartitionsRDD[176] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.047+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 76.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.048+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 76.0 (TID 49) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.048+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 76.0 (TID 49)
[2025-11-30T09:30:54.049+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.061+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 76.0 (TID 49). 2136 bytes result sent to driver
[2025-11-30T09:30:54.062+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 76.0 (TID 49) in 16 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.066+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 76.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.066+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 76 (corr at NativeMethodAccessorImpl.java:0) finished in 0.021 s
[2025-11-30T09:30:54.067+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.068+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.069+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.070+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.086+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.087+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 50 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.088+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 78 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.089+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 77)
[2025-11-30T09:30:54.090+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.090+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 78 (MapPartitionsRDD[179] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.092+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_74 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.096+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_74_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.097+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_74_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.098+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_71_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.099+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 74 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.099+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 78 (MapPartitionsRDD[179] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 78.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_69_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.101+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 78.0 (TID 50) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.101+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 78.0 (TID 50)
[2025-11-30T09:30:54.102+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_70_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.102+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_73_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.103+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.103+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.104+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 78.0 (TID 50). 3989 bytes result sent to driver
[2025-11-30T09:30:54.104+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 78.0 (TID 50) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 78.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 78 (corr at NativeMethodAccessorImpl.java:0) finished in 0.015 s
[2025-11-30T09:30:54.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 50 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 78: Stage finished
[2025-11-30T09:30:54.107+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 50 finished: corr at NativeMethodAccessorImpl.java:0, took 0.017733 s
[2025-11-30T09:30:54.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.147+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_75 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.152+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_75_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.153+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_75_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.154+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 75 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.154+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.158+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 183 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 26
[2025-11-30T09:30:54.159+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 51 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.160+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 79 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.161+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.162+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.163+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 79 (MapPartitionsRDD[183] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.164+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_76 stored as values in memory (estimated size 33.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.164+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_76_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.165+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_76_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.166+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 76 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.167+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 79 (MapPartitionsRDD[183] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.168+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 79.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.169+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 79.0 (TID 51) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.170+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 79.0 (TID 51)
[2025-11-30T09:30:54.170+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.183+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 79.0 (TID 51). 2136 bytes result sent to driver
[2025-11-30T09:30:54.184+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 79.0 (TID 51) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.185+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 79.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.185+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 79 (corr at NativeMethodAccessorImpl.java:0) finished in 0.025 s
[2025-11-30T09:30:54.186+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.187+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.187+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.188+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.201+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 52 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 81 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.203+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 80)
[2025-11-30T09:30:54.203+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 81 (MapPartitionsRDD[186] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.205+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_77 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.205+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_77_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.206+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_77_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.207+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 77 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.207+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 81 (MapPartitionsRDD[186] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.208+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 81.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.208+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 81.0 (TID 52) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.209+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 81.0 (TID 52)
[2025-11-30T09:30:54.209+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.210+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.214+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 81.0 (TID 52). 4075 bytes result sent to driver
[2025-11-30T09:30:54.215+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_76_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.216+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 81.0 (TID 52) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.217+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 81.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.218+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_74_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.219+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 81 (corr at NativeMethodAccessorImpl.java:0) finished in 0.014 s
[2025-11-30T09:30:54.221+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 52 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.222+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 81: Stage finished
[2025-11-30T09:30:54.222+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 52 finished: corr at NativeMethodAccessorImpl.java:0, took 0.017343 s
[2025-11-30T09:30:54.223+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_72_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.245+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.263+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_78 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.268+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_78_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.269+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_78_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.270+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 78 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.271+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.273+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 190 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 27
[2025-11-30T09:30:54.274+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 53 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.274+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 82 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.275+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.276+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.276+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 82 (MapPartitionsRDD[190] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.277+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_79 stored as values in memory (estimated size 33.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.278+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_79_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.279+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_79_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.280+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 79 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.280+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 82 (MapPartitionsRDD[190] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.281+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 82.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.282+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 82.0 (TID 53) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.282+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 82.0 (TID 53)
[2025-11-30T09:30:54.283+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.296+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 82.0 (TID 53). 2136 bytes result sent to driver
[2025-11-30T09:30:54.297+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 82.0 (TID 53) in 19 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.298+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 82.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.298+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 82 (corr at NativeMethodAccessorImpl.java:0) finished in 0.023 s
[2025-11-30T09:30:54.299+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.299+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.300+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.300+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.319+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.320+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 54 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.321+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 84 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.322+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 83)
[2025-11-30T09:30:54.323+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.324+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 84 (MapPartitionsRDD[193] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.325+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_80 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.326+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_80_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.327+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_80_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.328+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 80 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.329+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 84 (MapPartitionsRDD[193] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 84.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 84.0 (TID 54) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.331+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 84.0 (TID 54)
[2025-11-30T09:30:54.332+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.333+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.334+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 84.0 (TID 54). 3989 bytes result sent to driver
[2025-11-30T09:30:54.335+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 84.0 (TID 54) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.336+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 84.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.337+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 84 (corr at NativeMethodAccessorImpl.java:0) finished in 0.013 s
[2025-11-30T09:30:54.338+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 54 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 84: Stage finished
[2025-11-30T09:30:54.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 54 finished: corr at NativeMethodAccessorImpl.java:0, took 0.015213 s
[2025-11-30T09:30:54.358+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.359+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.360+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.380+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_81 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T09:30:54.389+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_80_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.391+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_77_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.393+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_81_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 432.9 MiB)
[2025-11-30T09:30:54.394+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_81_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.395+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 81 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.395+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_79_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.396+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.397+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_75_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.398+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_78_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.399+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 197 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 28
[2025-11-30T09:30:54.400+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 55 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.401+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 85 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.402+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.403+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.404+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 85 (MapPartitionsRDD[197] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.406+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_82 stored as values in memory (estimated size 33.9 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.406+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_82_piece0 stored as bytes in memory (estimated size 12.7 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.407+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_82_piece0 in memory on fa0622e2494f:33513 (size: 12.7 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.408+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 82 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.409+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 85 (MapPartitionsRDD[197] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.410+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 85.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.410+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 85.0 (TID 55) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.411+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 85.0 (TID 55)
[2025-11-30T09:30:54.412+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.429+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 85.0 (TID 55). 2136 bytes result sent to driver
[2025-11-30T09:30:54.430+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 85.0 (TID 55) in 26 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.431+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 85.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.432+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 85 (corr at NativeMethodAccessorImpl.java:0) finished in 0.030 s
[2025-11-30T09:30:54.433+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.434+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.435+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.435+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 56 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.450+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 87 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.450+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 86)
[2025-11-30T09:30:54.451+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.452+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 87 (MapPartitionsRDD[200] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.453+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_83 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.453+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_83_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.454+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_83_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.455+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 83 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.456+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 87 (MapPartitionsRDD[200] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.456+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 87.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.457+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 87.0 (TID 56) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.458+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 87.0 (TID 56)
[2025-11-30T09:30:54.458+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.459+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.460+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 87.0 (TID 56). 3989 bytes result sent to driver
[2025-11-30T09:30:54.461+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 87.0 (TID 56) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.462+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 87.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.462+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 87 (corr at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T09:30:54.463+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 56 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.464+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 87: Stage finished
[2025-11-30T09:30:54.465+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 56 finished: corr at NativeMethodAccessorImpl.java:0, took 0.013816 s
[2025-11-30T09:30:54.484+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.485+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.486+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.514+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO CodeGenerator: Code generated in 12.037222 ms
[2025-11-30T09:30:54.517+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_84 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_84_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.525+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_84_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.525+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 84 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.526+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.529+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 204 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 29
[2025-11-30T09:30:54.530+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 57 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.531+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 88 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.532+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.532+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.535+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 88 (MapPartitionsRDD[204] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.536+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_85 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_85_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.546+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_85_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.547+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_83_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.548+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 85 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.548+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 88 (MapPartitionsRDD[204] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.549+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 88.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.549+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_82_piece0 on fa0622e2494f:33513 in memory (size: 12.7 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.550+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 88.0 (TID 57) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 88.0 (TID 57)
[2025-11-30T09:30:54.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_81_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.555+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO CodeGenerator: Code generated in 8.904774 ms
[2025-11-30T09:30:54.556+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.578+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 88.0 (TID 57). 2136 bytes result sent to driver
[2025-11-30T09:30:54.579+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 88.0 (TID 57) in 38 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.580+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 88.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.580+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 88 (corr at NativeMethodAccessorImpl.java:0) finished in 0.049 s
[2025-11-30T09:30:54.580+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.581+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.581+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.582+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 58 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 90 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 89)
[2025-11-30T09:30:54.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 90 (MapPartitionsRDD[207] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_86 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_86_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_86_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 86 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 90 (MapPartitionsRDD[207] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 90.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 90.0 (TID 58) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 90.0 (TID 58)
[2025-11-30T09:30:54.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.609+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 90.0 (TID 58). 3989 bytes result sent to driver
[2025-11-30T09:30:54.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 90.0 (TID 58) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.611+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 90.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.612+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 90 (corr at NativeMethodAccessorImpl.java:0) finished in 0.011 s
[2025-11-30T09:30:54.613+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 58 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.614+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 90: Stage finished
[2025-11-30T09:30:54.614+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 58 finished: corr at NativeMethodAccessorImpl.java:0, took 0.014062 s
[2025-11-30T09:30:54.650+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.650+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.651+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.672+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_87 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.679+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_87_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.681+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_87_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.681+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 87 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.682+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.685+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 211 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 30
[2025-11-30T09:30:54.685+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 59 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.686+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 91 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.687+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.687+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.688+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 91 (MapPartitionsRDD[211] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.689+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_88 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.690+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_88_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.691+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_88_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.691+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 88 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 91 (MapPartitionsRDD[211] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 91.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.692+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 91.0 (TID 59) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.693+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 91.0 (TID 59)
[2025-11-30T09:30:54.694+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.721+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 91.0 (TID 59). 2222 bytes result sent to driver
[2025-11-30T09:30:54.722+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_84_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.723+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 91.0 (TID 59) in 32 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.724+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 91.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.725+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 91 (corr at NativeMethodAccessorImpl.java:0) finished in 0.037 s
[2025-11-30T09:30:54.725+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.726+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.727+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.727+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.728+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_86_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.729+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_85_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.739+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.740+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 60 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.741+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 93 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.742+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 92)
[2025-11-30T09:30:54.742+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.743+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 93 (MapPartitionsRDD[214] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.745+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_89 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.745+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_89_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:54.746+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_89_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.747+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 89 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 93 (MapPartitionsRDD[214] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 93.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.749+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 93.0 (TID 60) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.750+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 93.0 (TID 60)
[2025-11-30T09:30:54.751+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 93.0 (TID 60). 3989 bytes result sent to driver
[2025-11-30T09:30:54.753+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 93.0 (TID 60) in 5 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.753+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 93.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.754+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 93 (corr at NativeMethodAccessorImpl.java:0) finished in 0.010 s
[2025-11-30T09:30:54.755+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 60 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.756+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 93: Stage finished
[2025-11-30T09:30:54.756+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 60 finished: corr at NativeMethodAccessorImpl.java:0, took 0.011157 s
[2025-11-30T09:30:54.771+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.772+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.773+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.789+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_90 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.795+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_90_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.796+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_90_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.797+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 90 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.798+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.800+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 218 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 31
[2025-11-30T09:30:54.801+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 61 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 94 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.803+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.804+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 94 (MapPartitionsRDD[218] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.804+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_91 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.805+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_91_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.806+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_91_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.806+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 91 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.807+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 94 (MapPartitionsRDD[218] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.808+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 94.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.809+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 94.0 (TID 61) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.809+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 94.0 (TID 61)
[2025-11-30T09:30:54.810+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.832+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 94.0 (TID 61). 2136 bytes result sent to driver
[2025-11-30T09:30:54.833+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 94.0 (TID 61) in 28 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.834+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 94.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.835+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 94 (corr at NativeMethodAccessorImpl.java:0) finished in 0.032 s
[2025-11-30T09:30:54.836+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.837+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.837+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.838+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:54.854+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.855+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got job 62 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.856+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ResultStage 96 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.856+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 95)
[2025-11-30T09:30:54.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.857+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ResultStage 96 (MapPartitionsRDD[221] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.858+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_92 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.863+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_92_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.864+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_91_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.865+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_92_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.865+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 92 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.866+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 96 (MapPartitionsRDD[221] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.866+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 96.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.867+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_87_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.868+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 96.0 (TID 62) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:54.869+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 96.0 (TID 62)
[2025-11-30T09:30:54.869+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_89_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.870+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Removed broadcast_88_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:54.870+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:54.871+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:54.873+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 96.0 (TID 62). 3989 bytes result sent to driver
[2025-11-30T09:30:54.874+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 96.0 (TID 62) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.875+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 96.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.876+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ResultStage 96 (corr at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-11-30T09:30:54.877+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 62 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:54.877+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Killing all running tasks in stage 96: Stage finished
[2025-11-30T09:30:54.878+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Job 62 finished: corr at NativeMethodAccessorImpl.java:0, took 0.021604 s
[2025-11-30T09:30:54.898+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:54.899+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:54.900+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:54.922+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_93 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.930+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_93_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.931+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_93_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.932+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 93 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:54.933+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:54.944+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Registering RDD 225 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 32
[2025-11-30T09:30:54.945+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Got map stage job 63 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:54.946+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Final stage: ShuffleMapStage 97 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:54.947+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:54.949+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:54.949+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting ShuffleMapStage 97 (MapPartitionsRDD[225] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:54.950+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_94 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T09:30:54.951+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO MemoryStore: Block broadcast_94_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:54.952+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO BlockManagerInfo: Added broadcast_94_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:54.954+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO SparkContext: Created broadcast 94 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:54.955+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 97 (MapPartitionsRDD[225] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:54.955+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Adding task set 97.0 with 1 tasks resource profile 0
[2025-11-30T09:30:54.956+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Starting task 0.0 in stage 97.0 (TID 63) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:54.957+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Running task 0.0 in stage 97.0 (TID 63)
[2025-11-30T09:30:54.961+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:54.989+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO Executor: Finished task 0.0 in stage 97.0 (TID 63). 2136 bytes result sent to driver
[2025-11-30T09:30:54.992+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSetManager: Finished task 0.0 in stage 97.0 (TID 63) in 37 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:54.993+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO TaskSchedulerImpl: Removed TaskSet 97.0, whose tasks have all completed, from pool
[2025-11-30T09:30:54.994+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: ShuffleMapStage 97 (corr at NativeMethodAccessorImpl.java:0) finished in 0.046 s
[2025-11-30T09:30:54.995+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:54.995+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:54.996+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:54.997+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:54 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.015+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.016+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 64 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.017+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 99 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.017+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 98)
[2025-11-30T09:30:55.018+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.018+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 99 (MapPartitionsRDD[228] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.019+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_95 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.020+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_95_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.020+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_95_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.021+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 95 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.022+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 99 (MapPartitionsRDD[228] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.022+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 99.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.023+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 99.0 (TID 64) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.024+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 99.0 (TID 64)
[2025-11-30T09:30:55.025+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.026+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.034+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_94_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.035+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 99.0 (TID 64). 4032 bytes result sent to driver
[2025-11-30T09:30:55.036+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 99.0 (TID 64) in 14 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.037+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 99.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.038+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_92_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.038+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 99 (corr at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-11-30T09:30:55.039+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 64 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.040+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 99: Stage finished
[2025-11-30T09:30:55.040+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 64 finished: corr at NativeMethodAccessorImpl.java:0, took 0.021908 s
[2025-11-30T09:30:55.041+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_90_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.068+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.069+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.070+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO CodeGenerator: Code generated in 14.268904 ms
[2025-11-30T09:30:55.108+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_96 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.115+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_96_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.116+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_96_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.116+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 96 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.118+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 232 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 33
[2025-11-30T09:30:55.126+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 65 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 100 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 100 (MapPartitionsRDD[232] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.130+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_97 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.131+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_97_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.132+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_97_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.133+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 97 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.134+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 100 (MapPartitionsRDD[232] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.135+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 100.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.136+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 100.0 (TID 65) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.137+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 100.0 (TID 65)
[2025-11-30T09:30:55.149+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO CodeGenerator: Code generated in 12.812749 ms
[2025-11-30T09:30:55.150+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.172+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 100.0 (TID 65). 2136 bytes result sent to driver
[2025-11-30T09:30:55.173+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 100.0 (TID 65) in 42 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.175+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 100.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.176+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 100 (corr at NativeMethodAccessorImpl.java:0) finished in 0.048 s
[2025-11-30T09:30:55.177+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.177+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.178+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.181+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.201+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 66 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 102 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 101)
[2025-11-30T09:30:55.204+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.205+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 102 (MapPartitionsRDD[235] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.206+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_98 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.207+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_98_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.208+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_98_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.209+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 98 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.210+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 102 (MapPartitionsRDD[235] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.211+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 102.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.211+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 102.0 (TID 66) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.212+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 102.0 (TID 66)
[2025-11-30T09:30:55.213+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.213+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.216+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 102.0 (TID 66). 3989 bytes result sent to driver
[2025-11-30T09:30:55.217+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 102.0 (TID 66) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.218+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 102.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.219+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 102 (corr at NativeMethodAccessorImpl.java:0) finished in 0.015 s
[2025-11-30T09:30:55.220+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 66 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.220+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 102: Stage finished
[2025-11-30T09:30:55.221+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 66 finished: corr at NativeMethodAccessorImpl.java:0, took 0.019032 s
[2025-11-30T09:30:55.248+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.250+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.251+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.280+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_99 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T09:30:55.292+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_97_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.294+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_93_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.295+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_99_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.296+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_99_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.297+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 99 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.298+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.299+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_96_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.300+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_98_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.301+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_95_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.302+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 239 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 34
[2025-11-30T09:30:55.303+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 67 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.304+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 103 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.304+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.305+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.308+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 103 (MapPartitionsRDD[239] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.309+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_100 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.310+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_100_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.311+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_100_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.312+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 100 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.313+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 103 (MapPartitionsRDD[239] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.314+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 103.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.315+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 103.0 (TID 67) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.315+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 103.0 (TID 67)
[2025-11-30T09:30:55.316+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.336+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 103.0 (TID 67). 2136 bytes result sent to driver
[2025-11-30T09:30:55.337+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 103.0 (TID 67) in 28 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.338+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 103.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 103 (corr at NativeMethodAccessorImpl.java:0) finished in 0.035 s
[2025-11-30T09:30:55.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.340+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.340+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.341+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.361+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.363+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 68 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.364+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 105 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.365+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 104)
[2025-11-30T09:30:55.365+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.366+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 105 (MapPartitionsRDD[242] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.368+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_101 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.369+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_101_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.370+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_101_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.371+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 101 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.372+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 105 (MapPartitionsRDD[242] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.372+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 105.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.373+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 105.0 (TID 68) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.374+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 105.0 (TID 68)
[2025-11-30T09:30:55.377+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.378+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.380+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 105.0 (TID 68). 3989 bytes result sent to driver
[2025-11-30T09:30:55.381+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 105.0 (TID 68) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 105.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.383+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 105 (corr at NativeMethodAccessorImpl.java:0) finished in 0.017 s
[2025-11-30T09:30:55.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 68 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.385+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 105: Stage finished
[2025-11-30T09:30:55.385+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 68 finished: corr at NativeMethodAccessorImpl.java:0, took 0.021387 s
[2025-11-30T09:30:55.412+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.413+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.414+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.436+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_102 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_99_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.452+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_100_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.454+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_101_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.455+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_102_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.5 MiB)
[2025-11-30T09:30:55.456+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_102_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.457+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 102 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.458+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.462+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 246 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 35
[2025-11-30T09:30:55.463+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 69 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.464+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 106 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.465+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.466+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.467+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 106 (MapPartitionsRDD[246] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.468+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_103 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.468+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_103_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.469+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_103_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 103 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 106 (MapPartitionsRDD[246] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.471+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 106.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.472+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 106.0 (TID 69) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.473+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 106.0 (TID 69)
[2025-11-30T09:30:55.474+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.492+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 106.0 (TID 69). 2136 bytes result sent to driver
[2025-11-30T09:30:55.494+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 106.0 (TID 69) in 25 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.495+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 106.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.495+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 106 (corr at NativeMethodAccessorImpl.java:0) finished in 0.031 s
[2025-11-30T09:30:55.496+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.497+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.497+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.498+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.511+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.512+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 70 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.513+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 108 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.514+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 107)
[2025-11-30T09:30:55.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.515+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 108 (MapPartitionsRDD[249] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.516+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_104 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.516+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_104_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.517+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_104_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.518+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 104 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.518+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 108 (MapPartitionsRDD[249] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.519+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 108.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.520+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 108.0 (TID 70) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.520+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 108.0 (TID 70)
[2025-11-30T09:30:55.521+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.522+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 108.0 (TID 70). 3989 bytes result sent to driver
[2025-11-30T09:30:55.525+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 108.0 (TID 70) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.525+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 108.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.526+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 108 (corr at NativeMethodAccessorImpl.java:0) finished in 0.012 s
[2025-11-30T09:30:55.526+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 70 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.527+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 108: Stage finished
[2025-11-30T09:30:55.528+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 70 finished: corr at NativeMethodAccessorImpl.java:0, took 0.014376 s
[2025-11-30T09:30:55.557+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.558+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.559+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.581+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_105 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.592+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_103_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_105_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.594+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_105_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.595+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_104_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.596+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 105 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_102_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 253 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 36
[2025-11-30T09:30:55.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 71 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 109 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 109 (MapPartitionsRDD[253] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.606+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_106 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_106_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_106_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 106 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.609+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 109 (MapPartitionsRDD[253] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 109.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.611+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 109.0 (TID 71) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.612+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 109.0 (TID 71)
[2025-11-30T09:30:55.613+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.632+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 109.0 (TID 71). 2136 bytes result sent to driver
[2025-11-30T09:30:55.633+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 109.0 (TID 71) in 26 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.634+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 109.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.635+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 109 (corr at NativeMethodAccessorImpl.java:0) finished in 0.031 s
[2025-11-30T09:30:55.635+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.636+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.637+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.638+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.654+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.655+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 72 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.656+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 111 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.657+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 110)
[2025-11-30T09:30:55.658+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.658+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 111 (MapPartitionsRDD[256] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.659+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_107 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.660+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_107_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.661+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_107_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.662+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 107 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.662+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 111 (MapPartitionsRDD[256] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.663+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 111.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.663+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 111.0 (TID 72) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.664+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 111.0 (TID 72)
[2025-11-30T09:30:55.667+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.668+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
[2025-11-30T09:30:55.670+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 111.0 (TID 72). 3989 bytes result sent to driver
[2025-11-30T09:30:55.671+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 111.0 (TID 72) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.672+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 111.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.673+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 111 (corr at NativeMethodAccessorImpl.java:0) finished in 0.016 s
[2025-11-30T09:30:55.674+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 72 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.675+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 111: Stage finished
[2025-11-30T09:30:55.676+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 72 finished: corr at NativeMethodAccessorImpl.java:0, took 0.019047 s
[2025-11-30T09:30:55.710+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.711+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.712+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.737+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_108 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_106_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.750+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_107_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_108_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.752+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_108_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.753+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 108 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.754+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_105_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.754+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.758+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 260 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 37
[2025-11-30T09:30:55.759+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 73 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.760+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 112 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.761+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.761+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.762+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 112 (MapPartitionsRDD[260] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.762+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_109 stored as values in memory (estimated size 33.0 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.763+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_109_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.764+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_109_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:55.765+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 109 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.766+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 112 (MapPartitionsRDD[260] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.767+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 112.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.768+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 112.0 (TID 73) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.768+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 112.0 (TID 73)
[2025-11-30T09:30:55.772+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.796+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 112.0 (TID 73). 2136 bytes result sent to driver
[2025-11-30T09:30:55.797+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 112.0 (TID 73) in 32 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.798+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 112.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.799+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 112 (corr at NativeMethodAccessorImpl.java:0) finished in 0.039 s
[2025-11-30T09:30:55.800+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.801+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.802+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.827+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 74 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.828+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 114 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.829+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 113)
[2025-11-30T09:30:55.830+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.830+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 114 (MapPartitionsRDD[263] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.831+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_110 stored as values in memory (estimated size 22.2 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.832+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_110_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.4 MiB)
[2025-11-30T09:30:55.833+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_110_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.833+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 110 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.834+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 114 (MapPartitionsRDD[263] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.835+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 114.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.835+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 114.0 (TID 74) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.836+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 114.0 (TID 74)
[2025-11-30T09:30:55.837+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.838+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.840+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 114.0 (TID 74). 3989 bytes result sent to driver
[2025-11-30T09:30:55.842+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 114.0 (TID 74) in 8 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 114.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.843+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 114 (corr at NativeMethodAccessorImpl.java:0) finished in 0.014 s
[2025-11-30T09:30:55.844+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 74 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.844+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 114: Stage finished
[2025-11-30T09:30:55.845+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 74 finished: corr at NativeMethodAccessorImpl.java:0, took 0.016297 s
[2025-11-30T09:30:55.874+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:55.875+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:55.876+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:55.899+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_111 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:55.908+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_111_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.909+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_111_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.910+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 111 from corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.910+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:55.913+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Registering RDD 267 (corr at NativeMethodAccessorImpl.java:0) as input to shuffle 38
[2025-11-30T09:30:55.914+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got map stage job 75 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.915+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ShuffleMapStage 115 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.915+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:55.916+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.916+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ShuffleMapStage 115 (MapPartitionsRDD[267] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.917+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_112 stored as values in memory (estimated size 33.0 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.917+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_112_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.918+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_112_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.919+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 112 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.919+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 115 (MapPartitionsRDD[267] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 115.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 115.0 (TID 75) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:55.920+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 115.0 (TID 75)
[2025-11-30T09:30:55.923+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:55.941+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 115.0 (TID 75). 2136 bytes result sent to driver
[2025-11-30T09:30:55.942+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 115.0 (TID 75) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.943+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 115.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.944+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ShuffleMapStage 115 (corr at NativeMethodAccessorImpl.java:0) finished in 0.029 s
[2025-11-30T09:30:55.944+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:55.945+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:55.945+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:55.946+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:55.963+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Starting job: corr at NativeMethodAccessorImpl.java:0
[2025-11-30T09:30:55.964+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Got job 76 (corr at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2025-11-30T09:30:55.965+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Final stage: ResultStage 117 (corr at NativeMethodAccessorImpl.java:0)
[2025-11-30T09:30:55.965+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 116)
[2025-11-30T09:30:55.966+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:55.966+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting ResultStage 117 (MapPartitionsRDD[270] at corr at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:55.966+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_113 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.967+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO MemoryStore: Block broadcast_113_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:55.968+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Added broadcast_113_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.969+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO SparkContext: Created broadcast 113 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:55.969+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 117 (MapPartitionsRDD[270] at corr at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:55.970+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Adding task set 117.0 with 1 tasks resource profile 0
[2025-11-30T09:30:55.970+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Starting task 0.0 in stage 117.0 (TID 76) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:55.970+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Running task 0.0 in stage 117.0 (TID 76)
[2025-11-30T09:30:55.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:55.973+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:55.982+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO Executor: Finished task 0.0 in stage 117.0 (TID 76). 4075 bytes result sent to driver
[2025-11-30T09:30:55.983+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_112_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.984+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSetManager: Finished task 0.0 in stage 117.0 (TID 76) in 14 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:55.985+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Removed TaskSet 117.0, whose tasks have all completed, from pool
[2025-11-30T09:30:55.986+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_110_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.987+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: ResultStage 117 (corr at NativeMethodAccessorImpl.java:0) finished in 0.019 s
[2025-11-30T09:30:55.988+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 76 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:55.992+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO TaskSchedulerImpl: Killing all running tasks in stage 117: Stage finished
[2025-11-30T09:30:55.994+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO DAGScheduler: Job 76 finished: corr at NativeMethodAccessorImpl.java:0, took 0.021767 s
[2025-11-30T09:30:55.995+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_108_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:55.995+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:55 INFO BlockManagerInfo: Removed broadcast_109_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.3 MiB)
[2025-11-30T09:30:56.023+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:56.025+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:56.026+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:56.049+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_114 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.057+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_114_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.057+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_114_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.058+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 114 from corr at <unknown>:0
[2025-11-30T09:30:56.059+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:56.064+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Registering RDD 274 (corr at <unknown>:0) as input to shuffle 39
[2025-11-30T09:30:56.065+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got map stage job 77 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.066+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ShuffleMapStage 118 (corr at <unknown>:0)
[2025-11-30T09:30:56.067+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.068+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.069+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 118 (MapPartitionsRDD[274] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.070+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_115 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.071+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_115_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.071+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_115_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.072+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 115 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.072+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 118 (MapPartitionsRDD[274] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.073+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 118.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.074+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 118.0 (TID 77) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:56.075+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 118.0 (TID 77)
[2025-11-30T09:30:56.078+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:56.100+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 118.0 (TID 77). 2136 bytes result sent to driver
[2025-11-30T09:30:56.101+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 118.0 (TID 77) in 29 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.103+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 118.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.104+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ShuffleMapStage 118 (corr at <unknown>:0) finished in 0.037 s
[2025-11-30T09:30:56.104+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:56.105+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:56.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:56.106+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:56.120+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T09:30:56.121+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 78 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.122+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 120 (corr at <unknown>:0)
[2025-11-30T09:30:56.123+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 119)
[2025-11-30T09:30:56.124+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 120 (MapPartitionsRDD[277] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.125+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_116 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.126+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_116_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_116_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.127+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 116 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 120 (MapPartitionsRDD[277] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.128+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 120.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 120.0 (TID 78) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:56.129+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 120.0 (TID 78)
[2025-11-30T09:30:56.130+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:56.131+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:56.133+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 120.0 (TID 78). 3989 bytes result sent to driver
[2025-11-30T09:30:56.134+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 120.0 (TID 78) in 7 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.134+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 120.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.135+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ResultStage 120 (corr at <unknown>:0) finished in 0.013 s
[2025-11-30T09:30:56.136+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 78 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:56.136+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 120: Stage finished
[2025-11-30T09:30:56.138+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 78 finished: corr at <unknown>:0, took 0.014631 s
[2025-11-30T09:30:56.160+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:56.161+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:56.161+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:56.181+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_117 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T09:30:56.188+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_117_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 432.9 MiB)
[2025-11-30T09:30:56.189+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_117_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.190+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 117 from corr at <unknown>:0
[2025-11-30T09:30:56.191+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:56.194+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Registering RDD 281 (corr at <unknown>:0) as input to shuffle 40
[2025-11-30T09:30:56.195+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got map stage job 79 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ShuffleMapStage 121 (corr at <unknown>:0)
[2025-11-30T09:30:56.196+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.197+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.197+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 121 (MapPartitionsRDD[281] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_118 stored as values in memory (estimated size 33.0 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.198+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_118_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.199+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_118_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.200+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 118 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.201+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 121 (MapPartitionsRDD[281] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.201+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 121.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.202+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 121.0 (TID 79) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:56.203+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 121.0 (TID 79)
[2025-11-30T09:30:56.203+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:56.220+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 121.0 (TID 79). 2136 bytes result sent to driver
[2025-11-30T09:30:56.221+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 121.0 (TID 79) in 22 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.222+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 121.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.223+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ShuffleMapStage 121 (corr at <unknown>:0) finished in 0.027 s
[2025-11-30T09:30:56.223+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:56.224+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:56.224+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:56.225+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:56.239+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T09:30:56.240+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 80 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.240+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 123 (corr at <unknown>:0)
[2025-11-30T09:30:56.241+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 122)
[2025-11-30T09:30:56.242+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.242+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 123 (MapPartitionsRDD[284] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.243+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_119 stored as values in memory (estimated size 22.2 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.244+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_119_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.245+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_119_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.1 MiB)
[2025-11-30T09:30:56.245+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 119 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.246+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 123 (MapPartitionsRDD[284] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.247+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 123.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.248+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 123.0 (TID 80) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:56.248+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 123.0 (TID 80)
[2025-11-30T09:30:56.249+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:56.250+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:56.258+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 123.0 (TID 80). 4032 bytes result sent to driver
[2025-11-30T09:30:56.258+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_113_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.259+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 123.0 (TID 80) in 13 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.260+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 123.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.260+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ResultStage 123 (corr at <unknown>:0) finished in 0.018 s
[2025-11-30T09:30:56.261+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_118_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.261+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 80 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:56.262+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 123: Stage finished
[2025-11-30T09:30:56.264+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 80 finished: corr at <unknown>:0, took 0.020426 s
[2025-11-30T09:30:56.265+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_111_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.265+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_114_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.266+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_115_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.267+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_116_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.3 MiB)
[2025-11-30T09:30:56.286+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:56.287+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:56.288+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:56.321+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_120 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.328+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_120_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.329+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_120_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 120 from corr at <unknown>:0
[2025-11-30T09:30:56.330+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:56.334+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Registering RDD 288 (corr at <unknown>:0) as input to shuffle 41
[2025-11-30T09:30:56.335+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got map stage job 81 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.336+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ShuffleMapStage 124 (corr at <unknown>:0)
[2025-11-30T09:30:56.336+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.337+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.338+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 124 (MapPartitionsRDD[288] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.338+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_121 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.339+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_121_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.340+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_121_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.341+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 121 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.341+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 124 (MapPartitionsRDD[288] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.342+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 124.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.342+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 124.0 (TID 81) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:56.343+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 124.0 (TID 81)
[2025-11-30T09:30:56.344+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:56.362+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 124.0 (TID 81). 2136 bytes result sent to driver
[2025-11-30T09:30:56.363+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 124.0 (TID 81) in 23 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.364+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 124.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.365+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ShuffleMapStage 124 (corr at <unknown>:0) finished in 0.028 s
[2025-11-30T09:30:56.365+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:56.366+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:56.366+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:56.367+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:56.380+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T09:30:56.381+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 82 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.382+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 126 (corr at <unknown>:0)
[2025-11-30T09:30:56.383+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 125)
[2025-11-30T09:30:56.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.384+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 126 (MapPartitionsRDD[291] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.385+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_122 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.386+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_122_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.386+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_122_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.387+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 122 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.388+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 126 (MapPartitionsRDD[291] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.388+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 126.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.389+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 126.0 (TID 82) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:56.390+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 126.0 (TID 82)
[2025-11-30T09:30:56.391+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:56.391+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:56.394+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 126.0 (TID 82). 3989 bytes result sent to driver
[2025-11-30T09:30:56.396+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 126.0 (TID 82) in 9 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.396+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 126.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.397+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ResultStage 126 (corr at <unknown>:0) finished in 0.014 s
[2025-11-30T09:30:56.398+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 82 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:56.399+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 126: Stage finished
[2025-11-30T09:30:56.399+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 82 finished: corr at <unknown>:0, took 0.017072 s
[2025-11-30T09:30:56.418+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:56.419+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:56.420+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:56.433+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_123 stored as values in memory (estimated size 207.3 KiB, free 432.9 MiB)
[2025-11-30T09:30:56.439+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_123_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 432.9 MiB)
[2025-11-30T09:30:56.440+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_123_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.441+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 123 from corr at <unknown>:0
[2025-11-30T09:30:56.442+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:56.444+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Registering RDD 295 (corr at <unknown>:0) as input to shuffle 42
[2025-11-30T09:30:56.445+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got map stage job 83 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ShuffleMapStage 127 (corr at <unknown>:0)
[2025-11-30T09:30:56.446+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.447+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 127 (MapPartitionsRDD[295] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.448+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_124 stored as values in memory (estimated size 33.0 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_124_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.449+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_124_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.450+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 124 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.450+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 127 (MapPartitionsRDD[295] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.451+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 127.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.451+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 127.0 (TID 83) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:56.452+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 127.0 (TID 83)
[2025-11-30T09:30:56.452+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:56.467+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 127.0 (TID 83). 2136 bytes result sent to driver
[2025-11-30T09:30:56.467+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 127.0 (TID 83) in 19 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.468+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 127.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ShuffleMapStage 127 (corr at <unknown>:0) finished in 0.022 s
[2025-11-30T09:30:56.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:56.471+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:56.472+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:56.472+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:56.485+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T09:30:56.487+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 84 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.487+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 129 (corr at <unknown>:0)
[2025-11-30T09:30:56.488+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 128)
[2025-11-30T09:30:56.488+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.489+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 129 (MapPartitionsRDD[298] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.489+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_125 stored as values in memory (estimated size 22.2 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.494+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_125_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 432.8 MiB)
[2025-11-30T09:30:56.495+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_125_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.1 MiB)
[2025-11-30T09:30:56.495+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_120_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.496+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 125 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.497+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 129 (MapPartitionsRDD[298] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.498+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 129.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.498+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_121_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.499+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 129.0 (TID 84) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:56.500+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_124_piece0 on fa0622e2494f:33513 in memory (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.501+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 129.0 (TID 84)
[2025-11-30T09:30:56.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_119_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.502+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:56.503+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_122_piece0 on fa0622e2494f:33513 in memory (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.504+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:56.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Removed broadcast_117_piece0 on fa0622e2494f:33513 in memory (size: 34.9 KiB, free: 434.3 MiB)
[2025-11-30T09:30:56.505+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 129.0 (TID 84). 3989 bytes result sent to driver
[2025-11-30T09:30:56.506+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 129.0 (TID 84) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.507+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 129.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.507+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ResultStage 129 (corr at <unknown>:0) finished in 0.016 s
[2025-11-30T09:30:56.508+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 84 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:56.508+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 129: Stage finished
[2025-11-30T09:30:56.509+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 84 finished: corr at <unknown>:0, took 0.019167 s
[2025-11-30T09:30:56.522+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DataSourceStrategy: Pruning directories with:
[2025-11-30T09:30:56.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Pushed Filters:
[2025-11-30T09:30:56.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceStrategy: Post-Scan Filters:
[2025-11-30T09:30:56.539+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_126 stored as values in memory (estimated size 207.3 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.545+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_126_piece0 stored as bytes in memory (estimated size 34.9 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.546+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_126_piece0 in memory on fa0622e2494f:33513 (size: 34.9 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.547+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 126 from corr at <unknown>:0
[2025-11-30T09:30:56.548+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4197036 bytes, open cost is considered as scanning 4194304 bytes.
[2025-11-30T09:30:56.550+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Registering RDD 302 (corr at <unknown>:0) as input to shuffle 43
[2025-11-30T09:30:56.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got map stage job 85 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ShuffleMapStage 130 (corr at <unknown>:0)
[2025-11-30T09:30:56.552+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.553+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.554+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ShuffleMapStage 130 (MapPartitionsRDD[302] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.554+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_127 stored as values in memory (estimated size 33.0 KiB, free 433.2 MiB)
[2025-11-30T09:30:56.557+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_127_piece0 stored as bytes in memory (estimated size 12.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.557+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_127_piece0 in memory on fa0622e2494f:33513 (size: 12.2 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.558+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 127 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.558+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ShuffleMapStage 130 (MapPartitionsRDD[302] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.559+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 130.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.560+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 130.0 (TID 85) (fa0622e2494f, executor driver, partition 0, ANY, 8341 bytes)
[2025-11-30T09:30:56.561+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 130.0 (TID 85)
[2025-11-30T09:30:56.564+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileScanRDD: Reading File path: hdfs://hadoop-namenode:9000/clean-data/air-quality/year=2025/month=11/day=30/part-00000-75230919-c22c-49ae-9fae-201213b830f2.c000.snappy.parquet, range: 0-2732, partition values: [2025,11,30]
[2025-11-30T09:30:56.580+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 130.0 (TID 85). 2136 bytes result sent to driver
[2025-11-30T09:30:56.581+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 130.0 (TID 85) in 21 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.582+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 130.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.583+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ShuffleMapStage 130 (corr at <unknown>:0) finished in 0.031 s
[2025-11-30T09:30:56.584+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: looking for newly runnable stages
[2025-11-30T09:30:56.585+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: running: Set()
[2025-11-30T09:30:56.585+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: waiting: Set()
[2025-11-30T09:30:56.586+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: failed: Set()
[2025-11-30T09:30:56.597+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: corr at <unknown>:0
[2025-11-30T09:30:56.598+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 86 (corr at <unknown>:0) with 1 output partitions
[2025-11-30T09:30:56.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 132 (corr at <unknown>:0)
[2025-11-30T09:30:56.599+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 131)
[2025-11-30T09:30:56.600+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 132 (MapPartitionsRDD[305] at corr at <unknown>:0), which has no missing parents
[2025-11-30T09:30:56.601+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_128 stored as values in memory (estimated size 22.2 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.602+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_128_piece0 stored as bytes in memory (estimated size 8.6 KiB, free 433.1 MiB)
[2025-11-30T09:30:56.603+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_128_piece0 in memory on fa0622e2494f:33513 (size: 8.6 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.604+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 128 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 132 (MapPartitionsRDD[305] at corr at <unknown>:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.605+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 132.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.606+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 132.0 (TID 86) (fa0622e2494f, executor driver, partition 0, NODE_LOCAL, 7615 bytes)
[2025-11-30T09:30:56.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 132.0 (TID 86)
[2025-11-30T09:30:56.607+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Getting 1 (80.0 B) non-empty blocks including 1 (80.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) push-merged-local and 0 (0.0 B) remote blocks
[2025-11-30T09:30:56.608+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
[2025-11-30T09:30:56.609+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Finished task 0.0 in stage 132.0 (TID 86). 3989 bytes result sent to driver
[2025-11-30T09:30:56.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Finished task 0.0 in stage 132.0 (TID 86) in 6 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:56.610+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Removed TaskSet 132.0, whose tasks have all completed, from pool
[2025-11-30T09:30:56.611+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: ResultStage 132 (corr at <unknown>:0) finished in 0.009 s
[2025-11-30T09:30:56.612+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 86 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:56.612+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Killing all running tasks in stage 132: Stage finished
[2025-11-30T09:30:56.613+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Job 86 finished: corr at <unknown>:0, took 0.011312 s
[2025-11-30T09:30:56.614+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:56,610 - INFO - Writing report to: hdfs://hadoop-namenode:9000/reports/data-quality/2025/11/30/dq_report.json
[2025-11-30T09:30:56.706+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO deprecation: mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
[2025-11-30T09:30:56.710+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-11-30T09:30:56.712+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-11-30T09:30:56.712+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-11-30T09:30:56.732+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Starting job: runJob at SparkHadoopWriter.scala:83
[2025-11-30T09:30:56.733+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Got job 87 (runJob at SparkHadoopWriter.scala:83) with 1 output partitions
[2025-11-30T09:30:56.734+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Final stage: ResultStage 133 (runJob at SparkHadoopWriter.scala:83)
[2025-11-30T09:30:56.735+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Parents of final stage: List()
[2025-11-30T09:30:56.736+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Missing parents: List()
[2025-11-30T09:30:56.736+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting ResultStage 133 (MapPartitionsRDD[309] at saveAsTextFile at NativeMethodAccessorImpl.java:0), which has no missing parents
[2025-11-30T09:30:56.744+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_129 stored as values in memory (estimated size 104.4 KiB, free 433.0 MiB)
[2025-11-30T09:30:56.745+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO MemoryStore: Block broadcast_129_piece0 stored as bytes in memory (estimated size 38.4 KiB, free 433.0 MiB)
[2025-11-30T09:30:56.746+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO BlockManagerInfo: Added broadcast_129_piece0 in memory on fa0622e2494f:33513 (size: 38.4 KiB, free: 434.2 MiB)
[2025-11-30T09:30:56.747+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO SparkContext: Created broadcast 129 from broadcast at DAGScheduler.scala:1580
[2025-11-30T09:30:56.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 133 (MapPartitionsRDD[309] at saveAsTextFile at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2025-11-30T09:30:56.748+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSchedulerImpl: Adding task set 133.0 with 1 tasks resource profile 0
[2025-11-30T09:30:56.749+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO TaskSetManager: Starting task 0.0 in stage 133.0 (TID 87) (fa0622e2494f, executor driver, partition 0, PROCESS_LOCAL, 10417 bytes)
[2025-11-30T09:30:56.750+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:56 INFO Executor: Running task 0.0 in stage 133.0 (TID 87)
[2025-11-30T09:30:57.428+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO HadoopMapRedCommitProtocol: Using output committer class org.apache.hadoop.mapred.FileOutputCommitter
[2025-11-30T09:30:57.428+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2025-11-30T09:30:57.429+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2025-11-30T09:30:57.470+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO PythonRunner: Times: total = 700, boot = 651, init = 49, finish = 0
[2025-11-30T09:30:57.520+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO FileOutputCommitter: Saved output of task 'attempt_202511300930564869349149428855690_0309_m_000000_0' to hdfs://hadoop-namenode:9000/reports/data-quality/2025/11/30/_temporary/0/task_202511300930564869349149428855690_0309_m_000000
[2025-11-30T09:30:57.521+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkHadoopMapRedUtil: attempt_202511300930564869349149428855690_0309_m_000000_0: Committed. Elapsed time: 7 ms.
[2025-11-30T09:30:57.523+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO Executor: Finished task 0.0 in stage 133.0 (TID 87). 1620 bytes result sent to driver
[2025-11-30T09:30:57.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO TaskSetManager: Finished task 0.0 in stage 133.0 (TID 87) in 775 ms on fa0622e2494f (executor driver) (1/1)
[2025-11-30T09:30:57.524+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO TaskSchedulerImpl: Removed TaskSet 133.0, whose tasks have all completed, from pool
[2025-11-30T09:30:57.525+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 37669
[2025-11-30T09:30:57.526+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO DAGScheduler: ResultStage 133 (runJob at SparkHadoopWriter.scala:83) finished in 0.792 s
[2025-11-30T09:30:57.527+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO DAGScheduler: Job 87 is finished. Cancelling potential speculative or zombie tasks for this job
[2025-11-30T09:30:57.527+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO TaskSchedulerImpl: Killing all running tasks in stage 133: Stage finished
[2025-11-30T09:30:57.528+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO DAGScheduler: Job 87 finished: runJob at SparkHadoopWriter.scala:83, took 0.794704 s
[2025-11-30T09:30:57.529+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkHadoopWriter: Start to commit write Job job_202511300930564869349149428855690_0309.
[2025-11-30T09:30:57.551+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkHadoopWriter: Write Job job_202511300930564869349149428855690_0309 committed. Elapsed time: 23 ms.
[2025-11-30T09:30:57.552+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO -  Data quality report written successfully
[2025-11-30T09:30:57.552+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO - ================================================================================
[2025-11-30T09:30:57.553+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO - DATA QUALITY REPORT (JSON)
[2025-11-30T09:30:57.554+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO - ================================================================================
[2025-11-30T09:30:57.555+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO - {
[2025-11-30T09:30:57.555+0000] {spark_submit.py:649} INFO - "report_date": "2025-11-30",
[2025-11-30T09:30:57.556+0000] {spark_submit.py:649} INFO - "report_timestamp": "2025-11-30T09:30:53.632651",
[2025-11-30T09:30:57.556+0000] {spark_submit.py:649} INFO - "summary": {
[2025-11-30T09:30:57.556+0000] {spark_submit.py:649} INFO - "total_records": 5,
[2025-11-30T09:30:57.557+0000] {spark_submit.py:649} INFO - "unique_records": 5,
[2025-11-30T09:30:57.557+0000] {spark_submit.py:649} INFO - "duplicate_records": 0,
[2025-11-30T09:30:57.558+0000] {spark_submit.py:649} INFO - "duplicate_ratio_percent": 0.0,
[2025-11-30T09:30:57.558+0000] {spark_submit.py:649} INFO - "null_columns": {
[2025-11-30T09:30:57.559+0000] {spark_submit.py:649} INFO - "city": {
[2025-11-30T09:30:57.559+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.560+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.560+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.561+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T09:30:57.561+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.561+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.562+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.562+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T09:30:57.562+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.563+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.563+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.565+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T09:30:57.566+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.567+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.568+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.568+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T09:30:57.569+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.569+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.570+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.570+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T09:30:57.571+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.571+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.572+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.573+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T09:30:57.574+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.574+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.575+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.576+0000] {spark_submit.py:649} INFO - "so2": {
[2025-11-30T09:30:57.576+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.577+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.578+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.578+0000] {spark_submit.py:649} INFO - "timestamp_utc": {
[2025-11-30T09:30:57.579+0000] {spark_submit.py:649} INFO - "null_count": 0,
[2025-11-30T09:30:57.579+0000] {spark_submit.py:649} INFO - "null_ratio_percent": 0.0
[2025-11-30T09:30:57.580+0000] {spark_submit.py:649} INFO - }
[2025-11-30T09:30:57.580+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.581+0000] {spark_submit.py:649} INFO - "range_violations": {
[2025-11-30T09:30:57.582+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T09:30:57.582+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T09:30:57.583+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.583+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.584+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.584+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T09:30:57.585+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T09:30:57.585+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.586+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.586+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.587+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T09:30:57.588+0000] {spark_submit.py:649} INFO - "range": "[0, 600]",
[2025-11-30T09:30:57.588+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.589+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.589+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.590+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T09:30:57.591+0000] {spark_submit.py:649} INFO - "range": "[0, 10000]",
[2025-11-30T09:30:57.591+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.592+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.593+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.594+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T09:30:57.595+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T09:30:57.596+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.597+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.597+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.598+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T09:30:57.599+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T09:30:57.600+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.601+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.602+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.603+0000] {spark_submit.py:649} INFO - "so2": {
[2025-11-30T09:30:57.604+0000] {spark_submit.py:649} INFO - "range": "[0, 500]",
[2025-11-30T09:30:57.604+0000] {spark_submit.py:649} INFO - "violations": 0,
[2025-11-30T09:30:57.605+0000] {spark_submit.py:649} INFO - "violation_ratio_percent": 0.0
[2025-11-30T09:30:57.606+0000] {spark_submit.py:649} INFO - }
[2025-11-30T09:30:57.607+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.608+0000] {spark_submit.py:649} INFO - "spike_detections": 0
[2025-11-30T09:30:57.609+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.610+0000] {spark_submit.py:649} INFO - "daily_city_details": [
[2025-11-30T09:30:57.610+0000] {spark_submit.py:649} INFO - {
[2025-11-30T09:30:57.611+0000] {spark_submit.py:649} INFO - "city": "HANOI",
[2025-11-30T09:30:57.612+0000] {spark_submit.py:649} INFO - "date": "2025-11-30",
[2025-11-30T09:30:57.613+0000] {spark_submit.py:649} INFO - "n_records": 5,
[2025-11-30T09:30:57.614+0000] {spark_submit.py:649} INFO - "aqi_nulls": 0,
[2025-11-30T09:30:57.615+0000] {spark_submit.py:649} INFO - "pm25_nulls": 0,
[2025-11-30T09:30:57.616+0000] {spark_submit.py:649} INFO - "pm10_nulls": 0,
[2025-11-30T09:30:57.616+0000] {spark_submit.py:649} INFO - "aqi_out_of_range": 0,
[2025-11-30T09:30:57.617+0000] {spark_submit.py:649} INFO - "pm25_out_of_range": 0,
[2025-11-30T09:30:57.618+0000] {spark_submit.py:649} INFO - "pm10_out_of_range": 0,
[2025-11-30T09:30:57.618+0000] {spark_submit.py:649} INFO - "aqi_avg": 217.0,
[2025-11-30T09:30:57.619+0000] {spark_submit.py:649} INFO - "aqi_stddev": null,
[2025-11-30T09:30:57.619+0000] {spark_submit.py:649} INFO - "aqi_p50": 217,
[2025-11-30T09:30:57.620+0000] {spark_submit.py:649} INFO - "status": "OK"
[2025-11-30T09:30:57.621+0000] {spark_submit.py:649} INFO - }
[2025-11-30T09:30:57.621+0000] {spark_submit.py:649} INFO - ],
[2025-11-30T09:30:57.622+0000] {spark_submit.py:649} INFO - "spikes": [],
[2025-11-30T09:30:57.622+0000] {spark_submit.py:649} INFO - "correlations": {
[2025-11-30T09:30:57.623+0000] {spark_submit.py:649} INFO - "aqi": {
[2025-11-30T09:30:57.623+0000] {spark_submit.py:649} INFO - "pm25": NaN,
[2025-11-30T09:30:57.624+0000] {spark_submit.py:649} INFO - "pm10": NaN,
[2025-11-30T09:30:57.625+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T09:30:57.625+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T09:30:57.625+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T09:30:57.626+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.626+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.627+0000] {spark_submit.py:649} INFO - "pm25": {
[2025-11-30T09:30:57.627+0000] {spark_submit.py:649} INFO - "pm10": NaN,
[2025-11-30T09:30:57.627+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T09:30:57.628+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T09:30:57.628+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T09:30:57.629+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.629+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.630+0000] {spark_submit.py:649} INFO - "pm10": {
[2025-11-30T09:30:57.630+0000] {spark_submit.py:649} INFO - "co": NaN,
[2025-11-30T09:30:57.630+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T09:30:57.631+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T09:30:57.631+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.632+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.632+0000] {spark_submit.py:649} INFO - "co": {
[2025-11-30T09:30:57.632+0000] {spark_submit.py:649} INFO - "no2": NaN,
[2025-11-30T09:30:57.633+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T09:30:57.633+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.634+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.634+0000] {spark_submit.py:649} INFO - "no2": {
[2025-11-30T09:30:57.635+0000] {spark_submit.py:649} INFO - "o3": NaN,
[2025-11-30T09:30:57.635+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.635+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.636+0000] {spark_submit.py:649} INFO - "o3": {
[2025-11-30T09:30:57.636+0000] {spark_submit.py:649} INFO - "so2": NaN
[2025-11-30T09:30:57.636+0000] {spark_submit.py:649} INFO - },
[2025-11-30T09:30:57.637+0000] {spark_submit.py:649} INFO - "so2": {}
[2025-11-30T09:30:57.637+0000] {spark_submit.py:649} INFO - }
[2025-11-30T09:30:57.638+0000] {spark_submit.py:649} INFO - }
[2025-11-30T09:30:57.638+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:57,551 - INFO - ================================================================================
[2025-11-30T09:30:57.638+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2025-11-30T09:30:57.639+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkUI: Stopped Spark web UI at http://fa0622e2494f:4040
[2025-11-30T09:30:57.639+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2025-11-30T09:30:57.640+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO MemoryStore: MemoryStore cleared
[2025-11-30T09:30:57.641+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO BlockManager: BlockManager stopped
[2025-11-30T09:30:57.641+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO BlockManagerMaster: BlockManagerMaster stopped
[2025-11-30T09:30:57.641+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2025-11-30T09:30:57.642+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:57 INFO SparkContext: Successfully stopped SparkContext
[2025-11-30T09:30:58.532+0000] {spark_submit.py:649} INFO - 2025-11-30 09:30:58,532 - INFO - Spark session stopped
[2025-11-30T09:30:58.578+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:58 INFO ShutdownHookManager: Shutdown hook called
[2025-11-30T09:30:58.579+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a634521-89db-47fb-94ea-2a0f1e6d9e47
[2025-11-30T09:30:58.583+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-4b5415f0-ac6e-45db-b1ca-5e07a3862b7b
[2025-11-30T09:30:58.586+0000] {spark_submit.py:649} INFO - 25/11/30 09:30:58 INFO ShutdownHookManager: Deleting directory /tmp/spark-3a634521-89db-47fb-94ea-2a0f1e6d9e47/pyspark-8a033f4e-675d-47cf-a32a-8099d7e5345e
[2025-11-30T09:30:58.671+0000] {taskinstance.py:1138} INFO - Marking task as SUCCESS. dag_id=1_hourly_cleaning_and_report, task_id=dq_report, execution_date=20251130T080000, start_date=20251130T093040, end_date=20251130T093058
[2025-11-30T09:30:58.719+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 0
[2025-11-30T09:30:58.751+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
